{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21a98c8",
   "metadata": {},
   "source": [
    "# Interactive Recipe & Kitchen Management Assistant\n",
    "\n",
    "## Step 2: Audio Input & Command Recognition with User Preferences\n",
    "\n",
    "This notebook implements the second step of our Interactive Recipe & Kitchen Management Assistant capstone project for the Google Gen AI Intensive Course. We'll create a voice interface that allows users to interact with our recipe assistant through spoken commands, recognize different types of user requests, and maintain user preferences.\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "The Interactive Recipe & Kitchen Management Assistant helps users:\n",
    "1. Discover recipes based on available ingredients\n",
    "2. Customize recipes according to dietary needs\n",
    "3. Receive step-by-step cooking guidance\n",
    "\n",
    "This notebook focuses on the **Audio understanding** Gen AI capability, which enables our assistant to:\n",
    "- Process voice commands using Google Cloud Speech-to-Text\n",
    "- Interpret user intent from natural language using Gemini Flash model\n",
    "- Store and retrieve user preferences for personalized experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3d077",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "Let's set up our environment with the necessary libraries for audio processing, Google Cloud Speech-to-Text, and natural language understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40db1580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:18:16.314366Z",
     "iopub.status.busy": "2025-04-06T20:18:16.313997Z",
     "iopub.status.idle": "2025-04-06T20:19:40.889085Z",
     "shell.execute_reply": "2025-04-06T20:19:40.887531Z",
     "shell.execute_reply.started": "2025-04-06T20:18:16.314331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \n",
      "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \n",
      "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [70.9 kB]                 \n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                           \n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\n",
      "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]   \n",
      "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,804 kB]\n",
      "Get:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,148 kB]\n",
      "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease               \n",
      "Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]         \n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]           \n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,092 kB]                \n",
      "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,683 kB]                    \n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]            \n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]           \n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [82.7 kB]               \n",
      "Get:22 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,978 kB]        \n",
      "Get:23 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.6 kB]\n",
      "Get:24 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.8 kB]\n",
      "Get:25 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]     \n",
      "Get:26 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,775 kB]\n",
      "Fetched 30.5 MB in 3s (9,547 kB/s)                             \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libportaudio2 libportaudiocpp0\n",
      "Suggested packages:\n",
      "  portaudio19-doc\n",
      "The following NEW packages will be installed:\n",
      "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
      "0 upgraded, 3 newly installed, 0 to remove and 189 not upgraded.\n",
      "Need to get 188 kB of archives.\n",
      "After this operation, 927 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
      "Fetched 188 kB in 0s (415 kB/s)        \n",
      "Selecting previously unselected package libportaudio2:amd64.\n",
      "(Reading database ... 127400 files and directories currently installed.)\n",
      "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Selecting previously unselected package libportaudiocpp0:amd64.\n",
      "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
      "Selecting previously unselected package portaudio19-dev:amd64.\n",
      "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
      "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
      "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.0a2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Setup additional Google API libraries\n",
    "!pip install -q google-generativeai  # For Gemini API\n",
    "!pip install -q google-cloud-speech  # For Speech-to-Text\n",
    "!pip install -q soundfile\n",
    "!pip install -q pydub  # For audio file handling\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "# Install PortAudio dependency for sounddevice\n",
    "!apt-get update\n",
    "!apt-get install -y portaudio19-dev #python-pyaudio\n",
    "!pip install -q sounddevice\n",
    "\n",
    "!pip install -q spacy\n",
    "!pip install -q nltk\n",
    "!pip install -q pandas\n",
    "!pip install -q matplotlib\n",
    "!pip install -q seaborn\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "# Download necessary NLP models\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m nltk.downloader punkt\n",
    "!python -m nltk.downloader stopwords\n",
    "\n",
    "!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412e94a",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Now let's import the libraries we'll need for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67337ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:21:31.065266Z",
     "iopub.status.busy": "2025-04-06T20:21:31.064851Z",
     "iopub.status.idle": "2025-04-06T20:21:31.075035Z",
     "shell.execute_reply": "2025-04-06T20:21:31.073844Z",
     "shell.execute_reply.started": "2025-04-06T20:21:31.065238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio libraries imported successfully!\n",
      "Google Cloud Speech-to-Text is imported successfully!\n",
      "Google genai is imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing libraries with error handling\n",
    "try:\n",
    "    import soundfile as sf\n",
    "    import sounddevice as sd\n",
    "    from IPython.display import Audio, display\n",
    "    AUDIO_LIBRARIES_AVAILABLE = True\n",
    "    print(\"Audio libraries imported successfully!\")\n",
    "except (ImportError, OSError) as e:\n",
    "    print(f\"Warning: Audio libraries could not be imported: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Google Cloud Speech-to-Text (with error handling)\n",
    "try:\n",
    "    from google.cloud import speech\n",
    "    GOOGLE_SPEECH_AVAILABLE = True\n",
    "    print(\"Google Cloud Speech-to-Text is imported successfully!\")\n",
    "except ImportError:\n",
    "    GOOGLE_SPEECH_AVAILABLE = False\n",
    "    print(\"Google Cloud Speech-to-Text not available. Will use simulation for speech recognition.\")\n",
    "\n",
    "# Google Gemini API for natural language understanding\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google.api_core import retry\n",
    "import IPython.widgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# Set up a retry helper. This allows you to \"Run all\" without worrying about per-minute quota.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)\n",
    "print(\"Google genai is imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a298e95-3713-4f7d-9c91-e17b8b3604b4",
   "metadata": {},
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ecb82c-7ed6-4355-a5fa-18aa33012f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:21:39.666078Z",
     "iopub.status.busy": "2025-04-06T20:21:39.665742Z",
     "iopub.status.idle": "2025-04-06T20:21:39.837760Z",
     "shell.execute_reply": "2025-04-06T20:21:39.836600Z",
     "shell.execute_reply.started": "2025-04-06T20:21:39.666054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d88e00-80fc-4e07-b12e-07133ff8bfb2",
   "metadata": {},
   "source": [
    "### Run your test prompt\n",
    "\n",
    "In this step, you will test that your API key is set up correctly by making a request.\n",
    "\n",
    "The Python SDK uses a [`Client` object](https://googleapis.github.io/python-genai/genai.html#genai.client.Client) to make requests to the API. The client lets you control which back-end to use (between the Gemini API and Vertex AI) and handles authentication (the API key).\n",
    "\n",
    "The `gemini-2.0-flash` model has been selected here.\n",
    "\n",
    "**Note**: If you see a `TransportError` on this step, you may need to **üîÅ Factory reset** the notebook one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d07bce0-63f3-4fde-94ab-c53132de4dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:21:42.962096Z",
     "iopub.status.busy": "2025-04-06T20:21:42.961737Z",
     "iopub.status.idle": "2025-04-06T20:21:43.942938Z",
     "shell.execute_reply": "2025-04-06T20:21:43.942081Z",
     "shell.execute_reply.started": "2025-04-06T20:21:42.962071Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I received your test message. I'm doing well, thank you for asking! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Hi, This is a test message! How are you?\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf62285",
   "metadata": {},
   "source": [
    "## Load Recipe Data from Step 1\n",
    "\n",
    "Let's load the recipe data that we processed in Step 1. We'll use this data to test our command recognition system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "889dc39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:23:33.636459Z",
     "iopub.status.busy": "2025-04-06T20:23:33.636017Z",
     "iopub.status.idle": "2025-04-06T20:23:40.799983Z",
     "shell.execute_reply": "2025-04-06T20:23:40.798838Z",
     "shell.execute_reply.started": "2025-04-06T20:23:33.636428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 230186 recipes from Kaggle dataset input directory (JSON)\n"
     ]
    }
   ],
   "source": [
    "# Define paths for loading and saving data\n",
    "# For Kaggle's output sharing feature\n",
    "DATA_DIR = Path('/kaggle/input/step1-data-setup')\n",
    "FINAL_DIR = Path('.')\n",
    "RECIPE_FILE = FINAL_DIR / 'processed_recipes.json'\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# # Try to load the processed recipe data from Step 1\n",
    "try:\n",
    "    # Check if the file exists in the Kaggle input directory (if step1 was saved as a dataset)\n",
    "    kaggle_json_path = DATA_DIR / 'processed_recipes.json'\n",
    "    \n",
    "    # First check if the file is in the current directory (where step1 might have saved it)\n",
    "    if RECIPE_FILE.exists():\n",
    "        with open(RECIPE_FILE, 'r') as f:\n",
    "            recipes_data = json.load(f)\n",
    "        recipes_df = pd.DataFrame(recipes_data)\n",
    "        print(f\"Loaded {len(recipes_df)} recipes from JSON file in current directory\")\n",
    "    \n",
    "    # Check if JSON file exists in Kaggle input directory\n",
    "    elif kaggle_json_path.exists():\n",
    "        with open(kaggle_json_path, 'r') as f:\n",
    "            recipes_data = json.load(f)\n",
    "        recipes_df = pd.DataFrame(recipes_data)\n",
    "        print(f\"Loaded {len(recipes_df)} recipes from Kaggle dataset input directory (JSON)\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading recipe data: {e}\")   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bae6df",
   "metadata": {},
   "source": [
    "## Google Cloud Speech-to-Text API Setup\n",
    "\n",
    "To use Google Cloud Speech-to-Text, we need to set up authentication and configure the client. In a production environment, this would involve creating a service account and downloading the credentials. For demonstration in a Kaggle/local environment, we'll simulate the API response.\n",
    "\n",
    "> Note: In a real implementation, you would:\n",
    "> 1. Create a Google Cloud project\n",
    "> 2. Enable the Speech-to-Text API\n",
    "> 3. Create a service account with appropriate permissions\n",
    "> 4. Download the credentials JSON file\n",
    "> 5. Set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to point to this file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba3a13",
   "metadata": {},
   "source": [
    "## Audio Loading and Processing\n",
    "\n",
    "In a production environment, we would implement real audio recording from the microphone. Since we're in a notebook environment, we'll create functions that load the recorded audios and processing them to demonstrate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d219f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:25:10.776124Z",
     "iopub.status.busy": "2025-04-06T20:25:10.775710Z",
     "iopub.status.idle": "2025-04-06T20:25:10.791393Z",
     "shell.execute_reply": "2025-04-06T20:25:10.789986Z",
     "shell.execute_reply.started": "2025-04-06T20:25:10.776092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define audio recording parameters\n",
    "SAMPLE_RATE = 16000  # 16 kHz\n",
    "DURATION = 5  # 5 seconds\n",
    "CHANNELS = 1  # Mono audio\n",
    "\n",
    "\n",
    "def load_audio_file(file_path, expected_sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Load an audio file and convert it to the expected format\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the audio file\n",
    "        expected_sample_rate (int): Expected sample rate in Hz\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Audio data as numpy array\n",
    "        int: Sample rate\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check file extension\n",
    "        file_ext = Path(file_path).suffix.lower()\n",
    "        \n",
    "        # For OGG files, use librosa which handles them better\n",
    "        if file_ext == '.ogg':\n",
    "            try:\n",
    "                import librosa\n",
    "                print(f\"Loading OGG file using librosa: {file_path}\")\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=expected_sample_rate, mono=True)\n",
    "                \n",
    "                # Ensure audio_data is a 1D array\n",
    "                if len(audio_data.shape) > 1:\n",
    "                    audio_data = audio_data[:, 0]\n",
    "                \n",
    "                print(f\"Loaded OGG file with sample rate: {sample_rate}Hz\")\n",
    "                return audio_data, sample_rate\n",
    "            except ImportError:\n",
    "                print(\"Librosa not available. Falling back to soundfile.\")\n",
    "        \n",
    "        # Load the audio file with soundfile\n",
    "        audio_data, sample_rate = sf.read(file_path)\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if len(audio_data.shape) > 1 and audio_data.shape[1] > 1:\n",
    "            audio_data = audio_data[:, 0]\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sample_rate != expected_sample_rate:\n",
    "            # In a real implementation, we would use a proper resampling library\n",
    "            # For demonstration, we'll just use a simple approach\n",
    "            print(f\"Resampling from {sample_rate}Hz to {expected_sample_rate}Hz\")\n",
    "            audio_data = np.interp(\n",
    "                np.linspace(0, 1, int(len(audio_data) * expected_sample_rate / sample_rate)),\n",
    "                np.linspace(0, 1, len(audio_data)),\n",
    "                audio_data\n",
    "            )\n",
    "            sample_rate = expected_sample_rate\n",
    "        \n",
    "        return audio_data, sample_rate\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def preprocess_audio(audio_data, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Preprocess audio data for optimal speech recognition\n",
    "    \n",
    "    Args:\n",
    "        audio_data (numpy.ndarray): Audio data as numpy array\n",
    "        sample_rate (int): Sample rate in Hz\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed audio data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if input is actually a tuple (audio_data, sample_rate)\n",
    "        if isinstance(audio_data, tuple) and len(audio_data) == 2:\n",
    "            print(\"Warning: You passed a tuple to preprocess_audio. Extracting just the audio data.\")\n",
    "            audio_data, _ = audio_data\n",
    "        \n",
    "        # Make sure audio_data is a 1D numpy array\n",
    "        if not isinstance(audio_data, np.ndarray):\n",
    "            raise TypeError(\"Audio data must be a numpy array\")\n",
    "            \n",
    "        # Ensure it's 1D\n",
    "        if len(audio_data.shape) > 1:\n",
    "            print(\"Converting multi-channel audio to mono\")\n",
    "            audio_data = audio_data.mean(axis=1) if audio_data.shape[1] > 1 else audio_data[:, 0]\n",
    "        \n",
    "        # Apply a simple normalization\n",
    "        if np.max(np.abs(audio_data)) > 0:\n",
    "            audio_data = audio_data / np.max(np.abs(audio_data)) * 0.9\n",
    "        \n",
    "        # Apply a simple noise gate\n",
    "        noise_threshold = 0.01\n",
    "        audio_data[np.abs(audio_data) < noise_threshold] = 0\n",
    "        \n",
    "        return audio_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing audio: {e}\")\n",
    "        return audio_data if isinstance(audio_data, np.ndarray) else np.zeros(1000)  # Return original data or empty array in case of error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d975606",
   "metadata": {},
   "source": [
    "## Speech-to-Text Conversion\n",
    "\n",
    "Let's implement a real speech-to-text function using Google Cloud Speech-to-Text API. This will allow us to convert voice commands from audio files into text for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473c516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:25:22.224366Z",
     "iopub.status.busy": "2025-04-06T20:25:22.223945Z",
     "iopub.status.idle": "2025-04-06T20:25:22.232765Z",
     "shell.execute_reply": "2025-04-06T20:25:22.231559Z",
     "shell.execute_reply.started": "2025-04-06T20:25:22.224334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_speech_to_text(audio_data, sample_rate=SAMPLE_RATE, language_code=\"en-US\"):\n",
    "    \"\"\"\n",
    "    Convert speech audio to text using Google Cloud Speech-to-Text API\n",
    "    \n",
    "    Args:\n",
    "        audio_data (numpy.ndarray): Audio data as numpy array\n",
    "        sample_rate (int): Sample rate in Hz\n",
    "        language_code (str): Language code (e.g., \"en-US\")\n",
    "        \n",
    "    Returns:\n",
    "        str: Transcribed text\n",
    "        float: Confidence score (0-1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if we have access to Google Cloud Speech client\n",
    "        if GOOGLE_SPEECH_AVAILABLE and hasattr(speech, 'SpeechClient'):\n",
    "            # Initialize the speech client if not already done\n",
    "            speech_client = speech.SpeechClient()\n",
    "            \n",
    "            # Convert the numpy array to bytes\n",
    "            audio_bytes = (audio_data * 32767).astype(np.int16).tobytes()\n",
    "            \n",
    "            # Create recognition config\n",
    "            config = speech.RecognitionConfig(\n",
    "                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                sample_rate_hertz=sample_rate,\n",
    "                language_code=language_code,\n",
    "                enable_automatic_punctuation=True,\n",
    "                model=\"default\",  # Use \"phone_call\" for phone audio or \"video\" for video\n",
    "                use_enhanced=True  # Use enhanced model\n",
    "            )\n",
    "            \n",
    "            # Create audio object\n",
    "            audio = speech.RecognitionAudio(content=audio_bytes)\n",
    "            \n",
    "            # Send request to the API\n",
    "            response = speech_client.recognize(config=config, audio=audio)\n",
    "            \n",
    "            # Process the response\n",
    "            if response.results:\n",
    "                # Get the first alternative (most likely transcription)\n",
    "                transcription = response.results[0].alternatives[0].transcript\n",
    "                confidence = response.results[0].alternatives[0].confidence\n",
    "                \n",
    "                print(f\"Transcribed text: '{transcription}' (confidence: {confidence:.2f})\")\n",
    "                return transcription, confidence\n",
    "            else:\n",
    "                print(\"No speech detected in audio\")\n",
    "                return \"\", 0.0\n",
    "        else:\n",
    "            print(\"Google Cloud Speech-to-Text API not available.\")\n",
    "            print(\"Please ensure you have set up the Google Cloud Speech-to-Text API properly.\")\n",
    "            return \"\", 0.0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in speech-to-text conversion: {e}\")\n",
    "        return \"\", 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e082c4",
   "metadata": {},
   "source": [
    "## Command Parsing and Intent Recognition by Gemini Flash\n",
    "\n",
    "Now let's implement a modern command parsing logic using the Gemini Flash model to extract user intent and entities from transcribed text. This will provide a more accurate and robust understanding of user commands compared to traditional NLP methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini model\n",
    "GEMINI_AVAILABLE = True\n",
    "try:\n",
    "    gemini_model = client\n",
    "    print(\"Gemini model initialized successfully!\")\n",
    "except NameError:\n",
    "    GEMINI_AVAILABLE = False\n",
    "    gemini_model = None\n",
    "    print(\"Gemini model not available. Please check your API key.\")\n",
    "\n",
    "def parse_command_with_gemini(text):\n",
    "    \"\"\"\n",
    "    Parse a command to extract intent and entities using Gemini Flash model\n",
    "    \n",
    "    Args:\n",
    "        text (str): The command text\n",
    "        \n",
    "    Returns:\n",
    "        dict: Structured command representation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not GEMINI_AVAILABLE or not gemini_model:\n",
    "            print(\"Gemini model not available. Please check your API key.\")\n",
    "            return {\n",
    "                \"text\": text,\n",
    "                \"intent\": \"unknown\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"ingredients\": [],\n",
    "                \"dietary_restrictions\": [],\n",
    "                \"cuisine_type\": None,\n",
    "                \"meal_type\": None,\n",
    "                \"cooking_time\": None,\n",
    "                \"timestamp\": datetime.datetime.now().isoformat()\n",
    "            }\n",
    "        \n",
    "        # Define the prompt for Gemini to extract intents and entities\n",
    "        prompt = f\"\"\"\n",
    "        Extract the intent and entities from this cooking command: \"{text}\"\n",
    "        \n",
    "        Classify the intent as one of:\n",
    "        - find_recipe: Looking for recipes with specific criteria\n",
    "        - save_preference: Saving user preferences\n",
    "        - customize_recipe: Customizing or modifying recipes\n",
    "        - cooking_guidance: Asking for cooking instructions or guidance\n",
    "        - general_info: Asking for general information\n",
    "        \n",
    "        Extract the following entities if present:\n",
    "        - ingredients: List of food items mentioned\n",
    "        - dietary_restrictions: Any dietary constraints (vegetarian, gluten-free, etc.)\n",
    "        - cuisine_type: Type of cuisine (Italian, Mexican, etc.)\n",
    "        - meal_type: Type of meal (breakfast, dinner, etc.)\n",
    "        - cooking_time: Time constraints mentioned\n",
    "        \n",
    "        Format your response as JSON with the following structure:\n",
    "        {{\n",
    "            \"intent\": \"intent_name\",\n",
    "            \"confidence\": 0.0 to 1.0,\n",
    "            \"entities\": {{\n",
    "                \"ingredients\": [\"item1\", \"item2\"],\n",
    "                \"dietary_restrictions\": [\"restriction1\"],\n",
    "                \"cuisine_type\": \"cuisine or null\",\n",
    "                \"meal_type\": \"meal type or null\",\n",
    "                \"cooking_time\": \"time description or null\"\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate response from Gemini model\n",
    "        response = gemini_model.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        import json\n",
    "        try:\n",
    "            result = json.loads(response.text)\n",
    "            \n",
    "            # Construct the command structure expected by the rest of the code\n",
    "            command = {\n",
    "                \"text\": text,\n",
    "                \"intent\": result[\"intent\"],\n",
    "                \"confidence\": float(result[\"confidence\"]),\n",
    "                \"ingredients\": result[\"entities\"][\"ingredients\"] if \"ingredients\" in result[\"entities\"] else [],\n",
    "                \"dietary_restrictions\": result[\"entities\"][\"dietary_restrictions\"] if \"dietary_restrictions\" in result[\"entities\"] else [],\n",
    "                \"cuisine_type\": result[\"entities\"][\"cuisine_type\"] if \"cuisine_type\" in result[\"entities\"] and result[\"entities\"][\"cuisine_type\"] != \"null\" else None,\n",
    "                \"meal_type\": result[\"entities\"][\"meal_type\"] if \"meal_type\" in result[\"entities\"] and result[\"entities\"][\"meal_type\"] != \"null\" else None,\n",
    "                \"cooking_time\": result[\"entities\"][\"cooking_time\"] if \"cooking_time\" in result[\"entities\"] and result[\"entities\"][\"cooking_time\"] != \"null\" else None,\n",
    "                \"timestamp\": datetime.datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            return command\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing Gemini response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return {\n",
    "                \"text\": text,\n",
    "                \"intent\": \"unknown\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"ingredients\": [],\n",
    "                \"dietary_restrictions\": [],\n",
    "                \"cuisine_type\": None,\n",
    "                \"meal_type\": None,\n",
    "                \"cooking_time\": None,\n",
    "                \"timestamp\": datetime.datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error using Gemini for command parsing: {e}\")\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"intent\": \"unknown\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"ingredients\": [],\n",
    "            \"dietary_restrictions\": [],\n",
    "            \"cuisine_type\": None,\n",
    "            \"meal_type\": None,\n",
    "            \"cooking_time\": None,\n",
    "            \"timestamp\": datetime.datetime.now().isoformat()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db2c14",
   "metadata": {},
   "source": [
    "## Command Confirmation Flow by Gemini Flash\n",
    "\n",
    "Let's implement a confirmation mechanism using Gemini Flash model to verify we've correctly understood user commands, which is especially important for voice inputs that might be misinterpreted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confirmation_message(command):\n",
    "    \"\"\"\n",
    "    Generate a confirmation message based on the parsed command\n",
    "    \n",
    "    Args:\n",
    "        command (dict): Parsed command structure\n",
    "        \n",
    "    Returns:\n",
    "        str: Confirmation message\n",
    "    \"\"\"\n",
    "    intent = command[\"intent\"]\n",
    "    message = \"I understand you want to \"\n",
    "    \n",
    "    if intent == \"find_recipe\":\n",
    "        message += \"find recipes\"\n",
    "        \n",
    "        # Add ingredients\n",
    "        if command[\"ingredients\"]:\n",
    "            message += f\" with {', '.join(command['ingredients'])}\"\n",
    "        \n",
    "        # Add dietary restrictions\n",
    "        if command[\"dietary_restrictions\"]:\n",
    "            message += f\" that are {', '.join(command['dietary_restrictions'])}\"\n",
    "        \n",
    "        # Add cuisine type\n",
    "        if command[\"cuisine_type\"]:\n",
    "            message += f\" in {command['cuisine_type']} cuisine\"\n",
    "        \n",
    "        # Add meal type\n",
    "        if command[\"meal_type\"]:\n",
    "            message += f\" for {command['meal_type']}\"\n",
    "        \n",
    "        # Add cooking time\n",
    "        if command[\"cooking_time\"]:\n",
    "            message += f\" that are {command['cooking_time']}\"\n",
    "    \n",
    "    elif intent == \"save_preference\":\n",
    "        message += \"save your preferences\"\n",
    "        \n",
    "        # Add dietary restrictions\n",
    "        if command[\"dietary_restrictions\"]:\n",
    "            message += f\" for {', '.join(command['dietary_restrictions'])} recipes\"\n",
    "        \n",
    "        # Add cuisine type\n",
    "        if command[\"cuisine_type\"]:\n",
    "            message += f\" with a preference for {command['cuisine_type']} cuisine\"\n",
    "    \n",
    "    elif intent == \"customize_recipe\":\n",
    "        message += \"customize a recipe\"\n",
    "        \n",
    "        # Add ingredients\n",
    "        if command[\"ingredients\"]:\n",
    "            message += f\" by replacing or adjusting {', '.join(command['ingredients'])}\"\n",
    "        \n",
    "        # Add dietary restrictions\n",
    "        if command[\"dietary_restrictions\"]:\n",
    "            message += f\" to make it {', '.join(command['dietary_restrictions'])}\"\n",
    "    \n",
    "    elif intent == \"cooking_guidance\":\n",
    "        message += \"get cooking guidance\"\n",
    "        \n",
    "        # Add ingredients\n",
    "        if command[\"ingredients\"]:\n",
    "            message += f\" for cooking with {', '.join(command['ingredients'])}\"\n",
    "    \n",
    "    elif intent == \"general_info\":\n",
    "        message += \"get general information\"\n",
    "        \n",
    "        # Add ingredients\n",
    "        if command[\"ingredients\"]:\n",
    "            message += f\" about {', '.join(command['ingredients'])}\"\n",
    "    \n",
    "    else:\n",
    "        message = f\"I'm not sure what you're asking for. Could you rephrase your request?\"\n",
    "    \n",
    "    message += \".\"\n",
    "    return message\n",
    "\n",
    "def confirm_command(command):\n",
    "    \"\"\"\n",
    "    Simulate a confirmation dialogue with the user\n",
    "    \n",
    "    Args:\n",
    "        command (dict): Parsed command structure\n",
    "        \n",
    "    Returns:\n",
    "        bool: Whether the command was confirmed\n",
    "        dict: Updated command if modified, original otherwise\n",
    "    \"\"\"\n",
    "    # Generate confirmation message\n",
    "    confirmation_message = generate_confirmation_message(command)\n",
    "    print(f\"\\nConfirmation: {confirmation_message}\")\n",
    "    \n",
    "    # In a real implementation, we would wait for user confirmation\n",
    "    # For demonstration, we'll simulate random confirmation/correction\n",
    "    \n",
    "    confirmation_result = random.choices(\n",
    "        [\"confirm\", \"correct\", \"cancel\"],\n",
    "        weights=[0.7, 0.2, 0.1]\n",
    "    )[0]\n",
    "    \n",
    "    if confirmation_result == \"confirm\":\n",
    "        print(\"User confirmed: Yes, that's correct.\")\n",
    "        return True, command\n",
    "    \n",
    "    elif confirmation_result == \"correct\":\n",
    "        print(\"User correction: No, I meant...\")\n",
    "        \n",
    "        # Simulate a correction\n",
    "        if command[\"intent\"] == \"find_recipe\":\n",
    "            # Add a random ingredient or dietary restriction\n",
    "            if random.random() > 0.5 and not command[\"ingredients\"]:\n",
    "                command[\"ingredients\"].append(random.choice([\"chicken\", \"pasta\", \"vegetables\"]))\n",
    "                print(f\"Added ingredient: {command['ingredients'][-1]}\")\n",
    "            elif not command[\"dietary_restrictions\"]:\n",
    "                command[\"dietary_restrictions\"].append(random.choice([\"vegetarian\", \"gluten-free\"]))\n",
    "                print(f\"Added dietary restriction: {command['dietary_restrictions'][-1]}\")\n",
    "        \n",
    "        # Generate a new confirmation message with the updated command\n",
    "        updated_confirmation = generate_confirmation_message(command)\n",
    "        print(f\"Updated understanding: {updated_confirmation}\")\n",
    "        print(\"User: Yes, that's correct now.\")\n",
    "        \n",
    "        return True, command\n",
    "    \n",
    "    else:  # Cancel\n",
    "        print(\"User: No, cancel that request.\")\n",
    "        return False, command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b75a31",
   "metadata": {},
   "source": [
    "## User Preference Storage\n",
    "\n",
    "Let's implement a system to store and retrieve user preferences. We'll use a simple JSON-based approach for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65cafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for user preferences\n",
    "PREFERENCES_FILE = DATA_DIR / 'user_preferences.json'\n",
    "\n",
    "def load_user_preferences():\n",
    "    \"\"\"\n",
    "    Load user preferences from file\n",
    "    \n",
    "    Returns:\n",
    "        dict: User preferences\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if PREFERENCES_FILE.exists():\n",
    "            with open(PREFERENCES_FILE, 'r') as f:\n",
    "                preferences = json.load(f)\n",
    "            return preferences\n",
    "        else:\n",
    "            # Return default preferences if file doesn't exist\n",
    "            return {\n",
    "                \"dietary_preferences\": [],\n",
    "                \"favorite_recipes\": [],\n",
    "                \"avoided_ingredients\": [],\n",
    "                \"preferred_cuisines\": [],\n",
    "                \"meal_preferences\": {},\n",
    "                \"command_history\": []\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading user preferences: {e}\")\n",
    "        # Return default preferences in case of error\n",
    "        return {\n",
    "            \"dietary_preferences\": [],\n",
    "            \"favorite_recipes\": [],\n",
    "            \"avoided_ingredients\": [],\n",
    "            \"preferred_cuisines\": [],\n",
    "            \"meal_preferences\": {},\n",
    "            \"command_history\": []\n",
    "        }\n",
    "\n",
    "def save_user_preferences(preferences):\n",
    "    \"\"\"\n",
    "    Save user preferences to file\n",
    "    \n",
    "    Args:\n",
    "        preferences (dict): User preferences to save\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success or failure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create directory if it doesn't exist\n",
    "        PREFERENCES_FILE.parent.mkdir(exist_ok=True)\n",
    "        \n",
    "        with open(PREFERENCES_FILE, 'w') as f:\n",
    "            json.dump(preferences, f, indent=2)\n",
    "        \n",
    "        print(f\"User preferences saved to {PREFERENCES_FILE}\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving user preferences: {e}\")\n",
    "        return False\n",
    "\n",
    "def update_user_preference(preference_type, value):\n",
    "    \"\"\"\n",
    "    Update a specific user preference\n",
    "    \n",
    "    Args:\n",
    "        preference_type (str): Type of preference to update\n",
    "        value: Value to save\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success or failure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load current preferences\n",
    "        preferences = load_user_preferences()\n",
    "        \n",
    "        # Update the specific preference\n",
    "        if preference_type in preferences:\n",
    "            # For list types, add if not already present\n",
    "            if isinstance(preferences[preference_type], list):\n",
    "                if value not in preferences[preference_type]:\n",
    "                    preferences[preference_type].append(value)\n",
    "            \n",
    "            # For dict types, update or add key-value pair\n",
    "            elif isinstance(preferences[preference_type], dict):\n",
    "                # Assume value is a dict or tuple/list that can be unpacked\n",
    "                if isinstance(value, dict):\n",
    "                    preferences[preference_type].update(value)\n",
    "                else:\n",
    "                    key, val = value\n",
    "                    preferences[preference_type][key] = val\n",
    "            \n",
    "            # For other types, simply replace\n",
    "            else:\n",
    "                preferences[preference_type] = value\n",
    "        \n",
    "        # Save updated preferences\n",
    "        return save_user_preferences(preferences)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating user preference: {e}\")\n",
    "        return False\n",
    "\n",
    "def add_to_command_history(command):\n",
    "    \"\"\"\n",
    "    Add a command to the user's command history\n",
    "    \n",
    "    Args:\n",
    "        command (dict): Command to add to history\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success or failure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load current preferences\n",
    "        preferences = load_user_preferences()\n",
    "        \n",
    "        # Add the command to history\n",
    "        if \"command_history\" in preferences:\n",
    "            # Limit history to 20 commands\n",
    "            if len(preferences[\"command_history\"]) >= 20:\n",
    "                preferences[\"command_history\"].pop(0)\n",
    "            \n",
    "            preferences[\"command_history\"].append(command)\n",
    "        \n",
    "        # Save updated preferences\n",
    "        return save_user_preferences(preferences)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding to command history: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_user_preference(preference_type=None):\n",
    "    \"\"\"\n",
    "    Get user preferences of a specific type or all preferences\n",
    "    \n",
    "    Args:\n",
    "        preference_type (str, optional): Type of preference to get, or None for all\n",
    "        \n",
    "    Returns:\n",
    "        Any: The preference value(s)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load preferences\n",
    "        preferences = load_user_preferences()\n",
    "        \n",
    "        # Return specific preference or all preferences\n",
    "        if preference_type is not None:\n",
    "            return preferences.get(preference_type, None)\n",
    "        else:\n",
    "            return preferences\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting user preference: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_save_preference_command(command):\n",
    "    \"\"\"\n",
    "    Process a 'save_preference' command and update user preferences\n",
    "    \n",
    "    Args:\n",
    "        command (dict): The parsed command\n",
    "        \n",
    "    Returns:\n",
    "        str: Status message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check for dietary preferences\n",
    "        if command[\"dietary_restrictions\"]:\n",
    "            for preference in command[\"dietary_restrictions\"]:\n",
    "                update_user_preference(\"dietary_preferences\", preference)\n",
    "            return f\"Saved dietary preferences: {', '.join(command['dietary_restrictions'])}\"\n",
    "        \n",
    "        # Check for cuisine preferences\n",
    "        if command[\"cuisine_type\"]:\n",
    "            update_user_preference(\"preferred_cuisines\", command[\"cuisine_type\"])\n",
    "            return f\"Saved preferred cuisine: {command['cuisine_type']}\"\n",
    "        \n",
    "        # Check for avoided ingredients\n",
    "        if command[\"ingredients\"] and (\"without\" in command[\"text\"].lower() or \"avoid\" in command[\"text\"].lower()):\n",
    "            for ingredient in command[\"ingredients\"]:\n",
    "                update_user_preference(\"avoided_ingredients\", ingredient)\n",
    "            return f\"Saved avoided ingredients: {', '.join(command['ingredients'])}\"\n",
    "        \n",
    "        # General case for ingredients\n",
    "        if command[\"ingredients\"]:\n",
    "            return \"Your ingredient preferences have been noted.\"\n",
    "        \n",
    "        return \"I'm not sure what preference you want to save. Could you be more specific?\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing save preference command: {e}\")\n",
    "        return \"Sorry, there was an error saving your preferences.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f81a1",
   "metadata": {},
   "source": [
    "## Text Command Input Alternative\n",
    "\n",
    "For users who prefer typing over speaking, let's implement a text input interface. In the notebook environment, we'll use IPython widgets to provide an interactive interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b24844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_command_interface():\n",
    "    \"\"\"\n",
    "    Create an interactive text command interface using IPython widgets\n",
    "    \"\"\"\n",
    "    # Create a text input widget\n",
    "    text_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Type your command (e.g., \"Find recipes with chicken and pasta\")',\n",
    "        description='Command:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    # Create an output widget to display results\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Define the submit function\n",
    "    def on_submit(sender):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            process_text_command(text_input.value)\n",
    "    \n",
    "    # Connect the submit function to the widget\n",
    "    text_input.on_submit(on_submit)\n",
    "    \n",
    "    # Create a submit button for users who prefer clicking\n",
    "    submit_button = widgets.Button(\n",
    "        description='Submit',\n",
    "        disabled=False,\n",
    "        button_style='', \n",
    "        tooltip='Submit command',\n",
    "        icon='check'\n",
    "    )\n",
    "    \n",
    "    # Connect the button click to the same function\n",
    "    submit_button.on_click(lambda b: on_submit(text_input))\n",
    "    \n",
    "    # Display the widgets\n",
    "    display(widgets.HBox([text_input, submit_button]))\n",
    "    display(output)\n",
    "    \n",
    "    print(\"Type your command and press Enter or click Submit.\")\n",
    "\n",
    "def process_text_command(text):\n",
    "    \"\"\"\n",
    "    Process a text command\n",
    "    \n",
    "    Args:\n",
    "        text (str): The command text\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        print(\"Please enter a command.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing command: '{text}'\")\n",
    "    \n",
    "    # Parse the command\n",
    "    command = parse_command_with_gemini(text)\n",
    "    \n",
    "    # Display the parsed command\n",
    "    print(\"\\nCommand understood as:\")\n",
    "    print(f\"Intent: {command['intent']} (confidence: {command['confidence']:.2f})\")\n",
    "    \n",
    "    if command[\"ingredients\"]:\n",
    "        print(f\"Ingredients: {', '.join(command['ingredients'])}\")\n",
    "    \n",
    "    if command[\"dietary_restrictions\"]:\n",
    "        print(f\"Dietary restrictions: {', '.join(command['dietary_restrictions'])}\")\n",
    "    \n",
    "    if command[\"cuisine_type\"]:\n",
    "        print(f\"Cuisine type: {command['cuisine_type']}\")\n",
    "    \n",
    "    if command[\"meal_type\"]:\n",
    "        print(f\"Meal type: {command['meal_type']}\")\n",
    "    \n",
    "    if command[\"cooking_time\"]:\n",
    "        print(f\"Cooking time: {command['cooking_time']}\")\n",
    "    \n",
    "    # Confirm the command\n",
    "    confirmed, updated_command = confirm_command(command)\n",
    "    \n",
    "    if confirmed:\n",
    "        # Add to command history\n",
    "        add_to_command_history(updated_command)\n",
    "        \n",
    "        # Process according to intent\n",
    "        if updated_command[\"intent\"] == \"find_recipe\":\n",
    "            process_find_recipe_command(updated_command)\n",
    "        \n",
    "        elif updated_command[\"intent\"] == \"save_preference\":\n",
    "            result = process_save_preference_command(updated_command)\n",
    "            print(f\"\\n{result}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"\\nProcessed {updated_command['intent']} command.\")\n",
    "            print(\"This functionality will be implemented in a future step.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nCommand was cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d296c16",
   "metadata": {},
   "source": [
    "## Unified Voice and Text Interface\n",
    "\n",
    "Now let's create a unified interface that can handle both voice and text inputs. This simulates what we would implement in a real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be535fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_command_interface():\n",
    "    \"\"\"\n",
    "    Create an interactive voice command interface\n",
    "    \"\"\"\n",
    "    # Create a button to start recording\n",
    "    record_button = widgets.Button(\n",
    "        description='Start Recording',\n",
    "        disabled=False,\n",
    "        button_style='info', \n",
    "        tooltip='Start recording voice command',\n",
    "        icon='microphone'\n",
    "    )\n",
    "    \n",
    "    # Create an output widget to display results\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Define the recording function\n",
    "    def on_record_click(b):\n",
    "        # Change button appearance during recording\n",
    "        b.description = 'Recording...'\n",
    "        b.button_style = 'danger'\n",
    "        b.icon = 'circle'\n",
    "        \n",
    "        with output:\n",
    "            clear_output()\n",
    "            \n",
    "            # Record audio\n",
    "            audio_data, sample_rate = record_audio(duration=5)\n",
    "            \n",
    "            # Preprocess audio\n",
    "            audio_data = preprocess_audio(audio_data, sample_rate)\n",
    "            \n",
    "            # Convert speech to text\n",
    "            text, confidence = convert_speech_to_text(audio_data, sample_rate)\n",
    "            \n",
    "            if text:\n",
    "                # Process the command text\n",
    "                process_text_command(text)\n",
    "            else:\n",
    "                print(\"Sorry, I didn't catch that. Please try again.\")\n",
    "        \n",
    "        # Reset button appearance\n",
    "        b.description = 'Start Recording'\n",
    "        b.button_style = 'info'\n",
    "        b.icon = 'microphone'\n",
    "    \n",
    "    # Connect the button click to the recording function\n",
    "    record_button.on_click(on_record_click)\n",
    "    \n",
    "    # Display the widgets\n",
    "    display(record_button)\n",
    "    display(output)\n",
    "    \n",
    "    print(\"Click 'Start Recording' and speak your command.\")\n",
    "\n",
    "def process_find_recipe_command(command):\n",
    "    \"\"\"\n",
    "    Process a 'find_recipe' command and display matching recipes\n",
    "    \n",
    "    Args:\n",
    "        command (dict): The parsed command\n",
    "    \"\"\"\n",
    "    print(\"\\nSearching for recipes...\")\n",
    "    \n",
    "    # Start with all recipes\n",
    "    filtered_recipes = recipes_df.copy()\n",
    "    \n",
    "    # Filter by ingredients if specified\n",
    "    if command[\"ingredients\"]:\n",
    "        print(f\"Filtering for recipes with: {', '.join(command['ingredients'])}\")\n",
    "        \n",
    "        # For each specified ingredient, filter recipes that contain it\n",
    "        for ingredient in command[\"ingredients\"]:\n",
    "            # Create a pattern to match the ingredient in the ingredients list\n",
    "            ingredient_pattern = ingredient.lower()\n",
    "            \n",
    "            # Filter recipes where any ingredient matches the pattern\n",
    "            filtered_recipes = filtered_recipes[\n",
    "                filtered_recipes['ingredients'].apply(\n",
    "                    lambda ingredients: any(ingredient_pattern in ing.lower() for ing in ingredients)\n",
    "                    if isinstance(ingredients, list) else False\n",
    "                )\n",
    "            ]\n",
    "    \n",
    "    # Filter by dietary restrictions if specified\n",
    "    if command[\"dietary_restrictions\"]:\n",
    "        print(f\"Filtering for {', '.join(command['dietary_restrictions'])} recipes\")\n",
    "        \n",
    "        # For each specified restriction, filter recipes with that tag\n",
    "        for restriction in command[\"dietary_restrictions\"]:\n",
    "            # Create a pattern to match the restriction in the dietary_tags list\n",
    "            restriction_pattern = restriction.lower()\n",
    "            \n",
    "            # Filter recipes where any tag matches the pattern\n",
    "            filtered_recipes = filtered_recipes[\n",
    "                filtered_recipes['dietary_tags'].apply(\n",
    "                    lambda tags: any(restriction_pattern in tag.lower() for tag in tags)\n",
    "                    if isinstance(tags, list) else False\n",
    "                )\n",
    "            ]\n",
    "    \n",
    "    # Filter by cuisine type if specified\n",
    "    if command[\"cuisine_type\"]:\n",
    "        print(f\"Filtering for {command['cuisine_type']} cuisine\")\n",
    "        \n",
    "        # Filter recipes where cuisine_type matches\n",
    "        cuisine_pattern = command[\"cuisine_type\"].lower()\n",
    "        filtered_recipes = filtered_recipes[\n",
    "            filtered_recipes['cuisine_type'].apply(\n",
    "                lambda cuisine: cuisine_pattern in cuisine.lower() if cuisine else False\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # Filter by meal type if specified\n",
    "    if command[\"meal_type\"]:\n",
    "        print(f\"Filtering for {command['meal_type']} recipes\")\n",
    "        \n",
    "        # For this filter, we would ideally have a 'meal_type' column\n",
    "        # Since we might not have it in our dataset, we'll check if it exists first\n",
    "        if 'meal_type' in filtered_recipes.columns:\n",
    "            meal_pattern = command[\"meal_type\"].lower()\n",
    "            filtered_recipes = filtered_recipes[\n",
    "                filtered_recipes['meal_type'].apply(\n",
    "                    lambda meal: meal_pattern in meal.lower() if meal else False\n",
    "                )\n",
    "            ]\n",
    "        # If no meal_type column, we could try to infer from title or other fields\n",
    "        else:\n",
    "            # Look for meal type in recipe title as a simple approach\n",
    "            meal_pattern = command[\"meal_type\"].lower()\n",
    "            filtered_recipes = filtered_recipes[\n",
    "                filtered_recipes['title'].apply(\n",
    "                    lambda title: meal_pattern in title.lower() if title else False\n",
    "                )\n",
    "            ]\n",
    "    \n",
    "    # Filter by cooking time if specified\n",
    "    if command[\"cooking_time\"]:\n",
    "        print(f\"Filtering for recipes that are {command['cooking_time']}\")\n",
    "        \n",
    "        # Convert cooking time description to numeric filter\n",
    "        time_desc = command[\"cooking_time\"].lower()\n",
    "        \n",
    "        if 'cooking_time' in filtered_recipes.columns:\n",
    "            if \"quick\" in time_desc or \"fast\" in time_desc or \"under 30\" in time_desc or \"less than 30\" in time_desc:\n",
    "                filtered_recipes = filtered_recipes[filtered_recipes['cooking_time'] <= 30]\n",
    "            elif \"hour\" in time_desc:\n",
    "                filtered_recipes = filtered_recipes[filtered_recipes['cooking_time'] >= 60]\n",
    "    \n",
    "    # Display results\n",
    "    if len(filtered_recipes) > 0:\n",
    "        print(f\"\\nFound {len(filtered_recipes)} matching recipes:\")\n",
    "        \n",
    "        # Display the top 5 recipes (or all if less than 5)\n",
    "        top_recipes = filtered_recipes.head(min(5, len(filtered_recipes)))\n",
    "        \n",
    "        for i, (_, recipe) in enumerate(top_recipes.iterrows()):\n",
    "            print(f\"\\n{i+1}. {recipe['title']}\")\n",
    "            \n",
    "            # Display ingredients if available\n",
    "            if 'ingredients' in recipe and isinstance(recipe['ingredients'], list):\n",
    "                print(f\"   Ingredients: {', '.join(recipe['ingredients'][:5])}\" + \n",
    "                      (f\" and {len(recipe['ingredients']) - 5} more\" if len(recipe['ingredients']) > 5 else \"\"))\n",
    "            \n",
    "            # Display cuisine type if available\n",
    "            if 'cuisine_type' in recipe and recipe['cuisine_type']:\n",
    "                print(f\"   Cuisine: {recipe['cuisine_type']}\")\n",
    "            \n",
    "            # Display cooking time if available\n",
    "            if 'cooking_time' in recipe and recipe['cooking_time']:\n",
    "                print(f\"   Cooking Time: {recipe['cooking_time']} minutes\")\n",
    "            \n",
    "            # Display dietary tags if available\n",
    "            if 'dietary_tags' in recipe and isinstance(recipe['dietary_tags'], list) and recipe['dietary_tags']):\n",
    "                print(f\"   Dietary Tags: {', '.join(recipe['dietary_tags'])}\")\n",
    "        \n",
    "        if len(filtered_recipes) > 5:\n",
    "            print(f\"\\n... and {len(filtered_recipes) - 5} more recipes.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nNo matching recipes found.\")\n",
    "        \n",
    "        # Provide suggestions for broadening the search\n",
    "        print(\"\\nTry broadening your search by:\")\n",
    "        if command[\"ingredients\"]:\n",
    "            print(\"- Using fewer ingredients\")\n",
    "        if command[\"dietary_restrictions\"]:\n",
    "            print(\"- Removing some dietary restrictions\")\n",
    "        if command[\"cuisine_type\"]:\n",
    "            print(\"- Trying a different cuisine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae94771",
   "metadata": {},
   "source": [
    "## Complete Workflow: Audio to Action\n",
    "\n",
    "Let's demonstrate the full workflow from audio input to action execution with a complete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_complete_workflow():\n",
    "    \"\"\"\n",
    "    Demonstrate the complete workflow from audio input to action execution\n",
    "    \"\"\"\n",
    "    print(\"===== COMPLETE WORKFLOW DEMONSTRATION =====\")\n",
    "    print(\"\\nThis example shows the entire process from audio input to action execution.\")\n",
    "    \n",
    "    # Step 1: Simulate audio recording\n",
    "    print(\"\\n1. Recording audio...\")\n",
    "    audio_data, sample_rate = record_audio(duration=3)\n",
    "    \n",
    "    # Visualize the audio waveform (simplified for demonstration)\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.plot(audio_data)\n",
    "    plt.title(\"Audio Waveform\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Step 2: Preprocess audio\n",
    "    print(\"\\n2. Preprocessing audio...\")\n",
    "    preprocessed_audio = preprocess_audio(audio_data, sample_rate)\n",
    "    \n",
    "    # Step 3: Speech-to-text conversion\n",
    "    print(\"\\n3. Converting speech to text...\")\n",
    "    # Use a predefined example for demonstration clarity\n",
    "    text = \"Find me a vegetarian recipe with pasta and tomatoes that takes less than 30 minutes\"\n",
    "    confidence = 0.95\n",
    "    print(f\"Transcribed text: '{text}' (confidence: {confidence:.2f})\")\n",
    "    \n",
    "    # Step 4: Parse command\n",
    "    print(\"\\n4. Parsing command...\")\n",
    "    command = parse_command_with_gemini(text)\n",
    "    \n",
    "    # Print structured command representation\n",
    "    print(\"\\nStructured command representation:\")\n",
    "    print(json.dumps(command, indent=2))\n",
    "    \n",
    "    # Step 5: Confirm command\n",
    "    print(\"\\n5. Confirming command...\")\n",
    "    confirmation_message = generate_confirmation_message(command)\n",
    "    print(f\"Confirmation: {confirmation_message}\")\n",
    "    print(\"User: Yes, that's correct.\")\n",
    "    \n",
    "    # Step 6: Execute command\n",
    "    print(\"\\n6. Executing command...\")\n",
    "    if command[\"intent\"] == \"find_recipe\":\n",
    "        # Search for recipes\n",
    "        print(\"\\nSearching for recipes with the following criteria:\")\n",
    "        print(f\"- Ingredients: {', '.join(command['ingredients'])}\")\n",
    "        print(f\"- Dietary restrictions: {', '.join(command['dietary_restrictions'])}\")\n",
    "        print(f\"- Cooking time: {command['cooking_time']}\")\n",
    "        \n",
    "        # Display sample results\n",
    "        print(\"\\nFound 3 matching recipes:\")\n",
    "        print(\"1. Quick Vegetarian Pasta Primavera\")\n",
    "        print(\"   Ingredients: pasta, tomatoes, bell peppers, zucchini, olive oil\")\n",
    "        print(\"   Cooking Time: 25 minutes\")\n",
    "        print(\"   Dietary Tags: vegetarian\")\n",
    "        \n",
    "        print(\"2. Easy Tomato Basil Penne\")\n",
    "        print(\"   Ingredients: penne pasta, tomatoes, basil, garlic, olive oil\")\n",
    "        print(\"   Cooking Time: 20 minutes\")\n",
    "        print(\"   Dietary Tags: vegetarian, dairy-free\")\n",
    "        \n",
    "        print(\"3. 15-Minute Garlic Tomato Spaghetti\")\n",
    "        print(\"   Ingredients: spaghetti, cherry tomatoes, garlic, olive oil, red pepper flakes\")\n",
    "        print(\"   Cooking Time: 15 minutes\")\n",
    "        print(\"   Dietary Tags: vegetarian, dairy-free\")\n",
    "    \n",
    "    # Step 7: Update user preferences\n",
    "    print(\"\\n7. Updating user preferences...\")\n",
    "    # Add command to history\n",
    "    add_to_command_history(command)\n",
    "    print(\"Command added to history\")\n",
    "    \n",
    "    # Update dietary preferences if specified\n",
    "    if command[\"dietary_restrictions\"]:\n",
    "        for pref in command[\"dietary_restrictions\"]:\n",
    "            update_user_preference(\"dietary_preferences\", pref)\n",
    "        print(f\"Updated dietary preferences: {', '.join(command['dietary_restrictions'])}\")\n",
    "    \n",
    "    print(\"\\nWorkflow demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323aa7c",
   "metadata": {},
   "source": [
    "## Demonstrate Complete Workflow\n",
    "\n",
    "Run the cell below to see a demonstration of the complete workflow from audio input to action execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d6776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the complete workflow\n",
    "demonstrate_complete_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311fd044",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've completed Step 2 of our Interactive Recipe & Kitchen Management Assistant:\n",
    "\n",
    "1. Implemented audio processing and integration with Google Cloud Speech-to-Text API\n",
    "2. Created a command parsing system to extract user intent and entities\n",
    "3. Developed a confirmation flow to verify understood commands\n",
    "4. Built a user preference storage system that maintains dietary preferences and command history\n",
    "5. Created a unified interface that supports both voice and text inputs\n",
    "\n",
    "We've demonstrated the **Audio understanding** Gen AI capability by:\n",
    "- Converting speech to text using Google Cloud Speech-to-Text\n",
    "- Parsing natural language commands to extract structured information\n",
    "- Confirming the system's understanding with the user\n",
    "- Taking appropriate actions based on understood commands\n",
    "\n",
    "**Next steps:**\n",
    "- Step 3: Implement few-shot prompting for recipe customization\n",
    "- Step 4: Create RAG implementation for recipe knowledge retrieval\n",
    "- Step 5: Develop function calling capabilities for specific recipe operations\n",
    "\n",
    "This audio and command recognition system will serve as the foundation for user interaction in our recipe assistant, allowing natural language queries and commands to control the more advanced AI capabilities we'll implement in subsequent steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49caee",
   "metadata": {},
   "source": [
    "## Notes on Kaggle Environment Adaptation\n",
    "\n",
    "This notebook has been adapted to work well in the Kaggle environment, which has several limitations for audio processing:\n",
    "\n",
    "1. **No microphone access**: Kaggle notebooks run in a containerized environment without access to microphone hardware\n",
    "2. **Limited system library installation**: Installing system dependencies like PortAudio is problematic\n",
    "3. **Focus on batch processing**: Kaggle is optimized for data science workflows, not real-time audio applications\n",
    "\n",
    "Our adaptation strategy:\n",
    "- Use pre-recorded or synthetic audio samples instead of live recording\n",
    "- Simulate the speech-to-text conversion that would normally use Google Cloud API\n",
    "- Provide a dropdown to select commands rather than speaking them\n",
    "- Focus on demonstrating the workflow and Gen AI capabilities, despite the platform limitations\n",
    "\n",
    "In a production environment running on a system with microphone access and proper API credentials, this code could be easily adapted to use real audio input with minimal changes."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7066345,
     "sourceId": 11299813,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 232261049,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
