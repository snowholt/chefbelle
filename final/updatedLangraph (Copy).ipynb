{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039544d8-09aa-41e7-973e-f68c8450c031",
   "metadata": {},
   "source": [
    "Okay, let's refine the `langraph.ipynb` notebook step-by-step to address the issues and improve the agent's capabilities and testing.\n",
    "\n",
    "**Goal:** Enhance the Kitchen Assistant agent by improving the system prompt, fixing visualization integration, creating coherent test scenarios, and ensuring overall code quality and robustness.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b678931c-6806-4dcd-8cd0-62dd16bcba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "from typing import Annotated, Any, Dict, List, Literal, Optional, Sequence, Tuple # Combined typing imports\n",
    "# Third-Party Imports\n",
    "import chromadb\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import Image, Markdown, clear_output, display # Combined IPython imports\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "from collections import defaultdict # Import defaultdict for aggregation node later\n",
    "\n",
    "# Langchain/LangGraph Imports (ensure these are covered in Step 0/1)\n",
    "from langchain_core.tools import tool\n",
    "#from langchain_google_community import GoogleSearchAPIWrapper # For google_search tool\n",
    "# Assuming llm is initialized in Step 2 and KitchenState in Step 1\n",
    "\n",
    "# LangChain/LangGraph Imports\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage # Combined messages import\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import END, START, StateGraph # Combined graph imports\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Google Gemini API for natural language understanding\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.api_core import retry\n",
    "# Assuming KitchenState is defined elsewhere\n",
    "\n",
    "# --- Database/Vector Store Paths ---\n",
    "VECTOR_DB_PATH = \"final/vector_db\"\n",
    "DB_PATH = \"final/kitchen_db.sqlite\"\n",
    "# --- End Paths ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "502bb3eb-945e-48ec-8584-08dc262a1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(service=\"openai\", file_path=None, language=\"en\", api_key=None, credentials_path=None, credentials_json=None):\n",
    "    \"\"\"\n",
    "    Transcribe audio using either OpenAI or Google Cloud Speech-to-Text API.\n",
    "    \n",
    "    Args:\n",
    "        service (str): The service to use for transcription ('openai' or 'google')\n",
    "        file_path (str): Path to the audio file to transcribe\n",
    "        language (str): Language code (e.g., 'en' for OpenAI, 'en-US' for Google)\n",
    "        api_key (str): OpenAI API key (required for OpenAI service)\n",
    "        credentials_path (str): Path to Google credentials JSON file (optional for Google service)\n",
    "        credentials_json (str): JSON string of Google credentials (optional for Google service)\n",
    "        \n",
    "    Returns:\n",
    "        str: Transcription text or error message\n",
    "    \"\"\"\n",
    "    \n",
    "    if not file_path:\n",
    "        return \"Error: No file path provided\"\n",
    "        \n",
    "    if not os.path.exists(file_path):\n",
    "        return f\"Error: File not found at {file_path}\"\n",
    "    \n",
    "    try:\n",
    "        if service.lower() == \"openai\":\n",
    "            if not api_key:\n",
    "                return \"Error: OpenAI API key required\"\n",
    "                \n",
    "            client = OpenAI(api_key=api_key)\n",
    "            \n",
    "            with open(file_path, \"rb\") as audio_file:\n",
    "                transcription = client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\", \n",
    "                    file=audio_file,\n",
    "                    language=language\n",
    "                )\n",
    "            \n",
    "            return transcription.text\n",
    "            \n",
    "        elif service.lower() == \"google\":\n",
    "            temp_cred_file = None\n",
    "            \n",
    "            # Handle Google authentication\n",
    "            if not credentials_path and not credentials_json:\n",
    "                return \"Error: Either credentials_path or credentials_json required for Google service\"\n",
    "            \n",
    "            # If credentials_json is provided, write to a temporary file\n",
    "            if credentials_json:\n",
    "                try:\n",
    "                    # Create a temporary file for credentials\n",
    "                    temp_cred_file = tempfile.NamedTemporaryFile(delete=False, suffix='.json')\n",
    "                    temp_cred_path = temp_cred_file.name\n",
    "                    temp_cred_file.write(credentials_json.encode('utf-8'))\n",
    "                    temp_cred_file.close()\n",
    "                    \n",
    "                    # Set environment variable to the temporary file\n",
    "                    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = temp_cred_path\n",
    "                except Exception as e:\n",
    "                    if temp_cred_file and os.path.exists(temp_cred_file.name):\n",
    "                        os.unlink(temp_cred_file.name)\n",
    "                    return f\"Error creating temporary credentials file: {str(e)}\"\n",
    "            else:\n",
    "                # Use provided credentials_path\n",
    "                os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "            \n",
    "            try:\n",
    "                # Initialize the Speech client\n",
    "                client = speech.SpeechClient()\n",
    "                \n",
    "                # Read the audio file\n",
    "                with io.open(file_path, \"rb\") as audio_file:\n",
    "                    content = audio_file.read()\n",
    "                \n",
    "                # Determine encoding based on file extension\n",
    "                file_ext = os.path.splitext(file_path)[1].lower()\n",
    "                if file_ext == \".ogg\":\n",
    "                    encoding = speech.RecognitionConfig.AudioEncoding.OGG_OPUS\n",
    "                elif file_ext == \".wav\":\n",
    "                    encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "                else:\n",
    "                    return f\"Error: Unsupported file format: {file_ext}\"\n",
    "                \n",
    "                # Configure the speech recognition\n",
    "                audio = speech.RecognitionAudio(content=content)\n",
    "                config = speech.RecognitionConfig(\n",
    "                    encoding=encoding,\n",
    "                    sample_rate_hertz=48000,  # May need adjustment based on actual audio file\n",
    "                    language_code=language if language else \"en-US\",\n",
    "                )\n",
    "                \n",
    "                # Perform the transcription\n",
    "                response = client.recognize(config=config, audio=audio)\n",
    "                \n",
    "                # Extract the transcription\n",
    "                if response.results:\n",
    "                    return response.results[0].alternatives[0].transcript\n",
    "                else:\n",
    "                    return \"No transcription results found\"\n",
    "                    \n",
    "            finally:\n",
    "                # Clean up temp file if it was created\n",
    "                if temp_cred_file and os.path.exists(temp_cred_file.name):\n",
    "                    os.unlink(temp_cred_file.name)\n",
    "        \n",
    "        else:\n",
    "            return f\"Error: Unknown service '{service}'. Use 'openai' or 'google'\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Clean up temp file if exception occurs\n",
    "        if service.lower() == \"google\" and temp_cred_file and os.path.exists(temp_cred_file.name):\n",
    "            os.unlink(temp_cred_file.name)\n",
    "        return f\"Error during transcription: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cef5527-1e81-454e-b0e9-5c1ba51530cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key exists: True\n",
      "OpenAI API Key exists: True\n",
      "SecretValueJson API Key exists: True\n"
     ]
    }
   ],
   "source": [
    "# Import the os module to access environment variables\n",
    "\n",
    "# Access environment variables\n",
    "def get_api_key(key_name):\n",
    "    \"\"\"\n",
    "    Retrieve an API key from environment variables.\n",
    "    \n",
    "    Args:\n",
    "        key_name (str): The name of the environment variable containing the API key\n",
    "        \n",
    "    Returns:\n",
    "        str: The API key or None if it doesn't exist\n",
    "    \"\"\"\n",
    "    api_key = os.environ.get(key_name)\n",
    "    \n",
    "    if api_key is None:\n",
    "        print(f\"Warning: {key_name} environment variable not found.\")\n",
    "    \n",
    "    return api_key\n",
    "\n",
    "# Example usage\n",
    "GOOGLE_API_KEY = get_api_key(\"GOOGLE_API_KEY\")\n",
    "OPENAI_API_KEY = get_api_key(\"OPENAI_API_KEY\")\n",
    "SecretValueJson=get_api_key(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "# Check if keys exist\n",
    "print(f\"Google API Key exists: {GOOGLE_API_KEY is not None}\")\n",
    "print(f\"OpenAI API Key exists: {OPENAI_API_KEY is not None}\")\n",
    "print(f\"SecretValueJson API Key exists: {SecretValueJson is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0992c5bd-9c26-43be-adbd-a4e21283f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 1: State Schema Defined\n"
     ]
    }
   ],
   "source": [
    "# Step 1: State Schema (`KitchenState`)**\n",
    "\n",
    "from typing import Annotated, Any, Dict, List, Literal, Optional, Sequence, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage #add_messages\n",
    "from collections import defaultdict\n",
    "\n",
    "class KitchenState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the conversation and actions within the\n",
    "    Interactive Recipe & Kitchen Management Assistant agent.\n",
    "    Follows a standard LangGraph pattern where tool results are processed\n",
    "    from ToolMessages by the parser node.\n",
    "\n",
    "    Attributes:\n",
    "        messages: The history of messages (human, AI, tool). Tool results appear here.\n",
    "        user_input: The latest raw input from the user (text or transcribed audio).\n",
    "        intent: The determined intent (used for routing custom logic like customization).\n",
    "        selected_recipe_id: The ID of the recipe currently in context.\n",
    "        customization_request: Details of a requested recipe customization.\n",
    "        nutrition_query: The ingredient name for a specific nutrition lookup.\n",
    "        grounding_query: A specific question requiring web search grounding.\n",
    "        current_recipe_details: Parsed details of the recipe after get_recipe_by_id runs.\n",
    "        recipe_reviews: Parsed ratings and reviews after get_ratings_and_reviews runs.\n",
    "        ingredient_nutrition_list: Temp storage for results from fetch_nutrition_from_openfoodfacts.\n",
    "        nutritional_info: Aggregated/final nutritional info prepared for display.\n",
    "        grounding_results_formatted: Formatted web search results prepared for display.\n",
    "        user_ingredients: A list of ingredients the user currently has available.\n",
    "        dietary_preferences: The user's specified dietary restrictions or preferences.\n",
    "        needs_clarification: Flag indicating if the agent requires more information.\n",
    "        finished: Flag indicating if the conversation/task is complete.\n",
    "        last_assistant_response: The last text response generated by the assistant for UI display.\n",
    "        audio_file_path: Path to the audio file if input was voice.\n",
    "    \"\"\"\n",
    "    # Conversation history (Human, AI, Tool messages)\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "    # User's raw input (text or transcribed audio)\n",
    "    user_input: Optional[str]\n",
    "    audio_file_path: Optional[str] # Added for voice input tracking\n",
    "\n",
    "    # Parsed intent & parameters (primarily for routing non-tool actions or context)\n",
    "    intent: Optional[str] # e.g., 'customize', 'aggregate_nutrition', 'general_chat', 'exit'\n",
    "    selected_recipe_id: Optional[str]\n",
    "    customization_request: Optional[str]\n",
    "    nutrition_query: Optional[str] # For single ingredient lookup\n",
    "    grounding_query: Optional[str] # For web search (now handled internally by LLM)\n",
    "\n",
    "    # Parsed/Aggregated data stored after processing ToolMessages\n",
    "    current_recipe_details: Optional[Dict[str, Any]] # Parsed from get_recipe_by_id ToolMessage\n",
    "    recipe_reviews: Optional[Dict[str, Any]] # Parsed from get_ratings_and_reviews ToolMessage\n",
    "    ingredient_nutrition_list: Optional[List[Dict[str, Any]]] # Temp storage from fetch_nutrition ToolMessages\n",
    "    nutritional_info: Optional[Dict[str, Any]] # Aggregated/formatted nutrition data\n",
    "    grounding_results_formatted: Optional[str] # Formatted search results (less likely needed now)\n",
    "\n",
    "    # User Context (Could be loaded/persisted separately)\n",
    "    user_ingredients: List[str]\n",
    "    dietary_preferences: List[str]\n",
    "\n",
    "    # Control Flow\n",
    "    needs_clarification: bool\n",
    "    finished: bool\n",
    "    last_assistant_response: Optional[str] # Store the last text response for UI\n",
    "\n",
    "# Initialize the state (optional, for testing/default values)\n",
    "initial_state: KitchenState = {\n",
    "    \"messages\": [],\n",
    "    \"user_input\": None,\n",
    "    \"audio_file_path\": None,\n",
    "    \"intent\": None,\n",
    "    \"selected_recipe_id\": None,\n",
    "    \"customization_request\": None,\n",
    "    \"nutrition_query\": None,\n",
    "    \"grounding_query\": None,\n",
    "    \"current_recipe_details\": None,\n",
    "    \"recipe_reviews\": None,\n",
    "    \"ingredient_nutrition_list\": None,\n",
    "    \"nutritional_info\": None,\n",
    "    \"grounding_results_formatted\": None,\n",
    "    \"user_ingredients\": [],\n",
    "    \"dietary_preferences\": [],\n",
    "    \"needs_clarification\": False,\n",
    "    \"finished\": False,\n",
    "    \"last_assistant_response\": None,\n",
    "}\n",
    "\n",
    "print(\"✅ LangGraph Step 1: State Schema Defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb6e84-cfd9-4051-a5c6-da0efae55f0d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Step 2: System Instructions & Core Nodes (Revised)**\n",
    "\n",
    "*   **Prompt (`KITCHEN_ASSISTANT_SYSINT`):** Significantly enhanced for clarity, context management, error handling, and the specific nutrition workflow. Added instructions on retaining context (`selected_recipe_id`).\n",
    "*   **`input_parser_node`:**\n",
    "    *   Refined aggregation detection: It now checks if the *previous* AI message requested nutrition *and* the current input consists of `ToolMessage` results for `fetch_nutrition_from_openfoodfacts`.\n",
    "    *   Improved state clearing: Explicitly preserves `selected_recipe_id` and `current_recipe_details` unless a new search/selection occurs.\n",
    "    *   Added handling for potential LLM errors or empty responses.\n",
    "*   **`response_formatter_node`:**\n",
    "    *   Defined a constant `NUTRITION_RESPONSE_HEADER` for consistency.\n",
    "    *   Improved logic to fetch recipe name for the nutrition summary.\n",
    "    *   Ensured the final formatted response is added as an `AIMessage` to the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b595173b-c852-48ee-a4be-7ed1d38e0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph Step 2: System Instructions & Base LLM Initialization (Corrected)\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.genai import types # Ensure this is imported (likely in first cell)\n",
    "\n",
    "# --- Constants ---\n",
    "NUTRITION_RESPONSE_HEADER = \"Here's the approximate average nutrition per 100g for ingredients in\" # Used by formatter and routing\n",
    "\n",
    "# --- System Instructions (Revised for Native Grounding & Context) ---\n",
    "KITCHEN_ASSISTANT_SYSINT = (\n",
    "    \"system\",\n",
    "    \"\"\"You are a helpful, friendly, and knowledgeable Interactive Recipe & Kitchen Management Assistant.\n",
    "Your goal is to understand the user's request, use the available tools effectively, process the results, manage conversation context, and provide a clear, concise, and helpful response.\n",
    "\n",
    "**Core Principles:**\n",
    "- **Be Conversational:** Engage naturally, ask clarifying questions when needed.\n",
    "- **Maintain Context:** Remember the `selected_recipe_id` and `current_recipe_details` from previous turns unless the user starts a new search or explicitly asks about a different recipe.\n",
    "- **Use Tools Appropriately:** Choose the best tool for the job based on the user's request and the tool descriptions. Only call tools listed below.\n",
    "- **Handle Errors Gracefully:** If a tool fails or returns an error, inform the user politely and suggest alternatives (e.g., \"Sorry, I couldn't fetch the reviews right now. Would you like recipe details instead?\"). Do not expose raw error messages unless specifically instructed.\n",
    "- **Summarize Tool Results:** When you receive `ToolMessage` results, process their content (parse JSON if needed), update your understanding, and generate a user-facing summary or answer. Don't just repeat the raw tool output.\n",
    "\n",
    "**Capabilities & Tool Usage Guide:**\n",
    "\n",
    "- **Recipe Discovery (`gemini_recipe_similarity_search`):**\n",
    "    - Use when the user asks for recipe ideas (e.g., \"find chicken recipes\", \"vegetarian pasta ideas\").\n",
    "    - Extract keywords, cuisine, dietary needs (vegetarian, vegan, gluten-free, low-carb, dairy-free), max cooking time.\n",
    "    - **Ask for clarification** if the request is too vague (e.g., \"What kind of recipes are you looking for?\").\n",
    "    - **Arguments:** `query_text` (required), `n_results` (required, default 5), `cuisine` (optional), `dietary_tag` (optional), `max_minutes` (optional).\n",
    "    - **Action:** Call the tool. Summarize the results list clearly, including name, time, and ID. Ask the user if they want details on a specific one.\n",
    "\n",
    "- **Recipe Details (`get_recipe_by_id`):**\n",
    "    - Use when the user asks for details about a *specific* recipe identified by its ID (e.g., \"tell me about recipe 12345\") OR refers to a recipe from a list you just provided (e.g., \"get details for the second one\", \"tell me more about the pasta recipe\").\n",
    "    - **Requires `recipe_id`.**\n",
    "    - **IMPORTANT CONTEXT RULE:** If the user refers to an item from a list you *just* showed them in your *immediately preceding message* (like 'the second one', 'the first', 'the one with chicken'), you **MUST** look at your last response in the message history. Find the list you presented, identify the item the user is referring to (e.g., 'second' = 2nd item), extract its `recipe_id`, and use that ID for the tool call.\n",
    "    - **Example:** If your last message was \"Here are recipes: 1. Soup A (ID: 101), 2. Soup B (ID: 102)\" and the user says \"Tell me about the second one\", you MUST call `get_recipe_by_id` with `recipe_id=\"102\"`.\n",
    "    - **If you cannot find the ID this way** (e.g., your last message wasn't a list, or the reference is unclear), **DO NOT apologize or guess.** You MUST **ASK** the user to provide the specific recipe ID they want details for.\n",
    "    - If a `selected_recipe_id` is already clearly established from previous turns (and you didn't just show a new list), use that ID unless the user explicitly asks about a different one.\n",
    "    - **Action:** Call the tool with the determined `recipe_id`. Summarize the key details (name, description, time, ingredients, steps). Update `current_recipe_details` and `selected_recipe_id` in the state.\n",
    "\n",
    "- **Ratings & Reviews (`get_ratings_and_reviews_by_recipe_id`):**\n",
    "    - Use when the user asks for reviews or ratings for a *specific* recipe.\n",
    "    - **Requires `recipe_id`.** Use the `selected_recipe_id` from the current context if available, otherwise ask.\n",
    "    - **Requires `limit` (integer, default 3).** Extract the requested number or use the default.\n",
    "    - **Action:** Call the tool. Summarize the overall rating and the recent reviews.\n",
    "\n",
    "- **Ingredient Nutrition (`fetch_nutrition_from_openfoodfacts`):**\n",
    "    - Use *only* when the user asks for nutrition of a *single, specific ingredient* (e.g., \"nutrition facts for flour\", \"how many calories in an egg?\").\n",
    "    - **Do NOT use this for full recipe nutrition analysis.**\n",
    "    - **Requires `ingredient_name`.**\n",
    "    - **Action:** Call the tool. Present the key nutritional facts found (calories, fat, carbs, protein per 100g).\n",
    "\n",
    "- **Recipe Nutrition Analysis (Multi-Step Flow):**\n",
    "    - Use when the user asks for the nutritional information of a *full recipe* currently in context (e.g., \"what's the nutrition for this recipe?\", \"analyze nutrition for recipe 12345\").\n",
    "    - **Step 1: Ensure Recipe Details are Available.** If `current_recipe_details` for the `selected_recipe_id` are not in the state, first call `get_recipe_by_id`.\n",
    "    - **Step 2: Identify Ingredients.** Once details are available, extract the `normalized_ingredients` list from `current_recipe_details`.\n",
    "    - **Step 3: Generate Multiple Tool Calls.** Create *separate* `tool_calls` to `fetch_nutrition_from_openfoodfacts` for *each* ingredient in the `normalized_ingredients` list.\n",
    "    - **Step 4: Wait for Aggregation.** The system will execute these calls and provide results via `ToolMessage`s. The *next* node (`AggregateNutritionNode`) will process these. Your job here is *only* to make the tool calls.\n",
    "    - **Step 5: Present Aggregated Results.** After the aggregation node runs, you will receive the final aggregated `nutritional_info` in the state. Your final task in a *subsequent* turn is to present this summary clearly to the user (e.g., \"Here's the approximate average nutrition per 100g for the ingredients...\"). Do not attempt to calculate or present nutrition before the aggregation step is complete.\n",
    "\n",
    "- **Recipe Customization (`customize_recipe` - Placeholder):**\n",
    "    - Use when the user asks to modify the recipe in context (e.g., \"make this vegan\", \"substitute chicken for tofu\", \"can I make this gluten-free?\").\n",
    "    - **Requires `recipe_id` (use context or ask) and `customization_request` (the user's specific change).**\n",
    "    - **Action:** Set `intent` to 'customize'. Call the `customize_recipe` tool. Present the suggested modifications from the tool's response.\n",
    "\n",
    "- **Grounding/General Questions (Using Built-in Search):**\n",
    "    - Use this capability for general cooking questions, definitions, techniques, or ingredient substitutions *not* tied to the specific recipe details in the database (e.g., \"what's the difference between baking soda and baking powder?\", \"how to properly chop an onion?\", \"substitute for buttermilk\", \"what can I use instead of zucchini in soupe au pistou?\").\n",
    "    - **IMPORTANT:** You **DO NOT** have a tool named `google_search` to call for this.\n",
    "    - **Action:** When you identify such a question, answer it directly in your response. Rely on your internal knowledge and built-in search/grounding capabilities to find the information. You can optionally mention that you looked it up, for example: \"Based on a quick search, a good substitute for zucchini is...\" or \"I found that the difference is...\". Generate a helpful, concise answer based on the information you find.\n",
    "\n",
    "**Conversation Flow:**\n",
    "1.  Analyze the latest human message and the current state (especially `selected_recipe_id` and your own previous messages). Check if context inference is needed for IDs.\n",
    "2.  Determine the user's intent and required parameters.\n",
    "3.  If a tool is needed, generate the appropriate `tool_calls`. Ensure context (`recipe_id`) is included if required by the tool (either explicitly given or inferred).\n",
    "4.  If multiple nutrition lookups are needed for a recipe, generate all `fetch_nutrition_from_openfoodfacts` calls in one go.\n",
    "5.  If no tool is needed (e.g., simple chat, greeting, general question requiring grounding), respond directly using your knowledge and built-in search.\n",
    "6.  If clarification is needed (e.g., missing `recipe_id`), ask the user. Set `needs_clarification` to True.\n",
    "7.  If you receive `ToolMessage` results, parse and summarize them for the user in your next response. Update relevant state fields like `current_recipe_details` or `recipe_reviews`.\n",
    "8.  If you receive aggregated `nutritional_info`, present it clearly.\n",
    "9.  If the user says goodbye or similar, set `intent` to 'exit' and respond politely.\n",
    "10. Format responses using Markdown for lists or emphasis where appropriate.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# --- LLM Initialization (CORRECTED) ---\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    convert_system_message_to_human=True,\n",
    "    # ---> CORRECTED THIS PART <---\n",
    "    generation_config=types.GenerateContentConfig( # Use generation_config\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())]\n",
    "    )\n",
    "    # safety_settings=[...] # Add safety settings if desired\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0ae6c3a-ddfe-4b43-a5ad-d9ea1242b9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 2: System Instructions & Core Nodes Defined (Revised)\n"
     ]
    }
   ],
   "source": [
    "# Tool binding happens in Step 3\n",
    "\n",
    "# --- Core Nodes (Revised) ---\n",
    "\n",
    "def input_parser_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parses user input or tool results using the LLM based on system instructions.\n",
    "    Determines intent, generates tool calls, handles chat responses, or triggers aggregation.\n",
    "    Preserves context like selected_recipe_id unless explicitly changed.\n",
    "    \"\"\"\n",
    "    print(\"---NODE: InputParserNode---\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else None\n",
    "    previous_ai_message: Optional[AIMessage] = None\n",
    "    for i in range(len(messages) - 2, -1, -1): # Look back for the last AI message\n",
    "        if isinstance(messages[i], AIMessage):\n",
    "            previous_ai_message = messages[i]\n",
    "            break\n",
    "\n",
    "    # --- Check if Aggregation is Needed (More Robust Check) ---\n",
    "    # Condition: The *previous* AI message requested nutrition lookups,\n",
    "    # *and* the *current* input is a ToolMessage for nutrition.\n",
    "    needs_aggregation = False\n",
    "    if isinstance(last_message, ToolMessage) and last_message.name == \"fetch_nutrition_from_openfoodfacts\":\n",
    "        if previous_ai_message and previous_ai_message.tool_calls:\n",
    "            # Check if the previous AI message *specifically* called the nutrition tool\n",
    "            made_nutrition_calls = any(\n",
    "                tc.get('name') == 'fetch_nutrition_from_openfoodfacts'\n",
    "                for tc in previous_ai_message.tool_calls\n",
    "            )\n",
    "            if made_nutrition_calls:\n",
    "                # Check if *all* messages since the last AI message are nutrition ToolMessages\n",
    "                # (This assumes tools run and return results before the next parser call)\n",
    "                all_nutrition_results = True\n",
    "                start_index = messages.index(previous_ai_message) + 1\n",
    "                if start_index < len(messages):\n",
    "                    for msg in messages[start_index:]:\n",
    "                        if not (isinstance(msg, ToolMessage) and msg.name == \"fetch_nutrition_from_openfoodfacts\"):\n",
    "                            all_nutrition_results = False\n",
    "                            break\n",
    "                else: # No messages after the AI message? Should not happen if tool calls were made.\n",
    "                    all_nutrition_results = False\n",
    "\n",
    "                if all_nutrition_results:\n",
    "                    needs_aggregation = True\n",
    "                    print(\"Detected nutrition tool results following specific request, setting intent to aggregate.\")\n",
    "\n",
    "    if needs_aggregation:\n",
    "        # Route directly to aggregation node without calling LLM again\n",
    "        # Preserve essential context from the current state\n",
    "        updates = {\n",
    "            \"intent\": \"aggregate_nutrition\",\n",
    "            \"messages\": [], # Prevent LLM re-processing tool results\n",
    "            \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "            \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "            # Keep other relevant fields if necessary\n",
    "        }\n",
    "        print(f\"Routing to aggregation. State updates: { {k:v for k,v in updates.items() if k != 'messages'} }\")\n",
    "        return updates\n",
    "    # --- End Aggregation Check ---\n",
    "\n",
    "       # --- Normal LLM Invocation ---\n",
    "    print(\"Proceeding with LLM invocation...\")\n",
    "    # Ensure llm_with_callable_tools is globally available (defined in Step 3) # <-- Updated comment\n",
    "    context_messages = [SystemMessage(content=KITCHEN_ASSISTANT_SYSINT[1])] + list(messages)\n",
    "    try:\n",
    "        # ---> MODIFY THIS LINE <---\n",
    "        ai_response: AIMessage = llm_with_callable_tools.invoke(context_messages) # <-- Use the re-bound LLM\n",
    "        print(f\"LLM Raw Response: {ai_response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Invocation Error: {e}\")\n",
    "        error_message = \"Sorry, I encountered an internal error trying to process that. Could you try rephrasing?\"\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=error_message)],\n",
    "            \"last_assistant_response\": error_message,\n",
    "            \"intent\": \"error\",\n",
    "            \"finished\": False,\n",
    "             # Preserve context even on error\n",
    "            \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "            \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        }\n",
    "\n",
    "\n",
    "    # Prepare state updates based on LLM response\n",
    "    updates = {\n",
    "        \"messages\": [ai_response],\n",
    "        \"intent\": \"general_chat\", # Default intent\n",
    "        \"finished\": False, # Default finished state\n",
    "        \"last_assistant_response\": None, # Will be set by formatter or if direct response\n",
    "        \"needs_clarification\": False, # Default clarification state\n",
    "        # --- Context Preservation ---\n",
    "        # Keep existing context unless explicitly overwritten by this turn's actions\n",
    "        \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "        \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        \"recipe_reviews\": state.get(\"recipe_reviews\"), # Keep reviews unless new recipe selected\n",
    "        # --- Clear Transient Fields ---\n",
    "        \"ingredient_nutrition_list\": None,\n",
    "        \"nutritional_info\": None,\n",
    "        \"grounding_results_formatted\": None,\n",
    "        \"customization_request\": None, # Clear customization request after parsing\n",
    "    }\n",
    "\n",
    "    if ai_response.tool_calls:\n",
    "        updates[\"intent\"] = \"tool_call\" # Set intent for routing\n",
    "        print(f\"Intent: tool_call, Tool Calls: {ai_response.tool_calls}\")\n",
    "\n",
    "        # --- Context Management based on Tool Calls ---\n",
    "        new_search_initiated = any(tc.get('name') == 'gemini_recipe_similarity_search' for tc in ai_response.tool_calls)\n",
    "        getting_new_details = any(tc.get('name') == 'get_recipe_by_id' for tc in ai_response.tool_calls)\n",
    "\n",
    "        if new_search_initiated:\n",
    "            print(\"New recipe search detected, clearing previous recipe context.\")\n",
    "            updates[\"current_recipe_details\"] = None\n",
    "            updates[\"selected_recipe_id\"] = None\n",
    "            updates[\"recipe_reviews\"] = None\n",
    "            updates[\"nutritional_info\"] = None # Clear old nutrition if new search\n",
    "\n",
    "        # Store recipe ID if details, reviews, or customization is called for *this* recipe\n",
    "        for tc in ai_response.tool_calls:\n",
    "            tool_name = tc.get('name')\n",
    "            tool_args = tc.get('args', {})\n",
    "            recipe_id_arg = tool_args.get('recipe_id')\n",
    "\n",
    "            if tool_name in ['get_recipe_by_id', 'get_ratings_and_reviews_by_recipe_id', 'customize_recipe']:\n",
    "                if recipe_id_arg:\n",
    "                    # If the call specifies an ID different from current context, update context\n",
    "                    if recipe_id_arg != updates[\"selected_recipe_id\"]:\n",
    "                         print(f\"Tool call for new recipe ID '{recipe_id_arg}', updating context.\")\n",
    "                         updates[\"selected_recipe_id\"] = recipe_id_arg\n",
    "                         updates[\"current_recipe_details\"] = None # Clear old details\n",
    "                         updates[\"recipe_reviews\"] = None\n",
    "                         updates[\"nutritional_info\"] = None\n",
    "                    # If the call uses the *same* ID, context is already correct (or will be updated by get_recipe_by_id)\n",
    "                    elif tool_name == 'get_recipe_by_id':\n",
    "                         updates[\"selected_recipe_id\"] = recipe_id_arg # Ensure it's set\n",
    "\n",
    "            if tool_name == 'customize_recipe':\n",
    "                 updates[\"customization_request\"] = tool_args.get('request')\n",
    "                 updates[\"intent\"] = \"customize\" # Explicitly set intent for routing *after* parsing\n",
    "\n",
    "            # If multiple nutrition calls are made, the intent remains 'tool_call'\n",
    "            # The aggregation logic will handle them after execution.\n",
    "\n",
    "    elif ai_response.content:\n",
    "        # Handle direct text responses from LLM\n",
    "        updates[\"last_assistant_response\"] = ai_response.content # Store for potential direct use\n",
    "        content_lower = ai_response.content.lower()\n",
    "\n",
    "        # Determine intent based on LLM's textual response content\n",
    "        if \"need more details\" in content_lower or \"could you clarify\" in content_lower or \"which recipe\" in content_lower:\n",
    "            updates[\"intent\"] = \"clarification_needed\"\n",
    "            updates[\"needs_clarification\"] = True\n",
    "        elif \"goodbye\" in content_lower or \"exit\" in content_lower or \"bye\" in content_lower:\n",
    "            updates[\"intent\"] = \"exit\"\n",
    "            updates[\"finished\"] = True\n",
    "        # Check if the user explicitly quit (handle case where LLM confirms exit)\n",
    "        elif state.get(\"user_input\", \"\").lower() in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
    "             updates[\"intent\"] = \"exit\"\n",
    "             updates[\"finished\"] = True\n",
    "        else:\n",
    "            updates[\"intent\"] = \"general_chat\" # Default for text response\n",
    "\n",
    "        print(f\"Intent: {updates['intent']}, Response: {updates['last_assistant_response'][:100]}...\")\n",
    "\n",
    "    else:\n",
    "        # Handle LLM error or empty response (no tool calls, no content)\n",
    "        updates[\"intent\"] = \"error\"\n",
    "        error_message = \"Sorry, I had trouble processing that request. Can you please try again?\"\n",
    "        updates[\"last_assistant_response\"] = error_message\n",
    "        # Ensure error message is in history for the next turn\n",
    "        updates[\"messages\"] = [AIMessage(content=error_message)]\n",
    "        print(f\"Intent: error (Empty LLM response)\")\n",
    "\n",
    "    # Return only fields that have changed or are essential for the next step\n",
    "    valid_keys = KitchenState.__annotations__.keys()\n",
    "    # Filter out keys that are not in the state definition or haven't changed (except messages)\n",
    "    return {k: v for k, v in updates.items() if k in valid_keys and (k == 'messages' or state.get(k) != v)}\n",
    "\n",
    "\n",
    "def response_formatter_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Formats the final response for the user. Prioritizes aggregated nutrition\n",
    "    if available, otherwise uses the last AI message content or a default.\n",
    "    Adds the final formatted response as an AIMessage to history.\n",
    "    \"\"\"\n",
    "    print(\"---NODE: ResponseFormatterNode---\")\n",
    "    formatted_response = \"Okay, let me know how else I can help!\" # Default fallback\n",
    "    final_intent_for_history = state.get(\"intent\", \"general_chat\") # Capture intent before reset\n",
    "\n",
    "    # 1. Check for aggregated nutrition info first\n",
    "     # 1. Check for aggregated nutrition info first\n",
    "    if state.get(\"nutritional_info\"):\n",
    "        agg_info = state[\"nutritional_info\"]\n",
    "        # ---> ADD THIS LINE to get the counts dict from agg_info <---\n",
    "        nutrient_counts_from_state = agg_info.get(\"nutrient_counts\", {}) # Default to empty dict if missing\n",
    "\n",
    "        recipe_name = \"the recipe\"\n",
    "        recipe_id = state.get(\"selected_recipe_id\")\n",
    "        if state.get(\"current_recipe_details\"):\n",
    "            recipe_name = state[\"current_recipe_details\"].get(\"name\", f\"recipe {recipe_id}\" if recipe_id else \"the recipe\")\n",
    "        elif recipe_id:\n",
    "            recipe_name = f\"recipe {recipe_id}\"\n",
    "\n",
    "        response_lines = [f\"{NUTRITION_RESPONSE_HEADER} **{recipe_name}**:\"] # Use constant header\n",
    "        processed_count = agg_info.get('processed_ingredient_count', 0)\n",
    "\n",
    "        display_order = [\"calories_100g\", \"fat_100g\", \"saturated_fat_100g\", \"carbohydrates_100g\", \"sugars_100g\", \"fiber_100g\", \"proteins_100g\", \"sodium_100g\"]\n",
    "        has_data = False\n",
    "        for key in display_order:\n",
    "            # ---> MODIFY THIS LINE to use nutrient_counts_from_state <---\n",
    "            if key in agg_info and nutrient_counts_from_state.get(key, 0) > 0: # Check if data exists and was counted\n",
    "                 val = agg_info[key]\n",
    "                 unit = 'kcal' if 'calories' in key else ('mg' if 'sodium' in key else 'g')\n",
    "                 display_key = key.replace('_100g', '').replace('_', ' ').capitalize()\n",
    "                 # Convert sodium to mg for display\n",
    "                 display_val = f\"{val*1000:.1f}\" if key == 'sodium_100g' else f\"{val:.1f}\"\n",
    "                 response_lines.append(f\"- {display_key}: {display_val} {unit}\")\n",
    "                 has_data = True\n",
    "\n",
    "        if has_data and processed_count > 0:\n",
    "             response_lines.append(f\"\\n(Note: Based on average of {processed_count} ingredients with available data from Open Food Facts. Actual recipe nutrition will vary.)\")\n",
    "        elif processed_count > 0:\n",
    "             response_lines.append(\"\\n(Note: Could not retrieve detailed nutrition data for the ingredients, only partial information might be available.)\")\n",
    "        else:\n",
    "             response_lines.append(\"\\n(Note: Could not retrieve nutrition data for the ingredients.)\")\n",
    "\n",
    "        formatted_response = \"\\n\".join(response_lines)\n",
    "        final_intent_for_history = \"nutrition_presented\" # Specific intent for this case\n",
    "\n",
    "    # 2. If no nutrition info, use the last AI message content if available and meaningful\n",
    "    elif state.get(\"last_assistant_response\"):\n",
    "         # Use the response generated by the parser node if it exists\n",
    "         formatted_response = state[\"last_assistant_response\"]\n",
    "    elif state['messages'] and isinstance(state['messages'][-1], AIMessage) and state['messages'][-1].content:\n",
    "         # Fallback to the absolute last message if parser didn't set one\n",
    "         formatted_response = state['messages'][-1].content\n",
    "\n",
    "    # 3. Handle explicit exit intent if no other content generated\n",
    "    elif state.get(\"intent\") == \"exit\" or state.get(\"finished\"):\n",
    "        formatted_response = \"Okay, goodbye! Feel free to ask if you need recipes later.\"\n",
    "        final_intent_for_history = \"exit\"\n",
    "\n",
    "\n",
    "    print(f\"Formatted Response: {formatted_response[:100]}...\")\n",
    "\n",
    "    # Update state for the next turn or end\n",
    "    updates = {\n",
    "        \"last_assistant_response\": formatted_response,\n",
    "        \"intent\": None, # Reset intent after formatting\n",
    "        \"needs_clarification\": False, # Reset flag\n",
    "        # Add the final formatted response as an AIMessage to history\n",
    "        # This ensures it's captured correctly for the next turn or final output\n",
    "        \"messages\": [AIMessage(content=formatted_response, metadata={\"intent\": final_intent_for_history})],\n",
    "        # Clear transient data fields used to generate this response\n",
    "        \"nutritional_info\": None,\n",
    "        \"ingredient_nutrition_list\": None,\n",
    "        \"grounding_results_formatted\": None,\n",
    "        # Keep context fields unless explicitly cleared elsewhere\n",
    "        \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "        \"recipe_reviews\": state.get(\"recipe_reviews\"),\n",
    "        \"finished\": state.get(\"finished\", False) # Preserve finished flag if set\n",
    "    }\n",
    "\n",
    "    # Return only necessary updates\n",
    "    valid_keys = KitchenState.__annotations__.keys()\n",
    "    return {k: v for k, v in updates.items() if k in valid_keys and (k == 'messages' or state.get(k) != v)}\n",
    "\n",
    "\n",
    "# HumanInputNode definition (remains the same, bypassed by UI)\n",
    "def human_input_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"(Bypassed by UI Loop) Handles getting input from the user.\"\"\"\n",
    "    print(\"---NODE: HumanInputNode (Bypassed by UI)---\\\")\")\n",
    "    # ... (rest of the function remains the same) ...\n",
    "    user_input = input(f\"Assistant: {state.get('last_assistant_response', 'How can I help?')}\\\\nYou: \")\n",
    "    finished = False\n",
    "    if user_input.lower() in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
    "        finished = True\n",
    "        intent = \"exit\"\n",
    "    else:\n",
    "        intent = None # Let parser determine intent\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [HumanMessage(content=user_input)],\n",
    "        \"finished\": finished,\n",
    "        \"intent\": intent # Pass potential exit intent\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✅ LangGraph Step 2: System Instructions & Core Nodes Defined (Revised)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db84854-f6f8-480e-9875-8c47074c6594",
   "metadata": {},
   "source": [
    "**Step 3: Tool Definition & Integration (Revised)**\n",
    "\n",
    "*   **`gemini_recipe_similarity_search`:** Fixed the ChromaDB `where` clause logic to correctly handle multiple filters using `$and`. Added more robust error handling for ChromaDB queries.\n",
    "*   **`google_search`:** Kept the `langchain_google_community` implementation but added a more explicit error message if the API wrapper fails (likely due to missing API keys/CSE ID). For testing (in Step 8), we might need to mock this or handle the error gracefully.\n",
    "*   **`extract_and_visualize_nutrition`:** This function remains defined here but will be *called* by the `VisualizeNutritionNode` (defined in Step 4). No changes needed in this step's code for the function itself.\n",
    "*   **LLM Binding:** Ensured `llm_with_all_tools` is defined using the updated `all_tools_for_llm` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a648cfed-f04e-43fd-a7cf-454ca5244da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 3: Tools Defined and Bound (Revised - Native Grounding)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 3: Tool Definition & LLM Binding (Corrected for Native Grounding)\n",
    "\n",
    "import chromadb\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Langchain/LangGraph Imports\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "# from langchain_google_community import GoogleSearchAPIWrapper # <-- REMOVED\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # Assuming llm initialized in Step 2\n",
    "\n",
    "# --- Database/Vector Store Paths ---\n",
    "# VECTOR_DB_PATH = \"final/vector_db\"\n",
    "# DB_PATH = \"final/kitchen_db.sqlite\"\n",
    "# --- NUTRITION_RESPONSE_HEADER ---\n",
    "# NUTRITION_RESPONSE_HEADER = \"Here's the approximate average nutrition per 100g for ingredients in\"\n",
    "\n",
    "# --- Helper Function ---\n",
    "def safe_convert(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return \" \".join([str(item) for item in x])\n",
    "    return str(x) if pd.notna(x) else \"\"\n",
    "\n",
    "# --- Tool Definitions (google_search removed) ---\n",
    "\n",
    "@tool\n",
    "def gemini_recipe_similarity_search(query_text: str, n_results: int = 5, cuisine: Optional[str] = None, dietary_tag: Optional[str] = None, max_minutes: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    Searches for similar recipes based on a query text using vector embeddings.\n",
    "    Allows filtering by cuisine type, a specific dietary tag (e.g., 'vegetarian', 'gluten-free'),\n",
    "    and maximum cooking time in minutes. Returns a JSON string list of matching recipe summaries.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG TOOL CALL: gemini_recipe_similarity_search(query_text='{query_text}', n_results={n_results}, cuisine='{cuisine}', dietary_tag='{dietary_tag}', max_minutes={max_minutes})\")\n",
    "    try:\n",
    "        client = chromadb.PersistentClient(path=VECTOR_DB_PATH)\n",
    "        recipe_collection = client.get_collection(name=\"recipes\")\n",
    "\n",
    "        filter_dict = {}\n",
    "        if cuisine:\n",
    "            filter_dict[\"cuisine_type\"] = cuisine\n",
    "        if dietary_tag:\n",
    "            # Ensure dietary_tag is treated as a single tag to check for inclusion\n",
    "            # ChromaDB's $in expects a list of potential values for the field.\n",
    "            # If dietary_tags in metadata is a list, $in checks if any element matches.\n",
    "            # If dietary_tags is a string, this might need adjustment based on how tags are stored.\n",
    "            # Assuming tags are stored as a list or space-separated string that gets split:\n",
    "             filter_dict[\"dietary_tags\"] = {\"$in\": [dietary_tag]} # Check if the tag is IN the list/string\n",
    "        if max_minutes is not None:\n",
    "            try:\n",
    "                filter_dict[\"minutes\"] = {\"$lte\": int(max_minutes)}\n",
    "            except ValueError:\n",
    "                return json.dumps({\"error\": f\"Invalid max_minutes: '{max_minutes}'. Must be an integer.\"})\n",
    "\n",
    "        where_clause = None\n",
    "        if len(filter_dict) == 1:\n",
    "            where_clause = filter_dict\n",
    "        elif len(filter_dict) > 1:\n",
    "            # Correctly format $and clause for ChromaDB\n",
    "            and_conditions = [{field: condition} for field, condition in filter_dict.items()]\n",
    "            where_clause = {\"$and\": and_conditions}\n",
    "\n",
    "\n",
    "        print(f\"ChromaDB Where Clause: {where_clause}\")\n",
    "\n",
    "        results = recipe_collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=int(n_results),\n",
    "            where=where_clause,\n",
    "            include=[\"metadatas\", \"distances\"]\n",
    "        )\n",
    "\n",
    "        if not results or not results.get('ids') or not results['ids'][0]:\n",
    "            return json.dumps({\"status\": \"not_found\", \"message\": f\"No similar recipes found for '{query_text}' with the specified criteria.\"})\n",
    "\n",
    "        output_list = []\n",
    "        for metadata, distance in zip(results['metadatas'][0], results['distances'][0]):\n",
    "            similarity = round((1 - distance) * 100, 2) if distance is not None else None\n",
    "            tags = metadata.get('dietary_tags', '')\n",
    "            # Handle tags being stored as string or list\n",
    "            if isinstance(tags, str):\n",
    "                 tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()] # Example for comma-separated\n",
    "            elif isinstance(tags, (list, set)):\n",
    "                 tag_list = list(tags)\n",
    "            else:\n",
    "                 tag_list = []\n",
    "\n",
    "\n",
    "            output_list.append({\n",
    "                \"recipe_id\": str(metadata.get('recipe_id', 'N/A')),\n",
    "                \"name\": metadata.get('name', 'N/A'),\n",
    "                \"minutes\": metadata.get('minutes', 'N/A'),\n",
    "                \"cuisine_type\": metadata.get('cuisine_type', 'N/A'),\n",
    "                \"dietary_tags\": tag_list,\n",
    "                \"similarity_score\": similarity\n",
    "            })\n",
    "        return json.dumps(output_list, indent=2)\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "         print(f\"ERROR in gemini_recipe_similarity_search (DB Connection?): {e}\")\n",
    "         return json.dumps({\"error\": f\"Database connection error during recipe search: {e}\"})\n",
    "    except ImportError as e:\n",
    "         print(f\"ERROR in gemini_recipe_similarity_search (Import Error): {e}\")\n",
    "         return json.dumps({\"error\": f\"Missing library required for search: {e}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in gemini_recipe_similarity_search: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Provide more specific feedback if possible\n",
    "        if \"Expected where operator\" in str(e) or \"Unsupported operand\" in str(e):\n",
    "             return json.dumps({\"error\": f\"Error during recipe similarity search: Problem with filter criteria syntax or data type mismatch in database. Details: {e}\"})\n",
    "        return json.dumps({\"error\": f\"Error during recipe similarity search: {e}\"})\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_recipe_by_id(recipe_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves full details for a specific recipe given its ID from the SQL database.\n",
    "    Returns details as a JSON string. Includes 'normalized_ingredients' used for nutrition lookup.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG TOOL CALL: get_recipe_by_id(recipe_id='{recipe_id}')\")\n",
    "    try:\n",
    "        # Validate recipe_id format more robustly\n",
    "        if not isinstance(recipe_id, str) or not recipe_id.isdigit():\n",
    "             # Try converting if it looks like a number string\n",
    "             try:\n",
    "                 recipe_id_int = int(recipe_id)\n",
    "                 recipe_id = str(recipe_id_int) # Convert back to string if valid int\n",
    "             except (ValueError, TypeError):\n",
    "                  return json.dumps({\"status\": \"error\", \"message\": f\"Invalid recipe_id format: '{recipe_id}'. Must be a numeric string.\"})\n",
    "\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            conn.row_factory = sqlite3.Row\n",
    "            cursor = conn.cursor()\n",
    "            # Ensure using integer for SQL query if ID column is INTEGER\n",
    "            cursor.execute(\"SELECT id, name, minutes, contributor_id, submitted, tags, nutrition, n_steps, steps, description, ingredients, n_ingredients, dietary_tags, cuisine_type, normalized_ingredients FROM recipes WHERE id = ?\", (int(recipe_id),))\n",
    "            recipe_data = cursor.fetchone()\n",
    "\n",
    "            if not recipe_data:\n",
    "                return json.dumps({\"status\": \"not_found\", \"message\": f\"Recipe ID {recipe_id} not found.\"})\n",
    "\n",
    "            recipe_dict = dict(recipe_data)\n",
    "            # Ensure ID is string in the output dictionary\n",
    "            recipe_dict['id'] = str(recipe_dict['id'])\n",
    "\n",
    "            # Improved parsing for list-like fields\n",
    "            for field in [\"ingredients\", \"steps\", \"tags\", \"dietary_tags\", \"normalized_ingredients\", \"nutrition\"]:\n",
    "                 if field in recipe_dict and isinstance(recipe_dict[field], str):\n",
    "                     raw_value = recipe_dict[field].strip()\n",
    "                     parsed_value = None\n",
    "                     try:\n",
    "                         # Try parsing as JSON list/dict first\n",
    "                         if raw_value.startswith(('[', '{')) and raw_value.endswith((']', '}')):\n",
    "                             parsed_value = json.loads(raw_value)\n",
    "                         # Fallback: Try ast.literal_eval for Python literal lists/tuples\n",
    "                         elif raw_value.startswith(('(', '[')) and raw_value.endswith((')', ']')):\n",
    "                              import ast\n",
    "                              parsed_value = ast.literal_eval(raw_value)\n",
    "                         # Fallback: Split comma-separated strings for specific fields\n",
    "                         elif field in [\"tags\", \"dietary_tags\", \"normalized_ingredients\", \"ingredients\", \"steps\"]:\n",
    "                              parsed_value = [item.strip() for item in raw_value.split(',') if item.strip()]\n",
    "\n",
    "                         if parsed_value is not None:\n",
    "                              recipe_dict[field] = parsed_value\n",
    "                         # else: keep as string if no parsing method worked\n",
    "\n",
    "                     except (json.JSONDecodeError, SyntaxError, ValueError, TypeError) as parse_error:\n",
    "                          print(f\"Warning: Could not parse field '{field}' for recipe {recipe_id}. Keeping as string. Value: '{raw_value[:50]}...'. Error: {parse_error}\")\n",
    "                          # Keep the original string value if parsing fails\n",
    "\n",
    "            # Ensure normalized_ingredients is a list, default to empty list if missing/wrong type\n",
    "            if not isinstance(recipe_dict.get(\"normalized_ingredients\"), list):\n",
    "                 print(f\"Warning: 'normalized_ingredients' for recipe {recipe_id} is not a list or missing. Setting to empty list.\")\n",
    "                 recipe_dict[\"normalized_ingredients\"] = []\n",
    "\n",
    "\n",
    "            return json.dumps(recipe_dict, indent=2, default=str) # Use default=str for safety\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"ERROR in get_recipe_by_id (SQL): {e}\")\n",
    "        return json.dumps({\"error\": f\"Database error fetching recipe ID {recipe_id}: {e}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in get_recipe_by_id: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return json.dumps({\"error\": f\"Unexpected error fetching recipe ID {recipe_id}: {e}\"})\n",
    "\n",
    "@tool\n",
    "def get_ratings_and_reviews_by_recipe_id(recipe_id: str, limit: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves the overall average rating and the most recent reviews (up to 'limit')\n",
    "    for a given recipe ID from the SQL database. Requires a positive integer for 'limit'.\n",
    "    Returns data as a JSON string.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG TOOL CALL: get_ratings_and_reviews_by_recipe_id(recipe_id='{recipe_id}', limit={limit})\")\n",
    "    # Validate recipe_id format\n",
    "    if not isinstance(recipe_id, str) or not recipe_id.isdigit():\n",
    "         try:\n",
    "             recipe_id_int = int(recipe_id)\n",
    "             recipe_id = str(recipe_id_int)\n",
    "         except (ValueError, TypeError):\n",
    "              return json.dumps({\"status\": \"error\", \"message\": f\"Invalid recipe_id format: '{recipe_id}'. Must be a numeric string.\"})\n",
    "\n",
    "    try:\n",
    "        limit_int = int(limit)\n",
    "        if limit_int <= 0: raise ValueError(\"'limit' must be positive.\")\n",
    "    except (ValueError, TypeError):\n",
    "        return json.dumps({\"error\": f\"'limit' parameter must be a positive integer. Got: {limit}\"})\n",
    "\n",
    "    try:\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            # Check if recipe exists first (optional but good practice)\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM recipes WHERE id = ?\", (int(recipe_id),))\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                 return json.dumps({\"status\": \"not_found\", \"message\": f\"Recipe ID {recipe_id} not found.\"})\n",
    "\n",
    "            cursor.execute(\"SELECT AVG(rating) FROM interactions WHERE recipe_id = ?\", (int(recipe_id),))\n",
    "            overall_rating_result = cursor.fetchone()\n",
    "            overall_rating = round(overall_rating_result[0], 2) if overall_rating_result and overall_rating_result[0] is not None else None\n",
    "\n",
    "            cursor.execute(\n",
    "                \"SELECT date, rating, review FROM interactions WHERE recipe_id = ? AND review IS NOT NULL AND review != '' ORDER BY date DESC LIMIT ?\",\n",
    "                (int(recipe_id), limit_int),\n",
    "            )\n",
    "            recent_reviews = cursor.fetchall()\n",
    "            columns = [\"date\", \"rating\", \"review\"]\n",
    "            reviews_list = [dict(zip(columns, review)) for review in recent_reviews]\n",
    "\n",
    "            result_dict = {\"recipe_id\": recipe_id, \"overall_rating\": overall_rating, \"recent_reviews\": reviews_list}\n",
    "            return json.dumps(result_dict, indent=2)\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"ERROR in get_ratings_and_reviews_by_recipe_id (SQL): {e}\")\n",
    "        return json.dumps({\"error\": f\"Database error fetching reviews for recipe ID {recipe_id}: {e}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in get_ratings_and_reviews_by_recipe_id: {e}\")\n",
    "        return json.dumps({\"error\": f\"Unexpected error fetching reviews for recipe ID {recipe_id}: {e}\"})\n",
    "\n",
    "@tool\n",
    "def fetch_nutrition_from_openfoodfacts(ingredient_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches nutrition data (per 100g) for a single ingredient from Open Food Facts API.\n",
    "    Includes robust retry logic. Returns nutrition data as a JSON string or an error/unavailable status.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG TOOL CALL: fetch_nutrition_from_openfoodfacts(ingredient_name='{ingredient_name}')\")\n",
    "    search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "    params = {\n",
    "        \"search_terms\": ingredient_name,\n",
    "        \"search_simple\": 1,\n",
    "        \"action\": \"process\",\n",
    "        \"json\": 1,\n",
    "        \"page_size\": 1\n",
    "    }\n",
    "    headers = {'User-Agent': 'KitchenAssistantLangGraph/1.0 (Language: Python)'} # Good practice\n",
    "\n",
    "    max_retries = 3 # Use the more robust retry count\n",
    "    base_timeout = 15\n",
    "    retry_delay = 1 # Initial delay\n",
    "\n",
    "    for attempt in range(max_retries): # 0, 1, 2 (3 attempts total)\n",
    "        try:\n",
    "            response = requests.get(search_url, params=params, headers=headers, timeout=base_timeout)\n",
    "            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "            data = response.json()\n",
    "\n",
    "            if data.get('products') and len(data['products']) > 0:\n",
    "                product = data['products'][0]\n",
    "                nutriments = product.get('nutriments', {})\n",
    "\n",
    "                # Extract desired fields, include context\n",
    "                nutrition_info = {\n",
    "                    \"food_normalized\": ingredient_name, # Keep this context\n",
    "                    \"source\": \"Open Food Facts\",      # Keep this context\n",
    "                    \"product_name\": product.get('product_name', ingredient_name), # Use input as fallback\n",
    "                    \"calories_100g\": nutriments.get('energy-kcal_100g'),\n",
    "                    \"fat_100g\": nutriments.get('fat_100g'),\n",
    "                    \"saturated_fat_100g\": nutriments.get('saturated-fat_100g'),\n",
    "                    \"carbohydrates_100g\": nutriments.get('carbohydrates_100g'),\n",
    "                    \"sugars_100g\": nutriments.get('sugars_100g'),\n",
    "                    \"fiber_100g\": nutriments.get('fiber_100g'),\n",
    "                    \"proteins_100g\": nutriments.get('proteins_100g'),\n",
    "                    \"sodium_100g\": nutriments.get('sodium_100g'), # Keep as is, handle units in formatting/plotting\n",
    "                }\n",
    "                # Filter out None values BEFORE checking core nutrients\n",
    "                filtered_nutrition = {k: v for k, v in nutrition_info.items() if v is not None}\n",
    "\n",
    "                # Check if at least one core nutrient is present and numeric\n",
    "                core_nutrients = [\"calories_100g\", \"fat_100g\", \"proteins_100g\", \"carbohydrates_100g\"]\n",
    "                has_core_data = False\n",
    "                for core_key in core_nutrients:\n",
    "                    if core_key in filtered_nutrition:\n",
    "                        try:\n",
    "                            # Check if it's actually a number\n",
    "                            float(filtered_nutrition[core_key])\n",
    "                            has_core_data = True\n",
    "                            break # Found at least one valid core nutrient\n",
    "                        except (ValueError, TypeError):\n",
    "                            continue # Skip if not numeric\n",
    "\n",
    "                if not has_core_data:\n",
    "                    print(f\"--> No core numeric nutrition data found for '{ingredient_name}' in product '{filtered_nutrition.get('product_name', 'N/A')}'\")\n",
    "                    # Return JSON string indicating unavailable status\n",
    "                    return json.dumps({\"status\": \"unavailable\", \"reason\": f\"No detailed numeric nutrition data found for '{ingredient_name}'\"})\n",
    "\n",
    "                # Success: return JSON string\n",
    "                print(f\"--> Successfully found nutrition data for '{ingredient_name}'\")\n",
    "                return json.dumps(filtered_nutrition, indent=2)\n",
    "            else:\n",
    "                # No product found\n",
    "                print(f\"--> No product found for '{ingredient_name}'\")\n",
    "                return json.dumps({\"status\": \"unavailable\", \"reason\": f\"No product found for '{ingredient_name}' on Open Food Facts\"})\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429 and attempt < max_retries - 1:\n",
    "                wait_time = (retry_delay * (2 ** attempt)) + random.uniform(0, 1)\n",
    "                print(f\"Rate limit hit for '{ingredient_name}'. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            elif e.response.status_code >= 500 and attempt < max_retries - 1:\n",
    "                 wait_time = (retry_delay * (2 ** attempt)) + random.uniform(0, 1)\n",
    "                 print(f\"Server error ({e.response.status_code}) for '{ingredient_name}'. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                 time.sleep(wait_time)\n",
    "                 continue\n",
    "            else:\n",
    "                print(f\"HTTP Error fetching nutrition for '{ingredient_name}': {e}\")\n",
    "                # Return JSON string indicating unavailable status\n",
    "                return json.dumps({\"status\": \"unavailable\", \"reason\": f\"API request failed with HTTP error: {e}\"})\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (retry_delay * (2 ** attempt)) + random.uniform(0, 1)\n",
    "                print(f\"Request error for '{ingredient_name}': {e}. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error fetching nutrition for '{ingredient_name}' after {max_retries} attempts: {e}\")\n",
    "                # Return JSON string indicating unavailable status\n",
    "                return json.dumps({\"status\": \"unavailable\", \"reason\": f\"API request failed after retries: {e}\"})\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON response for '{ingredient_name}'\")\n",
    "            # Return JSON string indicating unavailable status\n",
    "            return json.dumps({\"status\": \"unavailable\", \"reason\": \"Invalid JSON response from API\"})\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"ERROR in fetch_nutrition_from_openfoodfacts: {e}\")\n",
    "             import traceback\n",
    "             traceback.print_exc()\n",
    "             # Return JSON string indicating error status\n",
    "             return json.dumps({\"error\": f\"Unexpected error fetching nutrition for {ingredient_name}: {e}\"})\n",
    "\n",
    "    # If loop finishes after retries without success\n",
    "    print(f\"Max retries ({max_retries}) exceeded for API request for '{ingredient_name}'\")\n",
    "    return json.dumps({\"status\": \"unavailable\", \"reason\": f\"Max retries ({max_retries}) exceeded for API request for '{ingredient_name}'\"})\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def customize_recipe(recipe_id: str, request: str) -> str:\n",
    "    \"\"\"\n",
    "    (Placeholder Tool) Attempts to customize a recipe based on a user request (e.g., make vegetarian, substitute ingredient).\n",
    "    Requires the recipe_id and the specific customization request string.\n",
    "    Returns a string describing the suggested modifications or indicating inability.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG TOOL CALL: customize_recipe(recipe_id='{recipe_id}', request='{request}')\")\n",
    "    if not recipe_id or not request:\n",
    "        return json.dumps({\"error\": \"Missing recipe_id or customization request for customization.\"})\n",
    "    # Validate recipe_id format\n",
    "    if not isinstance(recipe_id, str) or not recipe_id.isdigit():\n",
    "         try:\n",
    "             recipe_id_int = int(recipe_id)\n",
    "             recipe_id = str(recipe_id_int)\n",
    "         except (ValueError, TypeError):\n",
    "              return json.dumps({\"error\": f\"Invalid recipe_id format: '{recipe_id}'. Must be numeric string.\"})\n",
    "\n",
    "    # Simulate customization logic (replace with actual logic if implemented)\n",
    "    response_message = f\"Placeholder: To make recipe {recipe_id} '{request}', you could try [Simulated Modification: e.g., replace butter with olive oil, use gluten-free flour blend]. (This is simulated customization).\"\n",
    "    return json.dumps({\n",
    "        \"status\": \"placeholder_success\",\n",
    "        \"message\": response_message,\n",
    "        \"recipe_id\": recipe_id,\n",
    "        \"request\": request\n",
    "    })\n",
    "\n",
    "# --- Nutrition Visualization Function ---\n",
    "def extract_and_visualize_nutrition(response_text: str):\n",
    "    \"\"\"\n",
    "    Extracts accumulated nutrition data from LLM response text and\n",
    "    visualizes it as a color-coded horizontal bar chart (% Daily Value).\n",
    "    \"\"\"\n",
    "    print(\"Attempting to extract and visualize nutrition...\")\n",
    "    try:\n",
    "        # Ensure NUTRITION_RESPONSE_HEADER is accessible (defined in Step 2)\n",
    "        header_pattern = re.escape(NUTRITION_RESPONSE_HEADER)\n",
    "    except NameError:\n",
    "        print(\"ERROR: NUTRITION_RESPONSE_HEADER constant not found for visualization.\")\n",
    "        # Define a fallback if necessary, though it should be defined globally\n",
    "        NUTRITION_RESPONSE_HEADER = \"Here's the approximate average nutrition per 100g\"\n",
    "        header_pattern = re.escape(NUTRITION_RESPONSE_HEADER)\n",
    "\n",
    "    # Regex to find the nutrition section more reliably\n",
    "    nutrition_section_match = re.search(\n",
    "        rf\"{header_pattern}.*?:\\s*\\n(.*?)(?:\\n\\s*\\n|\\n\\(Note:|\\Z)\", # Look for header until blank line, note, or end\n",
    "        response_text,\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    if not nutrition_section_match:\n",
    "        print(\"Could not find the nutrition section starting with the expected header in the text.\")\n",
    "        return\n",
    "\n",
    "    nutrition_text = nutrition_section_match.group(1).strip()\n",
    "    print(f\"Extracted Nutrition Text Block:\\n---\\n{nutrition_text}\\n---\")\n",
    "\n",
    "    # Regex to extract nutrient lines\n",
    "    nutrient_pattern = re.compile(\n",
    "        r\"^\\s*-\\s*(?P<nutrient>[^:]+?)\\s*:\\s*(?P<value>[\\d.]+)\\s*(?P<unit>kcal|g|mg).*\",\n",
    "        re.MULTILINE | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Mapping from display names back to state keys\n",
    "    key_map = {\n",
    "        'calories': 'calories_100g', 'fat': 'fat_100g', 'saturated fat': 'saturated_fat_100g',\n",
    "        'carbohydrates': 'carbohydrates_100g', 'sugars': 'sugars_100g', 'fiber': 'fiber_100g',\n",
    "        'proteins': 'proteins_100g', 'sodium': 'sodium_100g',\n",
    "    }\n",
    "    extracted_values: Dict[str, float] = {}\n",
    "    processed_nutrients = 0\n",
    "\n",
    "    for match in nutrient_pattern.finditer(nutrition_text):\n",
    "        nutrient_name = match.group(\"nutrient\").strip().lower()\n",
    "        value_str = match.group(\"value\").strip()\n",
    "        unit = match.group(\"unit\").strip().lower()\n",
    "\n",
    "        if nutrient_name in key_map:\n",
    "            state_key = key_map[nutrient_name]\n",
    "            try:\n",
    "                value = float(value_str)\n",
    "                # Convert sodium mg to g for internal consistency if needed,\n",
    "                # but the plotting logic handles mg display.\n",
    "                # Keep value as extracted (e.g., sodium in mg if unit is mg)\n",
    "                # The plotting logic below handles unit conversion for display.\n",
    "                extracted_values[state_key] = value\n",
    "                processed_nutrients += 1\n",
    "                print(f\"Extracted: {state_key} = {value} {unit}\") # Log unit too\n",
    "            except ValueError:\n",
    "                print(f\"Warning: Could not convert value '{value_str}' for nutrient '{nutrient_name}' to float.\")\n",
    "        else:\n",
    "             print(f\"Warning: Unrecognized nutrient '{nutrient_name}' found in text.\")\n",
    "\n",
    "    if processed_nutrients == 0:\n",
    "         print(\"No valid nutrition data found in the text block to plot.\")\n",
    "         return\n",
    "\n",
    "    print(f\"Processed {processed_nutrients} nutrients for visualization.\")\n",
    "    print(\"Extracted values for plotting:\", extracted_values)\n",
    "\n",
    "    # Daily values (adjust as needed, sodium in g for calculation)\n",
    "    daily_values = {\n",
    "        \"calories_100g\": 2000, \"fat_100g\": 78, \"saturated_fat_100g\": 20,\n",
    "        \"carbohydrates_100g\": 275, \"sugars_100g\": 50, \"fiber_100g\": 28,\n",
    "        \"proteins_100g\": 50, \"sodium_100g\": 2.3, # DV for sodium in grams (2300mg)\n",
    "    }\n",
    "    percent_dv: Dict[str, float] = {}\n",
    "    actual_values_plot: Dict[str, float] = {} # Store values as they should be plotted (e.g., sodium in mg)\n",
    "\n",
    "    for key, value in extracted_values.items():\n",
    "        dv = daily_values.get(key)\n",
    "        if dv is not None and dv > 0:\n",
    "            # Handle sodium conversion for %DV calculation (value is likely in mg from text)\n",
    "            value_for_calc = value / 1000.0 if key == 'sodium_100g' else value\n",
    "            percent_dv[key] = round((value_for_calc / dv) * 100, 1)\n",
    "            actual_values_plot[key] = round(value, 1) # Store original value for label\n",
    "        else:\n",
    "            # Handle nutrients without a standard DV (like calories) or if DV is missing\n",
    "            percent_dv[key] = 0.0 # Or handle differently if needed\n",
    "            actual_values_plot[key] = round(value, 1)\n",
    "            if dv is None: print(f\"Warning: No Daily Value defined for {key}.\")\n",
    "\n",
    "    # Separate calories for title display\n",
    "    calories_percent_dv = percent_dv.pop(\"calories_100g\", 0.0)\n",
    "    calories_actual = actual_values_plot.pop(\"calories_100g\", 0.0)\n",
    "\n",
    "    # Filter data for plotting (only those with %DV calculated, excluding calories)\n",
    "    plot_data = {k: v for k, v in percent_dv.items() if k in actual_values_plot and v > 0} # Only plot if %DV > 0\n",
    "    if not plot_data:\n",
    "        print(\"No data with calculable %DV > 0 to plot.\")\n",
    "        # Optionally, still show calories if available\n",
    "        if calories_actual > 0:\n",
    "             print(f\"Estimated Avg Calories per 100g Ingredient: {calories_actual:.0f} kcal\")\n",
    "        return\n",
    "\n",
    "    labels = list(plot_data.keys())\n",
    "    display_labels = [l.replace('_100g', '').replace('_', ' ').capitalize() for l in labels]\n",
    "    values = list(plot_data.values()) # These are %DV values\n",
    "    # Color coding based on %DV\n",
    "    colors = ['forestgreen' if v <= 15 else ('orange' if v <= 40 else 'red') for v in values] # Adjusted thresholds\n",
    "\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(10, max(4, len(labels) * 0.6)))\n",
    "        bars = ax.barh(display_labels, values, color=colors, height=0.6)\n",
    "        ax.set_xlabel('% Daily Value (DV) - Based on average of 100g of each ingredient')\n",
    "        ax.set_title('Average Ingredient Nutrition (%DV)', fontsize=16)\n",
    "        ax.tick_params(axis='both', labelsize=10)\n",
    "        # Adjust x-limit dynamically\n",
    "        max_val = max(values + [100]) # Include 100 in case all values are small\n",
    "        ax.set_xlim(right=max_val * 1.1)\n",
    "\n",
    "        # Add labels to bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width() # %DV value\n",
    "            nutrient_key = labels[i]\n",
    "            actual_val = actual_values_plot.get(nutrient_key, 0.0) # Get the actual value (e.g., sodium in mg)\n",
    "            # Determine unit based on key for display\n",
    "            unit = 'kcal' if 'calories' in nutrient_key else ('mg' if nutrient_key == 'sodium_100g' else 'g')\n",
    "            # Format actual value for display\n",
    "            display_actual = f\"{actual_val:.1f}\"\n",
    "\n",
    "            label_text = f'{width:.1f}% ({display_actual} {unit})'\n",
    "            # Position label inside or outside bar based on width\n",
    "            x_pos = width + max_val * 0.01 if width < max_val * 0.85 else width - max_val * 0.01\n",
    "            ha = 'left' if width < max_val * 0.85 else 'right'\n",
    "            color = 'black' if width < max_val * 0.85 else 'white'\n",
    "            ax.text(x_pos, bar.get_y() + bar.get_height()/2., label_text,\n",
    "                    ha=ha, va='center', color=color, fontsize=9, fontweight='bold')\n",
    "\n",
    "        # Add calorie information in the title or subtitle\n",
    "        cal_color = 'forestgreen' if calories_percent_dv <= 15 else ('orange' if calories_percent_dv <= 40 else 'red')\n",
    "        calorie_text = f'Estimated Avg Calories per 100g Ingredient: {calories_actual:.0f} kcal ({calories_percent_dv:.1f}% DV)'\n",
    "        # Place text slightly below the main title\n",
    "        fig.text(0.5, 0.97, calorie_text, ha='center', va='bottom', fontsize=12, color=cal_color, fontweight='bold')\n",
    "\n",
    "\n",
    "        plt.gca().invert_yaxis() # Show top nutrient first\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent overlap\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        plt.show()\n",
    "        print(\"Nutrition visualization displayed.\")\n",
    "    except Exception as plot_error:\n",
    "        print(f\"Error during plotting: {plot_error}\")\n",
    "\n",
    "\n",
    "# --- Tool Lists & Executor (MODIFIED) ---\n",
    "stateless_tools = [\n",
    "    gemini_recipe_similarity_search,\n",
    "    get_recipe_by_id,\n",
    "    get_ratings_and_reviews_by_recipe_id,\n",
    "    fetch_nutrition_from_openfoodfacts,\n",
    "    # google_search, # <-- REMOVED\n",
    "]\n",
    "# Tools intended for the LLM to call directly\n",
    "# Customize recipe is also a tool the LLM can call\n",
    "llm_callable_tools = stateless_tools + [customize_recipe] # <-- RENAMED list for clarity\n",
    "\n",
    "# ToolNode executes stateless tools when called by the LLM\n",
    "tool_executor_node = ToolNode(stateless_tools) # ToolNode only needs stateless ones\n",
    "\n",
    "# --- LLM Binding (MODIFIED) ---\n",
    "# Ensure llm is defined from Step 2 (and has grounding enabled)\n",
    "# Bind only the tools the LLM should explicitly call\n",
    "llm_with_callable_tools = llm.bind_tools(llm_callable_tools) # <-- Use the new list and name\n",
    "\n",
    "print(\"✅ LangGraph Step 3: Tools Defined and Bound (Revised - Native Grounding)\") # <-- Updated print message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "371d4684-7141-4747-86f7-1faf15ae5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 3.5: Core Nodes Defined (after LLM binding)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 3.5: Core Node Definitions (Moved After LLM Binding)\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from typing import Dict, Any, Optional, List\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# --- Assume KitchenState, KITCHEN_ASSISTANT_SYSINT, llm_with_callable_tools are defined ---\n",
    "\n",
    "def input_parser_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parses user input or tool results using the LLM based on system instructions.\n",
    "    Determines intent, generates tool calls, handles chat responses, or triggers aggregation.\n",
    "    Preserves context like selected_recipe_id unless explicitly changed.\n",
    "    \"\"\"\n",
    "    print(\"---NODE: InputParserNode---\")\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else None\n",
    "    previous_ai_message: Optional[AIMessage] = None\n",
    "    # Find the last AIMessage to check if it requested nutrition\n",
    "    for i in range(len(messages) - 2, -1, -1):\n",
    "        if isinstance(messages[i], AIMessage):\n",
    "            previous_ai_message = messages[i]\n",
    "            break\n",
    "\n",
    "    # --- Check if Aggregation is Needed ---\n",
    "    needs_aggregation = False\n",
    "    if isinstance(last_message, ToolMessage) and last_message.name == \"fetch_nutrition_from_openfoodfacts\":\n",
    "        if previous_ai_message and previous_ai_message.tool_calls:\n",
    "            made_nutrition_calls = any(\n",
    "                tc.get('name') == 'fetch_nutrition_from_openfoodfacts'\n",
    "                for tc in previous_ai_message.tool_calls\n",
    "            )\n",
    "            if made_nutrition_calls:\n",
    "                # Check if *all* messages since the last AI message are nutrition ToolMessages\n",
    "                all_nutrition_results = True\n",
    "                start_index = -1\n",
    "                try:\n",
    "                    start_index = messages.index(previous_ai_message) + 1\n",
    "                except ValueError:\n",
    "                    all_nutrition_results = False # Should not happen if previous_ai_message found\n",
    "\n",
    "                if all_nutrition_results and start_index != -1 and start_index < len(messages):\n",
    "                    for msg in messages[start_index:]:\n",
    "                        if not (isinstance(msg, ToolMessage) and msg.name == \"fetch_nutrition_from_openfoodfacts\"):\n",
    "                            all_nutrition_results = False\n",
    "                            break\n",
    "                # If no messages after AI msg or start_index invalid, it's not all nutrition results\n",
    "                elif start_index == -1 or start_index >= len(messages):\n",
    "                     all_nutrition_results = False\n",
    "\n",
    "\n",
    "                if all_nutrition_results:\n",
    "                    needs_aggregation = True\n",
    "                    print(\"Detected nutrition tool results following specific request, setting intent to aggregate.\")\n",
    "\n",
    "    if needs_aggregation:\n",
    "        # Route directly to aggregation node\n",
    "        updates = {\n",
    "            \"intent\": \"aggregate_nutrition\",\n",
    "            \"messages\": [], # Prevent LLM re-processing tool results in this node\n",
    "            \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "            \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        }\n",
    "        print(f\"Routing to aggregation. State updates: { {k:v for k,v in updates.items() if k != 'messages'} }\")\n",
    "        # Return only the necessary updates for routing and context\n",
    "        return {k: v for k, v in updates.items() if k in KitchenState.__annotations__}\n",
    "\n",
    "\n",
    "    # --- Normal LLM Invocation ---\n",
    "    print(\"Proceeding with LLM invocation...\")\n",
    "    # llm_with_callable_tools is now defined globally before this function runs\n",
    "    context_messages = [SystemMessage(content=KITCHEN_ASSISTANT_SYSINT[1])] + list(messages)\n",
    "    try:\n",
    "        # Use the LLM instance that has tools bound\n",
    "        ai_response: AIMessage = llm_with_callable_tools.invoke(context_messages)\n",
    "        print(f\"LLM Raw Response: {ai_response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Invocation Error: {e}\")\n",
    "        error_message = \"Sorry, I encountered an internal error trying to process that. Could you try rephrasing?\"\n",
    "        # Return minimal error state update\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=error_message)],\n",
    "            \"last_assistant_response\": error_message,\n",
    "            \"intent\": \"error\",\n",
    "            \"finished\": False,\n",
    "             # Preserve context even on error\n",
    "            \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "            \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        }\n",
    "\n",
    "\n",
    "    # Prepare state updates based on LLM response\n",
    "    updates = {\n",
    "        \"messages\": [ai_response], # Add the new AI response\n",
    "        \"intent\": \"general_chat\", # Default intent\n",
    "        \"finished\": False,\n",
    "        \"last_assistant_response\": None,\n",
    "        \"needs_clarification\": False,\n",
    "        # --- Context Preservation ---\n",
    "        \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "        \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        \"recipe_reviews\": state.get(\"recipe_reviews\"),\n",
    "        # --- Clear Transient Fields ---\n",
    "        \"ingredient_nutrition_list\": None,\n",
    "        \"nutritional_info\": None,\n",
    "        \"grounding_results_formatted\": None,\n",
    "        \"customization_request\": None,\n",
    "    }\n",
    "\n",
    "    if ai_response.tool_calls:\n",
    "        updates[\"intent\"] = \"tool_call\"\n",
    "        print(f\"Intent: tool_call, Tool Calls: {ai_response.tool_calls}\")\n",
    "\n",
    "        # --- Context Management based on Tool Calls ---\n",
    "        new_search_initiated = any(tc.get('name') == 'gemini_recipe_similarity_search' for tc in ai_response.tool_calls)\n",
    "        getting_new_details = any(tc.get('name') == 'get_recipe_by_id' for tc in ai_response.tool_calls)\n",
    "\n",
    "        if new_search_initiated:\n",
    "            print(\"New recipe search detected, clearing previous recipe context.\")\n",
    "            updates[\"current_recipe_details\"] = None\n",
    "            updates[\"selected_recipe_id\"] = None\n",
    "            updates[\"recipe_reviews\"] = None\n",
    "            updates[\"nutritional_info\"] = None\n",
    "\n",
    "        for tc in ai_response.tool_calls:\n",
    "            tool_name = tc.get('name')\n",
    "            tool_args = tc.get('args', {})\n",
    "            recipe_id_arg = tool_args.get('recipe_id')\n",
    "\n",
    "            if tool_name in ['get_recipe_by_id', 'get_ratings_and_reviews_by_recipe_id', 'customize_recipe']:\n",
    "                if recipe_id_arg:\n",
    "                    if recipe_id_arg != updates[\"selected_recipe_id\"]:\n",
    "                         print(f\"Tool call for new recipe ID '{recipe_id_arg}', updating context.\")\n",
    "                         updates[\"selected_recipe_id\"] = recipe_id_arg\n",
    "                         updates[\"current_recipe_details\"] = None\n",
    "                         updates[\"recipe_reviews\"] = None\n",
    "                         updates[\"nutritional_info\"] = None\n",
    "                    elif tool_name == 'get_recipe_by_id':\n",
    "                         updates[\"selected_recipe_id\"] = recipe_id_arg # Ensure it's set\n",
    "\n",
    "            if tool_name == 'customize_recipe':\n",
    "                 updates[\"customization_request\"] = tool_args.get('request')\n",
    "                 updates[\"intent\"] = \"customize\"\n",
    "\n",
    "    elif ai_response.content:\n",
    "        updates[\"last_assistant_response\"] = ai_response.content\n",
    "        content_lower = ai_response.content.lower()\n",
    "\n",
    "        if \"need more details\" in content_lower or \"could you clarify\" in content_lower or \"which recipe\" in content_lower:\n",
    "            updates[\"intent\"] = \"clarification_needed\"\n",
    "            updates[\"needs_clarification\"] = True\n",
    "        elif \"goodbye\" in content_lower or \"exit\" in content_lower or \"bye\" in content_lower:\n",
    "            updates[\"intent\"] = \"exit\"\n",
    "            updates[\"finished\"] = True\n",
    "        elif state.get(\"user_input\", \"\").lower() in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
    "             updates[\"intent\"] = \"exit\"\n",
    "             updates[\"finished\"] = True\n",
    "        else:\n",
    "            updates[\"intent\"] = \"general_chat\"\n",
    "\n",
    "        print(f\"Intent: {updates['intent']}, Response: {updates['last_assistant_response'][:100]}...\")\n",
    "\n",
    "    else: # Handle case where LLM returns neither content nor tool calls\n",
    "        updates[\"intent\"] = \"error\"\n",
    "        error_message = \"Sorry, I had trouble processing that request. Can you please try again?\"\n",
    "        updates[\"last_assistant_response\"] = error_message\n",
    "        updates[\"messages\"] = [AIMessage(content=error_message)] # Ensure error message is in history\n",
    "        print(f\"Intent: error (Empty LLM response)\")\n",
    "\n",
    "    # Return only fields that have changed or are essential for the next step\n",
    "    valid_keys = KitchenState.__annotations__.keys()\n",
    "    # Filter out keys that are not in the state definition or haven't changed (except messages)\n",
    "    return {k: v for k, v in updates.items() if k in valid_keys and (k == 'messages' or state.get(k) != v)}\n",
    "\n",
    "\n",
    "def response_formatter_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Formats the final response for the user. Prioritizes aggregated nutrition\n",
    "    if available, otherwise uses the last AI message content or a default.\n",
    "    Adds the final formatted response as an AIMessage to history.\n",
    "    \"\"\"\n",
    "    print(\"---NODE: ResponseFormatterNode---\")\n",
    "    formatted_response = \"Okay, let me know how else I can help!\" # Default fallback\n",
    "    final_intent_for_history = state.get(\"intent\", \"general_chat\") # Capture intent before reset\n",
    "\n",
    "    # 1. Check for aggregated nutrition info first\n",
    "    if state.get(\"nutritional_info\"):\n",
    "        agg_info = state[\"nutritional_info\"]\n",
    "        nutrient_counts_from_state = agg_info.get(\"nutrient_counts\", {}) # Get counts dict\n",
    "\n",
    "        recipe_name = \"the recipe\"\n",
    "        recipe_id = state.get(\"selected_recipe_id\")\n",
    "        if state.get(\"current_recipe_details\"):\n",
    "            recipe_name = state[\"current_recipe_details\"].get(\"name\", f\"recipe {recipe_id}\" if recipe_id else \"the recipe\")\n",
    "        elif recipe_id:\n",
    "            recipe_name = f\"recipe {recipe_id}\"\n",
    "\n",
    "        response_lines = [f\"{NUTRITION_RESPONSE_HEADER} **{recipe_name}**:\\n\"] # Use constant header, add newline\n",
    "        processed_count = agg_info.get('processed_ingredient_count', 0)\n",
    "\n",
    "        display_order = [\"calories_100g\", \"fat_100g\", \"saturated_fat_100g\", \"carbohydrates_100g\", \"sugars_100g\", \"fiber_100g\", \"proteins_100g\", \"sodium_100g\"]\n",
    "        has_data = False\n",
    "        for key in display_order:\n",
    "            # Use nutrient_counts_from_state\n",
    "            if key in agg_info and nutrient_counts_from_state.get(key, 0) > 0:\n",
    "                 val = agg_info[key]\n",
    "                 # Determine unit based on key name\n",
    "                 unit = 'kcal' if 'calories' in key else ('mg' if key == 'sodium_100g' else 'g')\n",
    "                 display_key = key.replace('_100g', '').replace('_', ' ').capitalize()\n",
    "                 # Format value, converting sodium to mg for display if it's stored in g\n",
    "                 # Assuming fetch_nutrition returns sodium in g, but formatter expects mg display\n",
    "                 # If fetch_nutrition returns mg, this logic needs adjustment\n",
    "                 # Let's assume fetch returns g for sodium based on DV standard\n",
    "                 # Correction: fetch_nutrition likely returns mg. Let's adjust.\n",
    "                 # Assume fetch_nutrition returns sodium in mg. Display as mg.\n",
    "                 display_val = f\"{val:.1f}\" # Keep as is if unit is mg or kcal\n",
    "                 if key == 'sodium_100g':\n",
    "                     unit = 'mg' # Explicitly set unit for sodium display\n",
    "\n",
    "                 response_lines.append(f\"- {display_key}: {display_val} {unit}\")\n",
    "                 has_data = True\n",
    "\n",
    "        if has_data and processed_count > 0:\n",
    "             response_lines.append(f\"\\n(Note: Based on average of {processed_count} ingredients with available data from Open Food Facts. Actual recipe nutrition will vary.)\")\n",
    "        elif processed_count > 0:\n",
    "             response_lines.append(\"\\n(Note: Could not retrieve detailed nutrition data for the ingredients, only partial information might be available.)\")\n",
    "        else:\n",
    "             response_lines.append(\"\\n(Note: Could not retrieve nutrition data for the ingredients.)\")\n",
    "\n",
    "        formatted_response = \"\\n\".join(response_lines)\n",
    "        final_intent_for_history = \"nutrition_presented\"\n",
    "\n",
    "    # 2. If no nutrition info, use the last AI message content if available and meaningful\n",
    "    elif state.get(\"last_assistant_response\"):\n",
    "         formatted_response = state[\"last_assistant_response\"]\n",
    "    elif state.get('messages') and isinstance(state['messages'][-1], AIMessage) and state['messages'][-1].content:\n",
    "         # Fallback to the absolute last message if parser didn't set one AND it has content\n",
    "         formatted_response = state['messages'][-1].content\n",
    "\n",
    "    # 3. Handle explicit exit intent if no other content generated\n",
    "    elif state.get(\"intent\") == \"exit\" or state.get(\"finished\"):\n",
    "        formatted_response = \"Okay, goodbye! Feel free to ask if you need recipes later.\"\n",
    "        final_intent_for_history = \"exit\"\n",
    "\n",
    "\n",
    "    print(f\"Formatted Response: {formatted_response[:100]}...\")\n",
    "\n",
    "    # Update state for the next turn or end\n",
    "    updates = {\n",
    "        \"last_assistant_response\": formatted_response,\n",
    "        \"intent\": None, # Reset intent after formatting\n",
    "        \"needs_clarification\": False, # Reset flag\n",
    "        \"messages\": [AIMessage(content=formatted_response, metadata={\"intent\": final_intent_for_history})],\n",
    "        # Clear transient data fields used to generate this response\n",
    "        \"nutritional_info\": None,\n",
    "        \"ingredient_nutrition_list\": None,\n",
    "        \"grounding_results_formatted\": None,\n",
    "        # Keep context fields unless explicitly cleared elsewhere\n",
    "        \"current_recipe_details\": state.get(\"current_recipe_details\"),\n",
    "        \"selected_recipe_id\": state.get(\"selected_recipe_id\"),\n",
    "        \"recipe_reviews\": state.get(\"recipe_reviews\"),\n",
    "        \"finished\": state.get(\"finished\", False) # Preserve finished flag if set\n",
    "    }\n",
    "\n",
    "    # Return only necessary updates\n",
    "    valid_keys = KitchenState.__annotations__.keys()\n",
    "    return {k: v for k, v in updates.items() if k in valid_keys and (k == 'messages' or state.get(k) != v)}\n",
    "\n",
    "\n",
    "# HumanInputNode definition (remains the same, bypassed by UI)\n",
    "def human_input_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"(Bypassed by UI Loop) Handles getting input from the user.\"\"\"\n",
    "    print(\"---NODE: HumanInputNode (Bypassed by UI)---\\\\\")\n",
    "    user_input = input(f\"Assistant: {state.get('last_assistant_response', 'How can I help?')}\\\\nYou: \")\n",
    "    finished = False\n",
    "    intent = None\n",
    "    if user_input.lower() in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
    "        finished = True\n",
    "        intent = \"exit\"\n",
    "\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [HumanMessage(content=user_input)],\n",
    "        \"finished\": finished,\n",
    "        \"intent\": intent\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✅ LangGraph Step 3.5: Core Nodes Defined (after LLM binding)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439be75-786f-41d1-9b0b-8f5fc0d96afc",
   "metadata": {},
   "source": [
    "**Step 4: Custom Action Nodes (Revised)**\n",
    "\n",
    "*   **`recipe_customization_node`:** Kept as a placeholder but improved the response message slightly.\n",
    "*   **`aggregate_nutrition_node`:** Made more robust. It now iterates backwards through messages to find *all* relevant `fetch_nutrition_from_openfoodfacts` `ToolMessage`s since the last AI request for them. Handles JSON parsing errors more gracefully. Stores `nutrient_counts`.\n",
    "*   **`visualize_nutrition_node`:** **Crucially**, this node now *calls* the `extract_and_visualize_nutrition` function (defined in Step 3) using the `last_assistant_response` from the state. This integrates visualization into the graph flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "966e91fd-fc9b-4d4e-8ab8-3bbf69aff8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 4: Custom Action Nodes Defined (Revised)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 4: Specific Action Nodes (Revised)\n",
    "\n",
    "# --- Assume KitchenState is defined ---\n",
    "# from step1_state import KitchenState\n",
    "# --- Assume visualization function is defined/imported ---\n",
    "# from step3_tools import extract_and_visualize_nutrition\n",
    "# --- Assume NUTRITION_RESPONSE_HEADER constant is defined ---\n",
    "# from step2_core import NUTRITION_RESPONSE_HEADER\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Any, Optional, List\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "\n",
    "\n",
    "# --- Custom Action Nodes ---\n",
    "\n",
    "def recipe_customization_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\" Handles recipe customization (Placeholder). Calls placeholder tool. \"\"\"\n",
    "    print(\"---NODE: RecipeCustomizationNode (Executing Placeholder Tool Call)---\")\n",
    "    recipe_id = state.get(\"selected_recipe_id\")\n",
    "    request = state.get(\"customization_request\")\n",
    "    recipe_name = \"the recipe\"\n",
    "    if state.get(\"current_recipe_details\"):\n",
    "        recipe_name = state[\"current_recipe_details\"].get(\"name\", f\"recipe {recipe_id}\" if recipe_id else \"the recipe\")\n",
    "    elif recipe_id:\n",
    "         recipe_name = f\"recipe {recipe_id}\"\n",
    "\n",
    "    if not recipe_id or not request:\n",
    "        error_msg = \"Sorry, I need a selected recipe and your specific customization request to proceed.\"\n",
    "        print(f\"Customization Error: {error_msg}\")\n",
    "        # Return state indicating clarification needed, maybe add error message\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=error_msg)],\n",
    "            \"last_assistant_response\": error_msg,\n",
    "            \"intent\": \"clarification_needed\",\n",
    "            \"needs_clarification\": True,\n",
    "        }\n",
    "\n",
    "    # --- Call the Placeholder Tool ---\n",
    "    # In a real scenario, the *parser* would generate the tool call,\n",
    "    # and the *executor* would run it. This node might just format the result.\n",
    "    # However, since it's a placeholder, we simulate the call and response here.\n",
    "    tool_result_str = customize_recipe.invoke({\"recipe_id\": recipe_id, \"request\": request})\n",
    "    try:\n",
    "        tool_result = json.loads(tool_result_str)\n",
    "        response_content = tool_result.get(\"message\", \"Placeholder customization applied.\")\n",
    "        status = tool_result.get(\"status\")\n",
    "        if \"error\" in tool_result or status == \"error\":\n",
    "             response_content = f\"Sorry, I encountered an issue trying to customize: {response_content}\"\n",
    "             print(f\"Customization Placeholder Tool Error: {response_content}\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        response_content = \"Sorry, I received an unexpected response while trying to customize.\"\n",
    "        print(f\"Customization Placeholder JSON Error: {tool_result_str}\")\n",
    "    except Exception as e:\n",
    "        response_content = f\"An unexpected error occurred during customization: {e}\"\n",
    "        print(f\"Customization Placeholder Unexpected Error: {e}\")\n",
    "\n",
    "\n",
    "    # --- End Placeholder ---\n",
    "\n",
    "    print(f\"Customization Response: {response_content}\")\n",
    "    # Update state: provide response, mark customization as handled\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response_content)],\n",
    "        \"last_assistant_response\": response_content,\n",
    "        \"customization_request\": None, # Clear request\n",
    "        \"intent\": \"customization_complete\" # Signal completion for routing\n",
    "    }\n",
    "\n",
    "\n",
    "# Nutrition Aggregation Node (Revised for Robustness)\n",
    "# Nutrition Aggregation Node (Revised for Robustness & Debugging)\n",
    "def aggregate_nutrition_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Aggregates nutrition data collected from fetch_nutrition_from_openfoodfacts tool calls\n",
    "    since the last AI message that requested them. Calculates average values per 100g.\n",
    "    Updates the nutritional_info field in the state.\n",
    "    \"\"\"\n",
    "    print(\"---NODE: AggregateNutritionNode---\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    aggregated_sums: Dict[str, float] = defaultdict(float) # Use defaultdict\n",
    "    nutrient_counts: Dict[str, int] = defaultdict(int)\n",
    "    processed_ingredient_count = 0\n",
    "    unavailable_count = 0\n",
    "    error_count = 0 # Add error counter\n",
    "    relevant_tool_messages = []\n",
    "\n",
    "    # Find the last AI message that made nutrition tool calls\n",
    "    last_nutrition_request_index = -1\n",
    "    for i in range(len(messages) - 1, -1, -1):\n",
    "        msg = messages[i]\n",
    "        if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "            if any(tc.get('name') == 'fetch_nutrition_from_openfoodfacts' for tc in msg.tool_calls):\n",
    "                last_nutrition_request_index = i\n",
    "                break\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            break # Stop searching if we hit a human message\n",
    "\n",
    "    # Collect all ToolMessages after that specific AI request\n",
    "    if last_nutrition_request_index != -1:\n",
    "        start_index = last_nutrition_request_index + 1\n",
    "        for i in range(start_index, len(messages)):\n",
    "            msg = messages[i]\n",
    "            if isinstance(msg, ToolMessage) and msg.name == \"fetch_nutrition_from_openfoodfacts\":\n",
    "                relevant_tool_messages.append(msg)\n",
    "            elif isinstance(msg, (AIMessage, HumanMessage)):\n",
    "                 break # Stop if we hit another user/AI message\n",
    "    else:\n",
    "        print(\"Warning: Could not find the preceding AI message that requested nutrition.\")\n",
    "        return {\"nutritional_info\": {\"processed_ingredient_count\": 0, \"nutrient_counts\": {}}}\n",
    "\n",
    "\n",
    "    print(f\"Found {len(relevant_tool_messages)} relevant nutrition ToolMessages to aggregate.\")\n",
    "    if not relevant_tool_messages:\n",
    "         print(\"No relevant tool messages found to aggregate.\")\n",
    "         return {\"nutritional_info\": {\"processed_ingredient_count\": 0, \"nutrient_counts\": {}}}\n",
    "\n",
    "\n",
    "    # Process the relevant messages\n",
    "    for msg in relevant_tool_messages:\n",
    "        # ---> ADD DETAILED PRINTING HERE <---\n",
    "        print(f\"\\nDEBUG Aggregation: Processing ToolMessage ID {getattr(msg, 'tool_call_id', 'N/A')}\")\n",
    "        print(f\"DEBUG Aggregation: Raw Content: {msg.content}\")\n",
    "        # ---> END OF ADDED PRINTING <---\n",
    "        try:\n",
    "            content_data = json.loads(msg.content)\n",
    "            ingredient_name = content_data.get(\"food_normalized\", \"Unknown Ingredient\")\n",
    "\n",
    "            # Check for explicit unavailable or error status\n",
    "            if content_data.get(\"status\") == \"unavailable\":\n",
    "                unavailable_count += 1\n",
    "                print(f\"--> Skipping unavailable result for '{ingredient_name}': {content_data.get('reason', 'No reason provided')}\")\n",
    "                continue\n",
    "            elif \"error\" in content_data:\n",
    "                error_count += 1\n",
    "                print(f\"--> Skipping error result for '{ingredient_name}': {content_data.get('error', 'Unknown error')}\")\n",
    "                continue\n",
    "\n",
    "            # Check if core numeric data exists\n",
    "            core_nutrients = [\"calories_100g\", \"fat_100g\", \"proteins_100g\", \"carbohydrates_100g\"]\n",
    "            has_core_data = False\n",
    "            numeric_values_found = {}\n",
    "\n",
    "            for key in content_data.keys():\n",
    "                if key.endswith(\"_100g\") and key not in [\"food_normalized\", \"source\", \"product_name\", \"status\", \"reason\", \"error\"]:\n",
    "                    value = content_data.get(key)\n",
    "                    if value is not None:\n",
    "                        try:\n",
    "                            num_value = float(value)\n",
    "                            if num_value >= 0:\n",
    "                                aggregated_sums[key] += num_value\n",
    "                                nutrient_counts[key] += 1\n",
    "                                numeric_values_found[key] = num_value # Store found value\n",
    "                                if key in core_nutrients:\n",
    "                                    has_core_data = True\n",
    "                            else:\n",
    "                                print(f\"--> Warning: Ignoring negative value '{num_value}' for key '{key}' in '{ingredient_name}'.\")\n",
    "                        except (ValueError, TypeError):\n",
    "                            print(f\"--> Warning: Could not convert value '{value}' for key '{key}' in '{ingredient_name}' to float.\")\n",
    "\n",
    "            # If we parsed the JSON but found no core numeric data, count as unavailable\n",
    "            if not has_core_data:\n",
    "                unavailable_count += 1\n",
    "                print(f\"--> Skipping result for '{ingredient_name}': Parsed OK, but no core numeric nutrition data found. Found: {numeric_values_found}\")\n",
    "                continue\n",
    "            else:\n",
    "                # Successfully processed ingredient with core data\n",
    "                processed_ingredient_count += 1\n",
    "                print(f\"--> Successfully processed nutrition for: {ingredient_name}\")\n",
    "\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            error_count += 1\n",
    "            print(f\"--> ERROR: Could not parse ToolMessage content as JSON: {msg.content[:100]}...\")\n",
    "        except Exception as e:\n",
    "             error_count += 1\n",
    "             print(f\"--> ERROR: Unexpected error processing ToolMessage ({getattr(msg, 'tool_call_id', 'N/A')}): {e}\")\n",
    "\n",
    "    # Calculate averages\n",
    "    average_nutrition = {}\n",
    "    for key, total_sum in aggregated_sums.items():\n",
    "        count = nutrient_counts[key]\n",
    "        average_nutrition[key] = round(total_sum / count, 2) if count > 0 else 0.0\n",
    "\n",
    "    # Add context counts AND the nutrient_counts dictionary itself\n",
    "    average_nutrition[\"processed_ingredient_count\"] = processed_ingredient_count\n",
    "    average_nutrition[\"unavailable_ingredient_count\"] = unavailable_count\n",
    "    average_nutrition[\"error_ingredient_count\"] = error_count # Add error count\n",
    "    average_nutrition[\"nutrient_counts\"] = dict(nutrient_counts) # Store the counts dict\n",
    "\n",
    "    print(f\"\\nAggregation Complete. Processed: {processed_ingredient_count}, Unavailable/NoData: {unavailable_count}, Errors: {error_count}\")\n",
    "    print(f\"Aggregated Nutrition (Avg per 100g): {average_nutrition}\")\n",
    "\n",
    "    # Update state\n",
    "    return {\"nutritional_info\": average_nutrition, \"ingredient_nutrition_list\": None}\n",
    "\n",
    "\n",
    "# Visualization Node (Revised to CALL the function)\n",
    "def visualize_nutrition_node(state: KitchenState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calls the nutrition visualization function using the final assistant response\n",
    "    if it contains the expected nutrition information header.\n",
    "    This node is typically terminal for the visualization part of the flow.\n",
    "    \"\"\"\n",
    "    print(\"---NODE: VisualizeNutritionNode---\")\n",
    "    final_response = state.get(\"last_assistant_response\")\n",
    "\n",
    "    # Check if the specific header used by the formatter exists in the final response\n",
    "    if final_response and NUTRITION_RESPONSE_HEADER in final_response:\n",
    "        print(\"Detected nutrition info in final response. Calling visualization function.\")\n",
    "        try:\n",
    "            # Call the visualization function defined/imported (e.g., from Step 3)\n",
    "            extract_and_visualize_nutrition(final_response)\n",
    "            print(\"Visualization function executed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during visualization call: {e}\")\n",
    "            # Log the error, but don't necessarily stop the flow unless critical\n",
    "    else:\n",
    "        print(\"No nutrition section header found in the final response, skipping visualization.\")\n",
    "\n",
    "    # This node primarily performs a side effect (plotting).\n",
    "    # It doesn't need to modify the state further for the main conversation flow.\n",
    "    # Return an empty dict or only essential pass-through fields if needed.\n",
    "    return {}\n",
    "\n",
    "\n",
    "print(\"✅ LangGraph Step 4: Custom Action Nodes Defined (Revised)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749bc9a-64d0-4f0f-9800-ffa12b60558f",
   "metadata": {},
   "source": [
    "**Step 5: Conditional Edge Functions (Revised)**\n",
    "\n",
    "*   **`route_after_parsing`:** Simplified routing logic. Checks for specific intents (`aggregate_nutrition`, `customize`, `exit`) or tool calls. Uses `END` object correctly.\n",
    "*   **`route_after_action`:** **Changed significantly.** Now routes *all* `ToolMessage` results back to `InputParserNode` for the LLM to process/summarize. Routes based on `intent == \"customization_complete\"` to the formatter. This makes the flow more standard: `Parse -> Act -> Parse Results -> Format`.\n",
    "*   **`route_after_formatting`:** Logic remains the same (check header, route to visualize or end), but ensures it uses the `NUTRITION_RESPONSE_HEADER` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2496dd65-7d45-4c6b-b9e3-92fd0a659ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 5: Conditional Edge Functions Defined (Revised)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 5: Conditional Edge Functions (Revised)\n",
    "\n",
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "# --- Assume KitchenState is defined ---\n",
    "# from step1_state import KitchenState\n",
    "# --- Assume NUTRITION_RESPONSE_HEADER constant is defined ---\n",
    "# from step2_core import NUTRITION_RESPONSE_HEADER\n",
    "\n",
    "# --- Conditional Edge Functions ---\n",
    "\n",
    "def route_after_parsing(state: KitchenState) -> Literal[\n",
    "    \"ToolExecutorNode\", \"RecipeCustomizationNode\", \"AggregateNutritionNode\",\n",
    "    \"ResponseFormatterNode\", END # Use END object type hint\n",
    "]:\n",
    "    \"\"\"\n",
    "    Routes after the InputParserNode based on intent or presence of tool calls.\n",
    "    - Tool calls -> ToolExecutorNode\n",
    "    - Specific intents ('aggregate_nutrition', 'customize') -> Corresponding Node\n",
    "    - 'exit' intent -> END\n",
    "    - Otherwise (general chat, clarification, error) -> ResponseFormatterNode\n",
    "    \"\"\"\n",
    "    print(\"---ROUTING (After Parsing)---\")\n",
    "    intent = state.get(\"intent\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    has_tool_calls = isinstance(last_message, AIMessage) and bool(last_message.tool_calls)\n",
    "\n",
    "    print(f\"Routing based on: Intent='{intent}', HasToolCalls={has_tool_calls}\")\n",
    "\n",
    "    if intent == \"aggregate_nutrition\":\n",
    "        print(\"Routing to: AggregateNutritionNode\")\n",
    "        return \"AggregateNutritionNode\"\n",
    "    elif has_tool_calls:\n",
    "        # Let the ToolExecutor handle all tool calls, including 'customize_recipe' if called by LLM\n",
    "        print(\"Routing to: ToolExecutorNode\")\n",
    "        return \"ToolExecutorNode\"\n",
    "    elif intent == \"customize\":\n",
    "        # Route to customization node if intent is set (e.g., by parser for placeholder)\n",
    "        print(\"Routing to: RecipeCustomizationNode (Intent-based)\")\n",
    "        return \"RecipeCustomizationNode\"\n",
    "    elif intent == \"exit\" or state.get(\"finished\"): # Check finished flag too\n",
    "        print(\"Routing to: END\")\n",
    "        return END # Use the imported END object\n",
    "    else: # general_chat, clarification_needed, error, or AI response without tool calls\n",
    "        print(\"Routing to: ResponseFormatterNode\")\n",
    "        return \"ResponseFormatterNode\"\n",
    "\n",
    "\n",
    "def route_after_action(state: KitchenState) -> Literal[\n",
    "    \"InputParserNode\", \"ResponseFormatterNode\"\n",
    "]:\n",
    "    \"\"\"\n",
    "    Routes after ToolExecutorNode or RecipeCustomizationNode.\n",
    "    - Tool results (ToolMessage) -> InputParserNode (for LLM to process/summarize).\n",
    "    - Customization node results ('customization_complete' intent) -> ResponseFormatterNode.\n",
    "    - Fallback -> InputParserNode.\n",
    "    \"\"\"\n",
    "    print(\"---ROUTING (After Action)---\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    intent = state.get(\"intent\") # Check intent set by the action node\n",
    "\n",
    "    print(f\"Routing based on: LastMessageType={type(last_message).__name__}, Intent='{intent}'\")\n",
    "\n",
    "    if isinstance(last_message, ToolMessage):\n",
    "        # Always send tool results back to the parser for the LLM to interpret\n",
    "        print(\"Routing to: InputParserNode (Process Tool Results)\")\n",
    "        return \"InputParserNode\"\n",
    "    elif intent == \"customization_complete\": # Check intent set by customization node\n",
    "         print(\"Routing to: ResponseFormatterNode (After Customization)\")\n",
    "         return \"ResponseFormatterNode\"\n",
    "    else:\n",
    "         # Fallback: If an action node didn't produce a ToolMessage or set a specific intent,\n",
    "         # send back to parser to figure out the next step.\n",
    "         print(\"Routing to: InputParserNode (Fallback after action)\")\n",
    "         return \"InputParserNode\"\n",
    "\n",
    "\n",
    "def route_after_formatting(state: KitchenState) -> Literal[\"VisualizeNutritionNode\", END]:\n",
    "    \"\"\"\n",
    "    Decides whether to visualize nutrition data after formatting the response.\n",
    "    Checks if the final response contains the specific nutrition header.\n",
    "    \"\"\"\n",
    "    print(\"---ROUTING (After Formatting)---\")\n",
    "    final_response = state.get(\"last_assistant_response\")\n",
    "\n",
    "    # Check if the specific header used by the formatter exists in the final response\n",
    "    # Ensure NUTRITION_RESPONSE_HEADER is accessible\n",
    "    try:\n",
    "        header_check = NUTRITION_RESPONSE_HEADER\n",
    "    except NameError:\n",
    "        print(\"Warning: NUTRITION_RESPONSE_HEADER not found for routing check.\")\n",
    "        header_check = \"Here's the approximate average nutrition\" # Fallback check\n",
    "\n",
    "    if final_response and header_check in final_response:\n",
    "        print(\"Routing to: VisualizeNutritionNode\")\n",
    "        return \"VisualizeNutritionNode\"\n",
    "    else:\n",
    "        print(\"Routing to: END (No visualization needed)\")\n",
    "        return END # Use the imported END object\n",
    "\n",
    "\n",
    "print(\"✅ LangGraph Step 5: Conditional Edge Functions Defined (Revised)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddeb03-c81f-49b5-9c8b-70e75fbffdd5",
   "metadata": {},
   "source": [
    "**Step 6: Graph Assembly & Compilation (Revised)**\n",
    "\n",
    "*   Adjusted edges based on the revised routing logic:\n",
    "    *   `ToolExecutorNode` now conditionally routes back to `InputParserNode` or `ResponseFormatterNode` (via `route_after_action`).\n",
    "    *   `AggregateNutritionNode` output goes to `ResponseFormatterNode`.\n",
    "    *   `ResponseFormatterNode` conditionally routes to `VisualizeNutritionNode` or `END` (via `route_after_formatting`).\n",
    "    *   `VisualizeNutritionNode` now leads directly to `END`.\n",
    "*   Added a comment acknowledging the potential `mermaid.ink` timeout issue for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e69e8f9-9bbb-4b8c-9751-b132a6bee081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ LangGraph Step 6: Graph Compiled Successfully! (Revised Flow)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 6: Graph Assembly & Compilation (Revised)\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# --- Assume KitchenState, Nodes, Edges are defined ---\n",
    "# from step1_state import KitchenState\n",
    "# from step3_5_nodes import input_parser_node, response_formatter_node # etc. (Note the new step number)\n",
    "# from step3_tools import tool_executor_node\n",
    "# from step4_actions import recipe_customization_node, aggregate_nutrition_node, visualize_nutrition_node\n",
    "# from step5_routing import route_after_parsing, route_after_action, route_after_formatting\n",
    "\n",
    "# --- Graph Assembly ---\n",
    "graph_builder = StateGraph(KitchenState)\n",
    "\n",
    "# Add Nodes (Ensure names match function names)\n",
    "graph_builder.add_node(\"InputParserNode\", input_parser_node)\n",
    "graph_builder.add_node(\"ToolExecutorNode\", tool_executor_node)\n",
    "graph_builder.add_node(\"RecipeCustomizationNode\", recipe_customization_node)\n",
    "graph_builder.add_node(\"AggregateNutritionNode\", aggregate_nutrition_node)\n",
    "graph_builder.add_node(\"ResponseFormatterNode\", response_formatter_node)\n",
    "graph_builder.add_node(\"VisualizeNutritionNode\", visualize_nutrition_node)\n",
    "\n",
    "# Define Entry Point\n",
    "graph_builder.add_edge(START, \"InputParserNode\")\n",
    "\n",
    "# Define Conditional Edges from Parser\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"InputParserNode\",\n",
    "    route_after_parsing,\n",
    "    {\n",
    "        \"ToolExecutorNode\": \"ToolExecutorNode\",\n",
    "        \"RecipeCustomizationNode\": \"RecipeCustomizationNode\",\n",
    "        \"AggregateNutritionNode\": \"AggregateNutritionNode\",\n",
    "        \"ResponseFormatterNode\": \"ResponseFormatterNode\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define Edges After Tool Execution or Customization Action\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"ToolExecutorNode\",\n",
    "    route_after_action,\n",
    "    {\n",
    "        \"InputParserNode\": \"InputParserNode\",\n",
    "        \"ResponseFormatterNode\": \"ResponseFormatterNode\" # Fallback/alternative path\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"RecipeCustomizationNode\",\n",
    "    route_after_action,\n",
    "     {\n",
    "        \"InputParserNode\": \"InputParserNode\", # Could go back to parser\n",
    "        \"ResponseFormatterNode\": \"ResponseFormatterNode\" # Usually goes to formatter\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# After aggregation, format the response\n",
    "graph_builder.add_edge(\"AggregateNutritionNode\", \"ResponseFormatterNode\")\n",
    "\n",
    "# After formatting, decide whether to visualize or end the turn\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"ResponseFormatterNode\",\n",
    "    route_after_formatting,\n",
    "    {\n",
    "        \"VisualizeNutritionNode\": \"VisualizeNutritionNode\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After visualization, the graph run ends for this turn\n",
    "graph_builder.add_edge(\"VisualizeNutritionNode\", END)\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "kitchen_assistant_graph = graph_builder.compile()\n",
    "\n",
    "print(\"\\n✅ LangGraph Step 6: Graph Compiled Successfully! (Revised Flow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42d9907e-d40d-486c-b844-595c00644f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph visualization displayed.\n"
     ]
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "# Note: mermaid.ink can be unreliable or time out. Graphviz local install is more robust.\n",
    "try:\n",
    "    # Set a longer timeout if needed, e.g., timeout=30\n",
    "    png_data = kitchen_assistant_graph.get_graph().draw_mermaid_png()\n",
    "    display(Image(png_data))\n",
    "    print(\"Graph visualization displayed.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nGraph visualization failed: {e}\")\n",
    "    print(\"This might be due to a network issue with mermaid.ink or missing/misconfigured graphviz.\")\n",
    "    print(\"Ensure graphviz is installed (`pip install graphviz` and potentially OS-level install: `sudo apt-get install graphviz` on Debian/Ubuntu).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53897fc7-e931-4056-9510-c14a76fc8cbe",
   "metadata": {},
   "source": [
    "**Step 7: User Interface Integration (Revised)**\n",
    "\n",
    "*   **Removed** the explicit call to `extract_and_visualize_nutrition` from the `run_graph_and_display` function. The visualization is now handled *within* the graph by the `VisualizeNutritionNode`.\n",
    "*   Improved the display loop to show the *final* assistant response from the state correctly, even if it wasn't the content of the very last message object (e.g., if the formatter added a message).\n",
    "*   Added robustness to the voice transcription call (using a placeholder if the API key is missing, which is common in test environments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e58977be-102a-411a-9a5a-d9b5fd1cc832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Kitchen Assistant Interface ---\n",
      "Uncomment for using UI for interacting with agent! Yaaaay! :)\n",
      "✅ LangGraph Step 7: UI Integration Setup Complete (Revised)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 7: User Interface Integration (Revised)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "\n",
    "# --- Assume KitchenState, Graph, transcribe_audio are defined ---\n",
    "# from step1_state import KitchenState\n",
    "# from step6_graph import kitchen_assistant_graph\n",
    "# from step0_utils import transcribe_audio # Or wherever it's defined\n",
    "\n",
    "# --- UI Simulation using ipywidgets ---\n",
    "\n",
    "# Conversation state (global for this simple example)\n",
    "# Reset state for UI interaction\n",
    "conversation_state: KitchenState = {\n",
    "    \"messages\": [], \"user_input\": None, \"audio_file_path\": None, \"intent\": None,\n",
    "    \"selected_recipe_id\": None, \"customization_request\": None, \"nutrition_query\": None,\n",
    "    \"grounding_query\": None, \"current_recipe_details\": None, \"recipe_reviews\": None,\n",
    "    \"ingredient_nutrition_list\": None, \"nutritional_info\": None, \"grounding_results_formatted\": None,\n",
    "    \"user_ingredients\": [], \"dietary_preferences\": [],\n",
    "    \"needs_clarification\": False, \"finished\": False, \"last_assistant_response\": None,\n",
    "}\n",
    "\n",
    "# Widgets\n",
    "text_input = widgets.Textarea(description=\"You:\", layout={'width': '90%'})\n",
    "text_submit_button = widgets.Button(description=\"Send Text\")\n",
    "# Define voice options (use actual paths accessible to your environment)\n",
    "# IMPORTANT: Update these paths to valid .ogg or .wav files if needed\n",
    "default_voice_path = \"/kaggle/input/some-audio-dataset/audio.ogg\" # Example placeholder\n",
    "voice_options = [\n",
    "    (\"Select Voice...\", None),\n",
    "    # (\"Pizza Search (Simulated)\", \"/path/to/your/pizza_search.ogg\"), # Replace with valid paths\n",
    "    # (\"Baking a Cake (Simulated)\", \"/path/to/your/baking_cake.ogg\"),\n",
    "]\n",
    "# Filter out options with non-existent files if needed before creating dropdown\n",
    "# valid_voice_options = [(name, path) for name, path in voice_options if path is None or os.path.exists(path)]\n",
    "# if len(valid_voice_options) <= 1: print(\"Warning: No valid voice file paths found.\")\n",
    "\n",
    "voice_dropdown = widgets.Dropdown(options=voice_options, description=\"Voice:\") # Use original options for now\n",
    "voice_submit_button = widgets.Button(description=\"Process Voice\")\n",
    "output_area = widgets.Output(layout={\n",
    "    'border': '1px solid black',\n",
    "    'height': '400px',\n",
    "    'overflow_y': 'scroll',\n",
    "    'width': '90%'\n",
    "})\n",
    "\n",
    "debug_output = widgets.Output(layout={\n",
    "    'border': '1px solid blue',\n",
    "    'height': '100px',\n",
    "    'overflow_y': 'scroll',\n",
    "    'width': '90%'\n",
    "})\n",
    "\n",
    "# Display initial welcome message\n",
    "with output_area:\n",
    "    print(\"Assistant: Welcome! Ask me about recipes, ingredients, or nutrition.\")\n",
    "    # Add initial AI message to state if desired\n",
    "    # conversation_state[\"messages\"].append(AIMessage(content=\"Welcome! Ask me about recipes, ingredients, or nutrition.\"))\n",
    "    # conversation_state[\"last_assistant_response\"] = \"Welcome! Ask me about recipes, ingredients, or nutrition.\"\n",
    "\n",
    "\n",
    "# --- Interaction Logic (Revised: Removed external visualization call) ---\n",
    "# Note: run_graph_and_display uses the 'conversation_state' global variable\n",
    "def run_graph_and_display(initial_state_update: Dict):\n",
    "    global conversation_state\n",
    "\n",
    "    # 1. Update state with the new input message and clear transient fields\n",
    "    current_messages = list(conversation_state.get(\"messages\", []))\n",
    "    if \"messages\" in initial_state_update:\n",
    "        current_messages.extend(initial_state_update[\"messages\"])\n",
    "\n",
    "    # Prepare the input state for the graph stream\n",
    "    input_for_graph = conversation_state.copy() # Start with current context\n",
    "    input_for_graph.update(initial_state_update) # Add new input/updates\n",
    "    input_for_graph[\"messages\"] = current_messages # Ensure messages are updated\n",
    "    # Clear fields that should be determined by the graph run\n",
    "    input_for_graph[\"intent\"] = None\n",
    "    input_for_graph[\"last_assistant_response\"] = None\n",
    "    input_for_graph[\"nutritional_info\"] = None\n",
    "    input_for_graph[\"needs_clarification\"] = False\n",
    "    # Keep context like selected_recipe_id unless overwritten by initial_state_update\n",
    "\n",
    "    # Display \"Thinking...\" and history\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        # Re-display history from the *current global state* before the run\n",
    "        for msg in conversation_state.get(\"messages\", []):\n",
    "             if isinstance(msg, HumanMessage): print(f\"You: {msg.content}\")\n",
    "             elif isinstance(msg, AIMessage) and msg.content: print(f\"Assistant: {msg.content}\")\n",
    "        # Display the *new* user input for this turn\n",
    "        if \"user_input\" in initial_state_update and initial_state_update[\"user_input\"]:\n",
    "             print(f\"You: {initial_state_update['user_input']}\")\n",
    "        print(\"\\nAssistant: Thinking...\") # Add newline for spacing\n",
    "\n",
    "    # 2. Stream graph execution\n",
    "    final_state_after_run = None\n",
    "    assistant_response_to_display = \"...\" # Default thinking message\n",
    "\n",
    "    try:\n",
    "        # Use stream to observe intermediate steps\n",
    "        for step_state in kitchen_assistant_graph.stream(input_for_graph, {\"recursion_limit\": 25}):\n",
    "            node_name = list(step_state.keys())[0]\n",
    "            current_state_snapshot = step_state[node_name]\n",
    "\n",
    "            # --- Debugging Output ---\n",
    "            with debug_output:\n",
    "                 # clear_output(wait=True) # Optional: Clear previous debug step\n",
    "                 print(f\"\\n--- Step: {node_name} ---\")\n",
    "                 print(f\"  Intent: {current_state_snapshot.get('intent')}\")\n",
    "                 print(f\"  Selected Recipe: {current_state_snapshot.get('selected_recipe_id')}\")\n",
    "                 print(f\"  Needs Clarification: {current_state_snapshot.get('needs_clarification')}\")\n",
    "                 print(f\"  Finished: {current_state_snapshot.get('finished')}\")\n",
    "                 last_msg = current_state_snapshot.get('messages', [])[-1] if current_state_snapshot.get('messages') else None\n",
    "                 if last_msg: print(f\"  Last Message Type: {type(last_msg).__name__}\")\n",
    "                 if isinstance(last_msg, AIMessage) and last_msg.tool_calls: print(f\"  Tool Calls: {[tc['name'] for tc in last_msg.tool_calls]}\")\n",
    "                 if isinstance(last_msg, ToolMessage): print(f\"  Tool Result ({last_msg.name}): {str(last_msg.content)[:100]}...\")\n",
    "                 if current_state_snapshot.get('nutritional_info'): print(f\"  Nutritional Info: Aggregated\")\n",
    "                 if current_state_snapshot.get('last_assistant_response'): print(f\"  Last Response Set: {current_state_snapshot.get('last_assistant_response')[:60]}...\")\n",
    "            # --- End Debugging ---\n",
    "\n",
    "            # Update global state progressively *after* processing the step\n",
    "            conversation_state.update(current_state_snapshot)\n",
    "            final_state_after_run = conversation_state # Keep track of the latest full state\n",
    "\n",
    "            if conversation_state.get(\"finished\", False):\n",
    "                print(\"--- Finished flag set, ending stream early. ---\")\n",
    "                assistant_response_to_display = conversation_state.get(\"last_assistant_response\", \"Goodbye!\")\n",
    "                break\n",
    "\n",
    "        # After the stream finishes (or breaks)\n",
    "        if final_state_after_run:\n",
    "            conversation_state.update(final_state_after_run) # Ensure final state is captured\n",
    "            assistant_response_to_display = conversation_state.get(\"last_assistant_response\", \"Okay, what next?\")\n",
    "            if conversation_state.get(\"finished\"):\n",
    "                 assistant_response_to_display = conversation_state.get(\"last_assistant_response\", \"Goodbye!\")\n",
    "        else:\n",
    "             assistant_response_to_display = \"Something went wrong during processing (no final state).\"\n",
    "             conversation_state[\"last_assistant_response\"] = assistant_response_to_display\n",
    "             if \"messages\" not in conversation_state: conversation_state[\"messages\"] = []\n",
    "             conversation_state[\"messages\"].append(AIMessage(content=assistant_response_to_display))\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        assistant_response_to_display = f\"An error occurred during graph execution: {e}\"\n",
    "        print(f\"ERROR during graph execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print stack trace to debug output\n",
    "        conversation_state[\"last_assistant_response\"] = assistant_response_to_display\n",
    "        if \"messages\" not in conversation_state: conversation_state[\"messages\"] = []\n",
    "        conversation_state[\"messages\"].append(AIMessage(content=f\"Error: {e}\"))\n",
    "\n",
    "    # 3. Display the final conversation history and response for this turn\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"--- Conversation History ---\")\n",
    "        displayed_final_response = False\n",
    "        for msg in conversation_state.get(\"messages\", []):\n",
    "             msg_content = getattr(msg, 'content', '')\n",
    "             if isinstance(msg, HumanMessage):\n",
    "                 print(f\"You: {msg_content}\")\n",
    "             elif isinstance(msg, AIMessage) and msg_content:\n",
    "                 print(f\"Assistant: {msg_content}\")\n",
    "                 if msg_content == assistant_response_to_display:\n",
    "                      displayed_final_response = True\n",
    "             elif isinstance(msg, ToolMessage):\n",
    "                 print(f\"  [Tool Result ({msg.name}): {str(msg_content)[:100]}...]\")\n",
    "             elif isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "                 print(f\"  [Assistant calling tools: {[tc['name'] for tc in msg.tool_calls]}]\")\n",
    "\n",
    "        if assistant_response_to_display and not displayed_final_response and not conversation_state.get(\"finished\"):\n",
    "             # Only print if it wasn't part of the message history already and not finished\n",
    "             print(f\"Assistant: {assistant_response_to_display}\")\n",
    "\n",
    "\n",
    "    # 4. Visualization is handled INSIDE the graph by VisualizeNutritionNode\n",
    "\n",
    "def on_text_submit(b):\n",
    "    user_text = text_input.value\n",
    "    if not user_text: return\n",
    "    initial_update = {\n",
    "        \"user_input\": user_text,\n",
    "        \"messages\": [HumanMessage(content=user_text)],\n",
    "        \"finished\": False # Reset finished flag on new input\n",
    "        }\n",
    "    text_input.value = \"\" # Clear input\n",
    "    run_graph_and_display(initial_update)\n",
    "\n",
    "def on_voice_submit(b):\n",
    "     selected_file = voice_dropdown.value\n",
    "     if not selected_file:\n",
    "         with output_area: clear_output(wait=True); print(\"Assistant: Please select a voice file.\")\n",
    "         return\n",
    "\n",
    "     if not os.path.exists(selected_file):\n",
    "          with output_area: clear_output(wait=True); print(f\"Assistant: Error - Voice file not found at path: {selected_file}\")\n",
    "          return\n",
    "\n",
    "     with output_area: clear_output(wait=True); print(f\"Processing voice file: {os.path.basename(selected_file)}...\")\n",
    "\n",
    "     transcribed_text = \"Error: Transcription setup failed.\"\n",
    "     try:\n",
    "         google_creds = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "         openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "         if google_creds and os.path.exists(google_creds):\n",
    "              try:\n",
    "                  import io\n",
    "                  from google.cloud import speech\n",
    "                  print(\"Attempting transcription with Google Cloud Speech...\")\n",
    "                  transcribed_text = transcribe_audio(service=\"google\", file_path=selected_file, credentials_path=google_creds)\n",
    "              except ImportError:\n",
    "                   print(\"Google Cloud Speech library not installed. Skipping Google transcription.\")\n",
    "                   transcribed_text = \"Error: Google Speech library missing.\"\n",
    "              except Exception as google_err:\n",
    "                   print(f\"Google transcription failed: {google_err}\")\n",
    "                   transcribed_text = f\"Error: Google transcription failed - {google_err}\"\n",
    "\n",
    "         elif openai_key:\n",
    "              try:\n",
    "                  from openai import OpenAI # Ensure OpenAI is imported if used\n",
    "                  print(\"Attempting transcription with OpenAI Whisper...\")\n",
    "                  transcribed_text = transcribe_audio(service=\"openai\", file_path=selected_file, api_key=openai_key)\n",
    "              except ImportError:\n",
    "                   print(\"OpenAI library not installed. Skipping OpenAI transcription.\")\n",
    "                   transcribed_text = \"Error: OpenAI library missing.\"\n",
    "              except Exception as openai_err:\n",
    "                   print(f\"OpenAI transcription failed: {openai_err}\")\n",
    "                   transcribed_text = f\"Error: OpenAI transcription failed - {openai_err}\"\n",
    "         else:\n",
    "              print(\"Neither Google Credentials nor OpenAI API Key found in environment.\")\n",
    "              transcribed_text = \"Error: No transcription service configured (API keys/credentials missing).\"\n",
    "\n",
    "     except Exception as e:\n",
    "          print(f\"Unexpected error during transcription setup: {e}\")\n",
    "          transcribed_text = f\"Error: Transcription failed unexpectedly - {e}\"\n",
    "\n",
    "\n",
    "     if \"Error:\" in transcribed_text:\n",
    "          with output_area: clear_output(wait=True); print(f\"Assistant: Transcription failed - {transcribed_text}\")\n",
    "          return\n",
    "\n",
    "     initial_update = {\n",
    "         \"user_input\": transcribed_text,\n",
    "         \"messages\": [HumanMessage(content=transcribed_text)],\n",
    "         \"audio_file_path\": selected_file,\n",
    "         \"finished\": False\n",
    "     }\n",
    "     voice_dropdown.value = None # Reset dropdown\n",
    "     run_graph_and_display(initial_update)\n",
    "\n",
    "# Assign callbacks\n",
    "text_submit_button.on_click(on_text_submit)\n",
    "voice_submit_button.on_click(on_voice_submit)\n",
    "\n",
    "# Display Widgets\n",
    "print(\"--- Kitchen Assistant Interface ---\")\n",
    "\n",
    "print(\"Uncomment for using UI for interacting with agent! Yaaaay! :)\")\n",
    "# display(widgets.VBox([\n",
    "#     widgets.HTML(\"<b>Enter request via text or select voice file:</b>\"),\n",
    "#     text_input, text_submit_button, widgets.HTML(\"<hr>\"),\n",
    "#     voice_dropdown, voice_submit_button, widgets.HTML(\"<hr><b>Conversation:</b>\"),\n",
    "#     output_area, widgets.HTML(\"<hr><b>Debug Log (Graph Steps):</b>\"), debug_output\n",
    "# ]))\n",
    "\n",
    "print(\"✅ LangGraph Step 7: UI Integration Setup Complete (Revised)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e074851-be5c-4b79-893c-1638ea521789",
   "metadata": {},
   "source": [
    "**Step 8: Testing and Refinement Setup (Revised)**\n",
    "\n",
    "*   **Fixed Test Runner Bug:** Corrected the `TypeError: 'str' object is not callable` by properly accessing the class name using `msg.__class__.__name__`.\n",
    "*   **Coherent Test Scenario:** Replaced the disconnected tests with a multi-turn scenario simulating a more realistic user interaction flow: Search -> Select -> Details/Reviews -> Nutrition -> Grounding -> Exit.\n",
    "*   **Updated Expectations:** Adjusted `expected_intent` and `expected_tool_calls` based on the new scenario flow and revised graph logic.\n",
    "*   **Mocking/Error Handling for Tests:**\n",
    "    *   Modified the `google_search` call *within the test setup* to return a simulated success string if API keys are missing, preventing test failure due to configuration.\n",
    "    *   Modified the `transcribe_audio` call *within the test setup* to use hardcoded text, making the voice test independent of actual file presence or API keys during automated testing.\n",
    "*   **Refinement Notes:** Kept the refinement notes section as it provides valuable guidance. Displayed the *revised* system prompt for easier review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88589fd2-d15a-44b7-b337-d56ffa9ca5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efdd5f-d3c6-4344-8056-50b443708aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3de4c20-15ed-4541-b5e7-10e2e285bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph Step 8: Chat Helper Function Defined (Corrected)\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Step 8: Chat Helper Function (Corrected)\n",
    "\n",
    "# ---> ADD THESE IMPORTS AND FUNCTION DEFINITION <---\n",
    "import sys\n",
    "import contextlib\n",
    "from io import StringIO\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage # Ensure all needed types are imported\n",
    "\n",
    "# Utility to suppress stdout (to hide LangGraph internal logs)\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = StringIO()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "# ---> END OF ADDED CODE <---\n",
    "\n",
    "\n",
    "# Function with external state input/output (REVERTED to simpler version)\n",
    "def chat_with_assistant(user_msg: str, state: dict) -> dict:\n",
    "    \"\"\"Runs a turn of the conversation with the LangGraph agent.\"\"\"\n",
    "    # Initialize state if it's the first turn or empty\n",
    "    if not state:\n",
    "        state = {\"messages\": []}\n",
    "    elif \"messages\" not in state:\n",
    "        state[\"messages\"] = []\n",
    "\n",
    "    # Append new HumanMessage to message history IN THE STATE DICTIONARY\n",
    "    # add_messages reducer in the graph will handle accumulation.\n",
    "    state[\"messages\"] = state.get(\"messages\", []) + [HumanMessage(content=user_msg)]\n",
    "    # Also update user_input for potential use within the graph if needed by logic/prompt\n",
    "    state[\"user_input\"] = user_msg\n",
    "    state[\"finished\"] = False # Ensure finished flag is reset on new input\n",
    "\n",
    "    # Suppress verbose internal logs during invocation\n",
    "    final_state = {}\n",
    "    print(f\"\\n--- Invoking Graph for: '{user_msg[:50]}...' ---\")\n",
    "    with suppress_stdout():\n",
    "        try:\n",
    "            # Invoke the graph, passing the entire updated state dictionary\n",
    "            final_state = kitchen_assistant_graph.invoke(state)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during graph invocation: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Create a minimal error state to return\n",
    "            final_state = state.copy() # Start with input state\n",
    "            error_content = f\"Sorry, an error occurred: {e}\"\n",
    "            final_state[\"messages\"] = final_state.get(\"messages\", []) + [AIMessage(content=error_content)]\n",
    "            final_state[\"last_assistant_response\"] = error_content\n",
    "            final_state[\"intent\"] = \"error\"\n",
    "\n",
    "    print(\"--- Graph Invocation Complete ---\")\n",
    "\n",
    "    # --- Message Filtering (Optional but good for clean display) ---\n",
    "    filtered_msgs = []\n",
    "    seen_contents = set()\n",
    "    if \"messages\" in final_state:\n",
    "        for msg in final_state[\"messages\"]:\n",
    "            msg_content = getattr(msg, 'content', None)\n",
    "            # Keep Human messages and unique AI messages with content\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                 filtered_msgs.append(msg)\n",
    "                 if msg_content: seen_contents.add(msg_content) # Add human msg to seen\n",
    "            elif isinstance(msg, AIMessage) and msg_content and msg_content not in seen_contents:\n",
    "                seen_contents.add(msg_content)\n",
    "                filtered_msgs.append(msg)\n",
    "            # Keep Tool messages or AI messages without content (e.g., only tool calls)\n",
    "            elif not isinstance(msg, (HumanMessage)) and (not hasattr(msg, 'content') or not msg_content):\n",
    "                 filtered_msgs.append(msg)\n",
    "            elif isinstance(msg, ToolMessage): # Explicitly keep tool messages\n",
    "                 filtered_msgs.append(msg)\n",
    "\n",
    "        final_state[\"messages\"] = filtered_msgs\n",
    "    # --- End Filtering ---\n",
    "\n",
    "    # Print the last Human and AI messages from the final state\n",
    "    print(\"--- Displaying Interaction ---\")\n",
    "    if final_state.get(\"messages\"):\n",
    "        try:\n",
    "            # Find last human message\n",
    "            recent_human = next(msg for msg in reversed(final_state[\"messages\"]) if isinstance(msg, HumanMessage))\n",
    "            # Find last AI message that has displayable content\n",
    "            recent_ai = next((msg for msg in reversed(final_state[\"messages\"]) if isinstance(msg, AIMessage) and getattr(msg, 'content', None)), None)\n",
    "\n",
    "            print(f\"🧑 You: {recent_human.content}\")\n",
    "            if recent_ai:\n",
    "                print(f\"🤖 AI: {recent_ai.content}\")\n",
    "            else:\n",
    "                # Maybe the last message was a tool call or error without content\n",
    "                 last_msg = final_state[\"messages\"][-1] if final_state[\"messages\"] else None\n",
    "                 if last_msg:\n",
    "                     print(f\"(Last message type: {type(last_msg).__name__}, no displayable AI content)\")\n",
    "                 else:\n",
    "                      print(\"⚠️ No AI response found.\")\n",
    "\n",
    "        except StopIteration:\n",
    "             # Handle cases where there isn't a human or AI message with content yet\n",
    "             last_msg = final_state[\"messages\"][-1] if final_state[\"messages\"] else None\n",
    "             if last_msg:\n",
    "                 print(f\"Last message type: {type(last_msg).__name__}\")\n",
    "                 if hasattr(last_msg, 'content'):\n",
    "                     print(f\"Content: {str(last_msg.content)[:100]}...\")\n",
    "             print(\"⚠️ Not enough message history for standard display.\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️ No messages found in the final state.\")\n",
    "\n",
    "    # Ensure last_assistant_response is set in the returned state for UI/next turn\n",
    "    if final_state.get(\"messages\"):\n",
    "         last_ai = next((msg for msg in reversed(final_state[\"messages\"]) if isinstance(msg, AIMessage) and getattr(msg, 'content', None)), None)\n",
    "         if last_ai:\n",
    "             final_state[\"last_assistant_response\"] = last_ai.content\n",
    "         elif \"last_assistant_response\" not in final_state: # Handle error cases where it might be missing\n",
    "              final_state[\"last_assistant_response\"] = \"Processing resulted in no displayable response.\"\n",
    "\n",
    "\n",
    "    return final_state # Return the full state returned by the graph invoke\n",
    "\n",
    "print(\"✅ LangGraph Step 8: Chat Helper Function Defined (Corrected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "203a6632-43e0-4d00-83ec-a189fea9dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}  # Initialize empty state first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f724d00-0241-4c66-8aee-56da27214b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking Graph for: 'Hello, what can you do?...' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snowholt/venv/analytic/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Graph Invocation Complete ---\n",
      "--- Displaying Interaction ---\n",
      "🧑 You: Hello, what can you do?\n",
      "🤖 AI: Hello! I can help you discover new recipes, give you detailed information about specific recipes, find ratings and reviews, provide nutrition information for ingredients, and even customize recipes. What are you in the mood for today?\n"
     ]
    }
   ],
   "source": [
    "state = chat_with_assistant(\"Hello, what can you do?\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "741d48ed-38d9-4639-b9af-6b3604e70353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking Graph for: 'Find me vegeterian soup recipes and tag the recipe...' ---\n",
      "--- Graph Invocation Complete ---\n",
      "--- Displaying Interaction ---\n",
      "🧑 You: Find me vegeterian soup recipes and tag the recipes. 5 recipes\n",
      "🤖 AI: Here are 5 vegetarian soup recipes I found:\n",
      "\n",
      "1.  **yogurt and cucumber soup** (Thai, 210 minutes, ID: 128684)\n",
      "2.  **soupe au pistou from nice** (French, 40 minutes, ID: 184537)\n",
      "3.  **greek barley soup** (Other, 75 minutes, ID: 37706)\n",
      "4.  **newfoundland style pea soup with doughboys dumplings** (Other, 270 minutes, ID: 332086)\n",
      "5.  **broccoli and cheese potato soup** (Other, 40 minutes, ID: 104304)\n",
      "\n",
      "Would you like more details on any of these recipes?\n"
     ]
    }
   ],
   "source": [
    "state = chat_with_assistant(\"Find me vegeterian soup recipes and tag the recipes. 5 recipes\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "957163e5-ba86-4a10-990a-9001e390fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking Graph for: 'I like to know about second recipe in the list...' ---\n",
      "--- Graph Invocation Complete ---\n",
      "--- Displaying Interaction ---\n",
      "🧑 You: I like to know about second recipe in the list\n",
      "🤖 AI: The second recipe, **soupe au pistou from nice**, is a simple and flavorful French vegetarian vegetable soup. Here's a summary:\n",
      "\n",
      "*   **Description:** A simple and flavorful vegetable soup from the soup bible by debra mayhew. The combination of pesto and sun-dried tomato paste is an inspired touch.\n",
      "*   **Cuisine:** French\n",
      "*   **Dietary Tags:** Vegetarian\n",
      "*   **Prep Time:** 40 minutes\n",
      "*   **Ingredients:** vegetable stock, zucchini, potato, shallot, carrot, chopped tomatoes, salt and pepper, green beans, frozen baby peas, pasta, pesto sauce, sun-dried tomato paste, parmesan cheese\n",
      "*   **Steps:**\n",
      "    1.  Place vegetable stock in a large saucepan.\n",
      "    2.  Add zucchini through tomatoes and season with salt and pepper bring to a boil.\n",
      "    3.  Cover.\n",
      "    4.  Lower heat and simmer 20 minutes add green beans through pasta and cook about 10 minutes longer until pasta is tender adjust seasonings if necessary Whisk together pesto and sundried tomato paste Ladle soup into 4 bowls and stir a spoonful of the pesto mixture into each Pass around grated parmesan to be sprinkled on soup.\n",
      "    5.  If desired\n",
      "\n",
      "Would you like to see ratings and reviews for this recipe, or perhaps explore other recipes?\n"
     ]
    }
   ],
   "source": [
    "state = chat_with_assistant(\"I like to know about second recipe in the list\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a657b2d7-f3ce-4bf7-a668-4275b692df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking Graph for: 'Great, show the review of that recipe...' ---\n",
      "--- Graph Invocation Complete ---\n",
      "--- Displaying Interaction ---\n",
      "🧑 You: Great, show the review of that recipe\n",
      "🤖 AI: OK, here are the ratings and reviews for **soupe au pistou from nice**:\n",
      "\n",
      "*   **Overall Rating:** 5 stars\n",
      "*   **Recent Reviews:**\n",
      "    *   \"Fantastic soup! Tasted almost like Minestrone (my favorite soup) with pesto and sundried tomato paste which gave it really nice flavor. I used penne pasta. Thanks echo echo, I'll be making this again!\" (November 19, 2007)\n",
      "    *   \"I have a cold and this soup really hit the spot! I didn't have shallots so used yellow onion and for the pasta used orzo. Thanks! Made for Zaar Tag.\" (November 10, 2007)\n",
      "\n",
      "Do you want to know the nutrition information for any ingredient in the recipe?\n"
     ]
    }
   ],
   "source": [
    "state = chat_with_assistant(\"Great, show the review of that recipe\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39570d5d-8cd4-4644-8f2a-b78309bf1874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking Graph for: 'Get nutrition information of recipe_...' ---\n",
      "--- Graph Invocation Complete ---\n",
      "--- Displaying Interaction ---\n",
      "🧑 You: Get nutrition information of recipe_\n",
      "🤖 AI: Here's the approximate average nutrition per 100g for ingredients in **recipe 184537**:\n",
      "\n",
      "\n",
      "(Note: Could not retrieve nutrition data for the ingredients.)\n"
     ]
    }
   ],
   "source": [
    "state = chat_with_assistant(\"Get nutrition information of recipe_\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9155783-c37e-4fbc-8872-9002abfa3ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking Graph for: 'What's a good substitute for zucchini in soupe au ...' ---\n",
      "--- Graph Invocation Complete ---\n",
      "--- Displaying Interaction ---\n",
      "🧑 You: What's a good substitute for zucchini in soupe au pistou from nice?\n",
      "🤖 AI: Based on a quick search, a good substitute for zucchini in soupe au pistou is yellow squash. It has a similar mild flavor and texture. You could also use other summer squashes like crookneck squash.\n"
     ]
    }
   ],
   "source": [
    "state = chat_with_assistant(\"What's a good substitute for zucchini in soupe au pistou from nice?\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82eebbab-7fdc-4e48-b6ce-fb5cf495358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, what can you do?', additional_kwargs={}, response_metadata={}, id='e6807b8e-a70e-4658-8940-b1054404e815'),\n",
       " AIMessage(content='Hello! I can help you discover new recipes, give you detailed information about specific recipes, find ratings and reviews, provide nutrition information for ingredients, and even customize recipes. What are you in the mood for today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-9a82fe2b-b5f8-4a0f-9974-e174c6d80918-0', usage_metadata={'input_tokens': 2399, 'output_tokens': 44, 'total_tokens': 2443, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='Find me vegeterian soup recipes and tag the recipes. 5 recipes', additional_kwargs={}, response_metadata={}, id='37d92246-f2b2-4179-939a-e64ca071131f'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'gemini_recipe_similarity_search', 'arguments': '{\"query_text\": \"vegeterian soup recipes\", \"n_results\": 5.0, \"dietary_tag\": \"vegetarian\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-ea7983bd-85d9-4baa-be7e-3e53e125c1d0-0', tool_calls=[{'name': 'gemini_recipe_similarity_search', 'args': {'query_text': 'vegeterian soup recipes', 'n_results': 5.0, 'dietary_tag': 'vegetarian'}, 'id': '5eed440f-d817-4df1-b531-4f4543fecf5d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2457, 'output_tokens': 23, 'total_tokens': 2480, 'input_token_details': {'cache_read': 0}}),\n",
       " ToolMessage(content='[\\n  {\\n    \"recipe_id\": \"128684\",\\n    \"name\": \"yogurt and cucumber soup\",\\n    \"minutes\": \"210\",\\n    \"cuisine_type\": \"thai\",\\n    \"dietary_tags\": [\\n      \"vegetarian\"\\n    ],\\n    \"similarity_score\": 29.09\\n  },\\n  {\\n    \"recipe_id\": \"184537\",\\n    \"name\": \"soupe au pistou from nice\",\\n    \"minutes\": \"40\",\\n    \"cuisine_type\": \"french\",\\n    \"dietary_tags\": [\\n      \"vegetarian\"\\n    ],\\n    \"similarity_score\": 24.68\\n  },\\n  {\\n    \"recipe_id\": \"37706\",\\n    \"name\": \"greek barley soup\",\\n    \"minutes\": \"75\",\\n    \"cuisine_type\": \"other\",\\n    \"dietary_tags\": [\\n      \"vegetarian\"\\n    ],\\n    \"similarity_score\": 24.27\\n  },\\n  {\\n    \"recipe_id\": \"332086\",\\n    \"name\": \"newfoundland style pea soup with doughboys  dumplings\",\\n    \"minutes\": \"270\",\\n    \"cuisine_type\": \"other\",\\n    \"dietary_tags\": [\\n      \"vegetarian\"\\n    ],\\n    \"similarity_score\": 24.18\\n  },\\n  {\\n    \"recipe_id\": \"104304\",\\n    \"name\": \"broccoli and cheese potato soup\",\\n    \"minutes\": \"40\",\\n    \"cuisine_type\": \"other\",\\n    \"dietary_tags\": [\\n      \"vegetarian\"\\n    ],\\n    \"similarity_score\": 24.1\\n  }\\n]', name='gemini_recipe_similarity_search', id='87233f19-ae60-4416-8170-11164acbd15e', tool_call_id='5eed440f-d817-4df1-b531-4f4543fecf5d'),\n",
       " AIMessage(content='Here are 5 vegetarian soup recipes I found:\\n\\n1.  **yogurt and cucumber soup** (Thai, 210 minutes, ID: 128684)\\n2.  **soupe au pistou from nice** (French, 40 minutes, ID: 184537)\\n3.  **greek barley soup** (Other, 75 minutes, ID: 37706)\\n4.  **newfoundland style pea soup with doughboys dumplings** (Other, 270 minutes, ID: 332086)\\n5.  **broccoli and cheese potato soup** (Other, 40 minutes, ID: 104304)\\n\\nWould you like more details on any of these recipes?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-612bb449-1ab1-402d-b2d1-bf2aa7f13b73-0', usage_metadata={'input_tokens': 2646, 'output_tokens': 174, 'total_tokens': 2820, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='I like to know about second recipe in the list', additional_kwargs={}, response_metadata={}, id='8d32cd61-6955-4c5f-b7ce-b95b95738592'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_recipe_by_id', 'arguments': '{\"recipe_id\": \"184537\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-5b8b358c-00f9-46c4-96e2-cffc5847938e-0', tool_calls=[{'name': 'get_recipe_by_id', 'args': {'recipe_id': '184537'}, 'id': 'cab9ef00-18c5-4d62-b376-6346dd92bb8d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2829, 'output_tokens': 16, 'total_tokens': 2845, 'input_token_details': {'cache_read': 0}}),\n",
       " ToolMessage(content='{\\n  \"id\": \"184537\",\\n  \"name\": \"soupe au pistou from nice\",\\n  \"minutes\": 40,\\n  \"contributor_id\": 121690,\\n  \"submitted\": \"2006-09-03\",\\n  \"tags\": [\\n    \"60-minutes-or-less time-to-make course main-ingredient cuisine preparation occasion lunch soups-stews vegetables french easy european dinner-party vegetarian stove-top dietary green-yellow-beans squash tomatoes taste-mood savory equipment\"\\n  ],\\n  \"nutrition\": [\\n    126.0,\\n    0.0,\\n    21.0,\\n    2.0,\\n    10.0,\\n    0.0,\\n    8.0\\n  ],\\n  \"n_steps\": 7,\\n  \"steps\": [\\n    \"place vegetable stock in a large saucepan\",\\n    \"add zucchini through tomatoes and season with salt and pepper bring to a boil\",\\n    \"cover\",\\n    \"lower heat and simmer 20 minutes add green beans through pasta and cook about 10 minutes longer until pasta is tender adjust seasonings if necessary whisk together pesto and sundried tomato paste ladle soup into 4 bowls and stir a spoonful of the pesto mixture into each pass around grated parmesan to be sprinkled on soup\",\\n    \"if desired\"\\n  ],\\n  \"description\": \"a simple and flavorful vegetable soup from the soup bible by debra mayhew. the combination of pesto and sundried tomato paste is an inspired touch.\",\\n  \"ingredients\": [\\n    \"vegetable stock zucchini potato shallot carrot chopped tomatoes salt and pepper green beans frozen baby peas pasta pesto sauce sun-dried tomato paste parmesan cheese\"\\n  ],\\n  \"n_ingredients\": 13,\\n  \"dietary_tags\": [\\n    \"vegetarian\"\\n  ],\\n  \"cuisine_type\": \"french\",\\n  \"normalized_ingredients\": [\\n    \"vegetable stock zucchini potato shallot carrot chopped tomatoes salt and pepper green beans frozen baby peas pasta pesto sauce sun-dried tomato paste parmesan cheese\"\\n  ]\\n}', name='get_recipe_by_id', id='f8acbd98-2eb2-4129-a016-3d0966946a12', tool_call_id='cab9ef00-18c5-4d62-b376-6346dd92bb8d'),\n",
       " AIMessage(content=\"The second recipe, **soupe au pistou from nice**, is a simple and flavorful French vegetarian vegetable soup. Here's a summary:\\n\\n*   **Description:** A simple and flavorful vegetable soup from the soup bible by debra mayhew. The combination of pesto and sun-dried tomato paste is an inspired touch.\\n*   **Cuisine:** French\\n*   **Dietary Tags:** Vegetarian\\n*   **Prep Time:** 40 minutes\\n*   **Ingredients:** vegetable stock, zucchini, potato, shallot, carrot, chopped tomatoes, salt and pepper, green beans, frozen baby peas, pasta, pesto sauce, sun-dried tomato paste, parmesan cheese\\n*   **Steps:**\\n    1.  Place vegetable stock in a large saucepan.\\n    2.  Add zucchini through tomatoes and season with salt and pepper bring to a boil.\\n    3.  Cover.\\n    4.  Lower heat and simmer 20 minutes add green beans through pasta and cook about 10 minutes longer until pasta is tender adjust seasonings if necessary Whisk together pesto and sundried tomato paste Ladle soup into 4 bowls and stir a spoonful of the pesto mixture into each Pass around grated parmesan to be sprinkled on soup.\\n    5.  If desired\\n\\nWould you like to see ratings and reviews for this recipe, or perhaps explore other recipes?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-667bf5ef-7651-4b41-bb2a-e24ce64bdead-0', usage_metadata={'input_tokens': 3124, 'output_tokens': 279, 'total_tokens': 3403, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='Great, show the review of that recipe', additional_kwargs={}, response_metadata={}, id='321580b4-542d-4ef5-9146-a71c37f50b67'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_ratings_and_reviews_by_recipe_id', 'arguments': '{\"limit\": 3.0, \"recipe_id\": \"184537\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-6430d844-0165-47b6-8baa-021428bb9dfd-0', tool_calls=[{'name': 'get_ratings_and_reviews_by_recipe_id', 'args': {'limit': 3.0, 'recipe_id': '184537'}, 'id': '28dc49d3-d5bc-461e-b854-a39381484598', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3410, 'output_tokens': 23, 'total_tokens': 3433, 'input_token_details': {'cache_read': 0}}),\n",
       " ToolMessage(content='{\\n  \"recipe_id\": \"184537\",\\n  \"overall_rating\": 5.0,\\n  \"recent_reviews\": [\\n    {\\n      \"date\": \"2007-11-19\",\\n      \"rating\": 5,\\n      \"review\": \"Fantastic soup!  Tasted almost like Minestrone (my favorite soup) with pesto and sundried tomato paste which gave it really nice flavor.  I used penne pasta.  Thanks echo echo, I\\'ll be making this again!\"\\n    },\\n    {\\n      \"date\": \"2007-11-10\",\\n      \"rating\": 5,\\n      \"review\": \"I have a cold and this soup really hit the spot! I didn\\'t have shallots so used yellow onion and for the pasta used orzo. Thanks! Made for Zaar Tag.\"\\n    }\\n  ]\\n}', name='get_ratings_and_reviews_by_recipe_id', id='9b6bc828-462e-458a-b42d-fc207eaae8c7', tool_call_id='28dc49d3-d5bc-461e-b854-a39381484598'),\n",
       " AIMessage(content='OK, here are the ratings and reviews for **soupe au pistou from nice**:\\n\\n*   **Overall Rating:** 5 stars\\n*   **Recent Reviews:**\\n    *   \"Fantastic soup! Tasted almost like Minestrone (my favorite soup) with pesto and sundried tomato paste which gave it really nice flavor. I used penne pasta. Thanks echo echo, I\\'ll be making this again!\" (November 19, 2007)\\n    *   \"I have a cold and this soup really hit the spot! I didn\\'t have shallots so used yellow onion and for the pasta used orzo. Thanks! Made for Zaar Tag.\" (November 10, 2007)\\n\\nDo you want to know the nutrition information for any ingredient in the recipe?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-44d07ebc-4654-4ac2-a96b-828b3d310c9c-0', usage_metadata={'input_tokens': 3574, 'output_tokens': 170, 'total_tokens': 3744, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='Get nutrition information of recipe_', additional_kwargs={}, response_metadata={}, id='e65c8112-9308-46fc-a477-ab6b432a9e85'),\n",
       " AIMessage(content='Okay, I can get you the nutrition information for the recipe \"soupe au pistou from nice\". To do this, I need to fetch the nutrition information for each ingredient individually and then aggregate the results.', additional_kwargs={'function_call': {'name': 'get_recipe_by_id', 'arguments': '{\"recipe_id\": \"184537\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-48252093-6521-469b-ac7b-bf2adbf7b01f-0', tool_calls=[{'name': 'get_recipe_by_id', 'args': {'recipe_id': '184537'}, 'id': 'aa8d9fce-d702-49cf-a1c4-41b246e46d0b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3749, 'output_tokens': 59, 'total_tokens': 3808, 'input_token_details': {'cache_read': 0}}),\n",
       " ToolMessage(content='{\\n  \"id\": \"184537\",\\n  \"name\": \"soupe au pistou from nice\",\\n  \"minutes\": 40,\\n  \"contributor_id\": 121690,\\n  \"submitted\": \"2006-09-03\",\\n  \"tags\": [\\n    \"60-minutes-or-less time-to-make course main-ingredient cuisine preparation occasion lunch soups-stews vegetables french easy european dinner-party vegetarian stove-top dietary green-yellow-beans squash tomatoes taste-mood savory equipment\"\\n  ],\\n  \"nutrition\": [\\n    126.0,\\n    0.0,\\n    21.0,\\n    2.0,\\n    10.0,\\n    0.0,\\n    8.0\\n  ],\\n  \"n_steps\": 7,\\n  \"steps\": [\\n    \"place vegetable stock in a large saucepan\",\\n    \"add zucchini through tomatoes and season with salt and pepper bring to a boil\",\\n    \"cover\",\\n    \"lower heat and simmer 20 minutes add green beans through pasta and cook about 10 minutes longer until pasta is tender adjust seasonings if necessary whisk together pesto and sundried tomato paste ladle soup into 4 bowls and stir a spoonful of the pesto mixture into each pass around grated parmesan to be sprinkled on soup\",\\n    \"if desired\"\\n  ],\\n  \"description\": \"a simple and flavorful vegetable soup from the soup bible by debra mayhew. the combination of pesto and sundried tomato paste is an inspired touch.\",\\n  \"ingredients\": [\\n    \"vegetable stock zucchini potato shallot carrot chopped tomatoes salt and pepper green beans frozen baby peas pasta pesto sauce sun-dried tomato paste parmesan cheese\"\\n  ],\\n  \"n_ingredients\": 13,\\n  \"dietary_tags\": [\\n    \"vegetarian\"\\n  ],\\n  \"cuisine_type\": \"french\",\\n  \"normalized_ingredients\": [\\n    \"vegetable stock zucchini potato shallot carrot chopped tomatoes salt and pepper green beans frozen baby peas pasta pesto sauce sun-dried tomato paste parmesan cheese\"\\n  ]\\n}', name='get_recipe_by_id', id='47dfb859-385b-4f08-8aa6-928f6283e86b', tool_call_id='aa8d9fce-d702-49cf-a1c4-41b246e46d0b'),\n",
       " AIMessage(content='Okay, I need to fetch the nutrition information for each ingredient in the recipe \"soupe au pistou from nice\".\\n\\nHere are the ingredients: vegetable stock, zucchini, potato, shallot, carrot, chopped tomatoes, salt and pepper, green beans, frozen baby peas, pasta, pesto sauce, sun-dried tomato paste, parmesan cheese.', additional_kwargs={'function_call': {'name': 'fetch_nutrition_from_openfoodfacts', 'arguments': '{\"ingredient_name\": \"parmesan cheese\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-94f591c1-40e0-4c07-a678-babfe1b8ed11-0', tool_calls=[{'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'vegetable stock'}, 'id': 'ce0a3444-9013-46c1-90f4-572b864bff4b', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'zucchini'}, 'id': '6fdef77e-9ae3-4fcb-947e-2d06cccb845a', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'potato'}, 'id': 'fc1a7b9f-c2d5-4d9d-808e-35f38438e70f', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'shallot'}, 'id': '0dc5fec8-b694-4c7a-b8d6-e46aceef97cb', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'carrot'}, 'id': '4ee9b806-67f0-43a8-84f4-d6c1c6a6e215', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'chopped tomatoes'}, 'id': '578eab24-ab1a-4fe4-ab70-0be459815bb3', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'salt and pepper'}, 'id': 'b204cc15-c050-4992-9d51-b75928941fbb', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'green beans'}, 'id': '9af3fd63-a8b9-41da-8f5a-7a19d5427033', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'frozen baby peas'}, 'id': '02a427e2-568c-41d7-8614-4c52ca85362e', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'pasta'}, 'id': 'a8a18724-9d6f-4ff3-9283-820c34bf0021', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'pesto sauce'}, 'id': '7bb05d99-005c-4efc-88db-35ae375e6694', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'sun-dried tomato paste'}, 'id': 'd139e3cc-87ee-486c-9c13-e29085b52e10', 'type': 'tool_call'}, {'name': 'fetch_nutrition_from_openfoodfacts', 'args': {'ingredient_name': 'parmesan cheese'}, 'id': '3567cafb-a6e8-4b4e-996c-9ad2b3710619', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4044, 'output_tokens': 258, 'total_tokens': 4302, 'input_token_details': {'cache_read': 0}}),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=vegetable+stock&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f79bd70>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='38c8bfcc-fdc7-4b7f-8915-ecf8f8a63eb5', tool_call_id='ce0a3444-9013-46c1-90f4-572b864bff4b'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=zucchini&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f79bbf0>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='073b5e3c-7a35-43d6-9082-610e135b67d9', tool_call_id='6fdef77e-9ae3-4fcb-947e-2d06cccb845a'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=potato&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f882ad280>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='f39583f5-6b0d-43bb-9db1-77da1c95b21b', tool_call_id='fc1a7b9f-c2d5-4d9d-808e-35f38438e70f'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=shallot&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f7ac080>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='01c0cea7-cadd-485e-9bb9-40987b3b4493', tool_call_id='0dc5fec8-b694-4c7a-b8d6-e46aceef97cb'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=carrot&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f79a540>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='bfdda6c1-fe79-420f-85e9-88a690a94446', tool_call_id='4ee9b806-67f0-43a8-84f4-d6c1c6a6e215'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=chopped+tomatoes&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f787c50>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='79e965db-110b-4d9a-82ab-65781bfe1ccd', tool_call_id='578eab24-ab1a-4fe4-ab70-0be459815bb3'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=salt+and+pepper&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f799430>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='4f565f78-8785-4009-bea4-8c260cacfe4b', tool_call_id='b204cc15-c050-4992-9d51-b75928941fbb'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=green+beans&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f79a000>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='f44eb7e0-f718-41e2-ac12-d33e2cfcb67d', tool_call_id='9af3fd63-a8b9-41da-8f5a-7a19d5427033'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=frozen+baby+peas&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f882af9b0>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='699694ac-8f31-4049-adf4-570ad5d3f28c', tool_call_id='02a427e2-568c-41d7-8614-4c52ca85362e'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=pasta&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f772c90>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='007bf1b2-da7f-447a-bcf2-9737d7ed676d', tool_call_id='a8a18724-9d6f-4ff3-9283-820c34bf0021'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=pesto+sauce&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f79b4a0>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='bf9fecb2-93a1-4369-999b-a62d72ba494e', tool_call_id='7bb05d99-005c-4efc-88db-35ae375e6694'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=sun-dried+tomato+paste&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f799d90>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='20dd3595-3fdb-495f-8477-fc5ac7e5dae6', tool_call_id='d139e3cc-87ee-486c-9c13-e29085b52e10'),\n",
       " ToolMessage(content='{\"status\": \"unavailable\", \"reason\": \"API request failed after retries: HTTPSConnectionPool(host=\\'world.openfoodfacts.org\\', port=443): Max retries exceeded with url: /cgi/search.pl?search_terms=parmesan+cheese&search_simple=1&action=process&json=1&page_size=1 (Caused by NewConnectionError(\\'<urllib3.connection.HTTPSConnection object at 0x783f1f7adf70>: Failed to establish a new connection: [Errno 111] Connection refused\\'))\"}', name='fetch_nutrition_from_openfoodfacts', id='de346bda-1036-4552-8947-0dac53390193', tool_call_id='3567cafb-a6e8-4b4e-996c-9ad2b3710619'),\n",
       " AIMessage(content=\"Here's the approximate average nutrition per 100g for ingredients in **recipe 184537**:\\n\\n\\n(Note: Could not retrieve nutrition data for the ingredients.)\", additional_kwargs={}, response_metadata={}, id='41602137-0d87-4d44-80ab-540f52827376', metadata={'intent': 'nutrition_presented'})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d10b2b18-3b38-4a7c-869c-f7687eca5bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG TOOL CALL: fetch_nutrition_from_usda_fdc(ingredient_name='raw apple')\n",
      "--> Successfully found nutrition data for 'raw apple' via USDA FDC\n",
      "\n",
      "--- Result for 'raw apple' ---\n",
      "{\n",
      "  \"food_normalized\": \"raw apple\",\n",
      "  \"source\": \"USDA FoodData Central\",\n",
      "  \"product_name\": \"Rose-apples, raw\",\n",
      "  \"fdc_id\": 168171,\n",
      "  \"data_type\": \"SR Legacy\",\n",
      "  \"calories_100g\": 25.0,\n",
      "  \"proteins_100g\": 0.6,\n",
      "  \"sodium_100g\": 0.0,\n",
      "  \"fat_100g\": 0.3,\n",
      "  \"carbohydrates_100g\": 5.7\n",
      "}\n",
      "\n",
      "--- Result for 'cheddar cheese' ---\n",
      "DEBUG TOOL CALL: fetch_nutrition_from_usda_fdc(ingredient_name='cheddar cheese')\n",
      "--> Successfully found nutrition data for 'cheddar cheese' via USDA FDC\n",
      "{\n",
      "  \"food_normalized\": \"cheddar cheese\",\n",
      "  \"source\": \"USDA FoodData Central\",\n",
      "  \"product_name\": \"Cheese, cheddar\",\n",
      "  \"fdc_id\": 328637,\n",
      "  \"data_type\": \"Foundation\",\n",
      "  \"carbohydrates_100g\": 2.44,\n",
      "  \"calories_100g\": 1710.0,\n",
      "  \"proteins_100g\": 23.3,\n",
      "  \"fat_100g\": 34.0,\n",
      "  \"saturated_fat_100g\": 19.2,\n",
      "  \"sodium_100g\": 654\n",
      "}\n",
      "\n",
      "--- Result for 'xyzabc_not_a_food_123' ---\n",
      "DEBUG TOOL CALL: fetch_nutrition_from_usda_fdc(ingredient_name='xyzabc_not_a_food_123')\n",
      "--> No product found for 'xyzabc_not_a_food_123' via USDA FDC\n",
      "{\"status\": \"unavailable\", \"reason\": \"No product found for 'xyzabc_not_a_food_123' on USDA FDC\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import os # Added to potentially get API key from environment\n",
    "\n",
    "# Consider getting the API key from an environment variable for security\n",
    "# Example: export USDA_API_KEY='YOUR_API_KEY_HERE'\n",
    "# If using an environment variable:\n",
    "# USDA_API_KEY = os.environ.get(\"USDA_API_KEY\")\n",
    "# Or pass it directly as an argument to the function.\n",
    "\n",
    "# Mapping from FDC nutrient names (or IDs for more stability) to our desired keys.\n",
    "# Using names here for readability. Units are typically per 100g in FDC.\n",
    "# Note: FDC uses 'KCAL' for calories, 'G' for macros, 'MG' for sodium.\n",
    "FDC_NUTRIENT_MAP = {\n",
    "    # Nutrient Name in FDC API : Target Key\n",
    "    \"Energy\": \"calories_100g\", # Often unit KCAL\n",
    "    \"Total lipid (fat)\": \"fat_100g\", # Often unit G\n",
    "    \"Fatty acids, total saturated\": \"saturated_fat_100g\", # Often unit G\n",
    "    \"Carbohydrate, by difference\": \"carbohydrates_100g\", # Often unit G\n",
    "    \"Sugars, total including NLEA\": \"sugars_100g\", # Often unit G\n",
    "    \"Fiber, total dietary\": \"fiber_100g\", # Often unit G\n",
    "    \"Protein\": \"proteins_100g\", # Often unit G\n",
    "    \"Sodium, Na\": \"sodium_100g\", # Often unit MG\n",
    "}\n",
    "\n",
    "# We also need to know the expected units to potentially filter/validate\n",
    "# (though the current code doesn't strictly enforce units, just finds the value)\n",
    "FDC_EXPECTED_UNITS = {\n",
    "    \"calories_100g\": \"KCAL\",\n",
    "    \"fat_100g\": \"G\",\n",
    "    \"saturated_fat_100g\": \"G\",\n",
    "    \"carbohydrates_100g\": \"G\",\n",
    "    \"sugars_100g\": \"G\",\n",
    "    \"fiber_100g\": \"G\",\n",
    "    \"proteins_100g\": \"G\",\n",
    "    \"sodium_100g\": \"MG\",\n",
    "}\n",
    "\n",
    "\n",
    "# @tool # Uncomment this if you are using it as a LangChain/LangGraph tool\n",
    "def fetch_nutrition_from_usda_fdc(ingredient_name: str, api_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches nutrition data (per 100g) for a single ingredient from USDA FoodData Central API.\n",
    "    Requires a USDA FDC API key. Includes robust retry logic.\n",
    "    Returns nutrition data as a JSON string or an error/unavailable status.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG TOOL CALL: fetch_nutrition_from_usda_fdc(ingredient_name='{ingredient_name}')\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"ERROR: USDA FDC API key is required.\")\n",
    "        return json.dumps({\"error\": \"USDA FDC API key was not provided.\"})\n",
    "\n",
    "    search_url = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
    "    params = {\n",
    "        \"query\": ingredient_name,\n",
    "        \"api_key\": api_key,\n",
    "        \"pageSize\": 1, # Get the top hit\n",
    "        \"dataType\": \"SR Legacy,Foundation\", # Prioritize standard reference / foundation foods for generic ingredients\n",
    "        # Consider adding \"Branded\" if you need specific packaged products\n",
    "    }\n",
    "    headers = {'User-Agent': 'KitchenAssistantLangGraph/1.0 (Language: Python)'} # Good practice\n",
    "\n",
    "    max_retries = 3\n",
    "    base_timeout = 15\n",
    "    retry_delay = 1 # Initial delay\n",
    "\n",
    "    for attempt in range(max_retries): # 0, 1, 2 (3 attempts total)\n",
    "        try:\n",
    "            response = requests.get(search_url, params=params, headers=headers, timeout=base_timeout)\n",
    "            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "            data = response.json()\n",
    "\n",
    "            if data.get('foods') and len(data['foods']) > 0:\n",
    "                food_item = data['foods'][0]\n",
    "                fdc_nutrients = food_item.get('foodNutrients', [])\n",
    "\n",
    "                # Extract desired fields using the mapping\n",
    "                nutrition_info = {\n",
    "                    \"food_normalized\": ingredient_name,\n",
    "                    \"source\": \"USDA FoodData Central\",\n",
    "                    \"product_name\": food_item.get('description', ingredient_name), # Use FDC description\n",
    "                    \"fdc_id\": food_item.get('fdcId'), # Useful identifier\n",
    "                    \"data_type\": food_item.get('dataType'), # e.g., SR Legacy, Branded\n",
    "                }\n",
    "\n",
    "                # Iterate through nutrients reported by FDC for this food\n",
    "                found_nutrients = {}\n",
    "                for nutrient in fdc_nutrients:\n",
    "                    nutrient_name = nutrient.get('nutrientName')\n",
    "                    nutrient_unit = nutrient.get('unitName')\n",
    "                    nutrient_value = nutrient.get('value')\n",
    "\n",
    "                    # Check if this nutrient is one we want to map\n",
    "                    target_key = FDC_NUTRIENT_MAP.get(nutrient_name)\n",
    "                    if target_key:\n",
    "                         # Optional: Check if the unit matches expected (e.g., KCAL for Energy)\n",
    "                         # expected_unit = FDC_EXPECTED_UNITS.get(target_key)\n",
    "                         # if nutrient_unit == expected_unit:\n",
    "                        found_nutrients[target_key] = nutrient_value\n",
    "                         # else:\n",
    "                         #    print(f\"Warning: Unit mismatch for {target_key}: Expected {expected_unit}, Got {nutrient_unit}\")\n",
    "\n",
    "\n",
    "                # Add found nutrients to the main dictionary\n",
    "                nutrition_info.update(found_nutrients)\n",
    "\n",
    "                # Filter out None values BEFORE checking core nutrients\n",
    "                # (Note: FDC usually returns 0 rather than null/None for zero values)\n",
    "                filtered_nutrition = {k: v for k, v in nutrition_info.items() if v is not None}\n",
    "\n",
    "                # Check if at least one core nutrient is present and numeric\n",
    "                core_nutrients = [\"calories_100g\", \"fat_100g\", \"proteins_100g\", \"carbohydrates_100g\"]\n",
    "                has_core_data = False\n",
    "                for core_key in core_nutrients:\n",
    "                    if core_key in filtered_nutrition:\n",
    "                        try:\n",
    "                            # Check if it's actually a number (or can be converted)\n",
    "                            float(filtered_nutrition[core_key])\n",
    "                            has_core_data = True\n",
    "                            break # Found at least one valid core nutrient\n",
    "                        except (ValueError, TypeError):\n",
    "                            continue # Skip if not numeric\n",
    "\n",
    "                if not has_core_data:\n",
    "                    print(f\"--> No core numeric nutrition data found for '{ingredient_name}' in product '{filtered_nutrition.get('product_name', 'N/A')}' (FDC ID: {filtered_nutrition.get('fdc_id')})\")\n",
    "                    return json.dumps({\"status\": \"unavailable\", \"reason\": f\"No detailed numeric core nutrition data found for '{ingredient_name}'\"})\n",
    "\n",
    "                # Success: return JSON string\n",
    "                print(f\"--> Successfully found nutrition data for '{ingredient_name}' via USDA FDC\")\n",
    "                return json.dumps(filtered_nutrition, indent=2)\n",
    "            else:\n",
    "                # No food found for the query\n",
    "                print(f\"--> No product found for '{ingredient_name}' via USDA FDC\")\n",
    "                # Try again with Branded data type? Or just report unavailable.\n",
    "                # Let's report unavailable for now.\n",
    "                return json.dumps({\"status\": \"unavailable\", \"reason\": f\"No product found for '{ingredient_name}' on USDA FDC\"})\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            # Specific handling for FDC API key errors (403 Forbidden often indicates bad key)\n",
    "            if e.response.status_code == 403:\n",
    "                 print(f\"HTTP Error 403 (Forbidden) for '{ingredient_name}'. Check your USDA FDC API key.\")\n",
    "                 return json.dumps({\"status\": \"error\", \"reason\": f\"API request failed with HTTP 403 (Forbidden). Check API Key.\"})\n",
    "            elif e.response.status_code == 429 and attempt < max_retries - 1:\n",
    "                wait_time = (retry_delay * (2 ** attempt)) + random.uniform(0, 1)\n",
    "                print(f\"Rate limit hit for '{ingredient_name}'. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            elif e.response.status_code >= 500 and attempt < max_retries - 1:\n",
    "                wait_time = (retry_delay * (2 ** attempt)) + random.uniform(0, 1)\n",
    "                print(f\"Server error ({e.response.status_code}) for '{ingredient_name}'. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"HTTP Error fetching nutrition for '{ingredient_name}': {e}\")\n",
    "                return json.dumps({\"status\": \"unavailable\", \"reason\": f\"API request failed with HTTP error: {e}\"})\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (retry_delay * (2 ** attempt)) + random.uniform(0, 1)\n",
    "                print(f\"Request error for '{ingredient_name}': {e}. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error fetching nutrition for '{ingredient_name}' after {max_retries} attempts: {e}\")\n",
    "                return json.dumps({\"status\": \"unavailable\", \"reason\": f\"API request failed after retries: {e}\"})\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON response for '{ingredient_name}'\")\n",
    "            return json.dumps({\"status\": \"unavailable\", \"reason\": \"Invalid JSON response from API\"})\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"ERROR in fetch_nutrition_from_usda_fdc: {e}\")\n",
    "             import traceback\n",
    "             traceback.print_exc()\n",
    "             return json.dumps({\"error\": f\"Unexpected error fetching nutrition for {ingredient_name}: {e}\"})\n",
    "\n",
    "    # If loop finishes after retries without success\n",
    "    print(f\"Max retries ({max_retries}) exceeded for API request for '{ingredient_name}'\")\n",
    "    return json.dumps({\"status\": \"unavailable\", \"reason\": f\"Max retries ({max_retries}) exceeded for API request for '{ingredient_name}'\"})\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANT: Replace 'YOUR_API_KEY_HERE' with your actual USDA FDC API key\n",
    "    # Or set the USDA_API_KEY environment variable\n",
    "    my_api_key = \"2X6M5RYxIHH57hHAp9OXdoNA8CuLHD51XgwAfp7c\" # <--- GET YOUR KEY FROM https://fdc.nal.usda.gov/api-guide.html#api-key\n",
    "\n",
    "    if my_api_key == \"YOUR_API_KEY_HERE\":\n",
    "       print(\"Please replace 'YOUR_API_KEY_HERE' with your actual USDA API key to run the example.\")\n",
    "    else:\n",
    "        ingredient = \"raw apple\"\n",
    "        result_json = fetch_nutrition_from_usda_fdc(ingredient, my_api_key)\n",
    "        print(\"\\n--- Result for 'raw apple' ---\")\n",
    "        print(result_json)\n",
    "\n",
    "        print(\"\\n--- Result for 'cheddar cheese' ---\")\n",
    "        result_json_cheese = fetch_nutrition_from_usda_fdc(\"cheddar cheese\", my_api_key)\n",
    "        print(result_json_cheese)\n",
    "\n",
    "        print(\"\\n--- Result for 'xyzabc_not_a_food_123' ---\")\n",
    "        result_json_nonsense = fetch_nutrition_from_usda_fdc(\"xyzabc_not_a_food_123\", my_api_key)\n",
    "        print(result_json_nonsense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658d845-458c-45f3-aa3a-4a2caca31347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
