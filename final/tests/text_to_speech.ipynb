{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c301bd2",
   "metadata": {},
   "source": [
    "## Text-to-Speech Utilities\n",
    "\n",
    "This section provides better alternatives to pyttsx3 for text-to-speech conversion.\n",
    "\n",
    "### Available TTS Options:\n",
    "\n",
    "1. **gTTS (Google Text-to-Speech)** - High-quality speech using Google's API\n",
    "2. **Cloud-based options** - Google Cloud TTS, Amazon Polly, Microsoft Azure\n",
    "3. **Local options** - Mozilla TTS, ESPnet, Coqui TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5f84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q gtts edge-tts nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure asyncio for Jupyter notebooks\n",
    "import asyncio\n",
    "import nest_asyncio  # Solution for asyncio in notebooks\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio.run() in notebooks\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e2a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Google Text-to-Speech (gTTS)\n",
    "# Install with: pip install gtts\n",
    "\n",
    "def tts_gtts(text, output_filename, lang='en', slow=False):\n",
    "    \"\"\"\n",
    "    Convert text to speech using Google's Text-to-Speech API (gTTS).\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to convert to speech\n",
    "        output_filename (str): Full path to save the output MP3 file\n",
    "        lang (str): Language code (default: 'en')\n",
    "        slow (bool): Whether to speak slowly (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from gtts import gTTS\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        \n",
    "        # Make sure output directory exists\n",
    "        output_path = Path(output_filename)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create gTTS object\n",
    "        tts = gTTS(text=text, lang=lang, slow=slow)\n",
    "        \n",
    "        # Save to file (MP3 format)\n",
    "        tts.save(str(output_path))\n",
    "        \n",
    "        print(f\"Audio saved to: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech conversion: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb448aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge TTS implementation - Microsoft Edge browser's TTS engine\n",
    "import asyncio\n",
    "\n",
    "async def run_edge_tts(text, output_filename, voice=\"en-US-AriaNeural\"):\n",
    "    \"\"\"Convert text to speech using Microsoft Edge TTS\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to convert to speech\n",
    "        output_filename (str): Full path to save the output MP3 file\n",
    "        voice (str): Voice identifier (default: 'en-US-AriaNeural')\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import edge_tts\n",
    "        from pathlib import Path\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        output_path = Path(output_filename)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Set up TTS communication\n",
    "        communicate = edge_tts.Communicate(text, voice)\n",
    "        \n",
    "        # Save audio to file\n",
    "        await communicate.save(str(output_path))\n",
    "        \n",
    "        print(f\"Audio saved to: {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech conversion: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0b2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronous wrapper for edge-tts\n",
    "def tts_edge(text, output_filename, voice=\"en-US-AriaNeural\"):\n",
    "    \"\"\"Synchronous wrapper for edge-tts\"\"\"\n",
    "    return asyncio.run(run_edge_tts(text, output_filename, voice))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d694236",
   "metadata": {},
   "source": [
    "### Comparison of TTS Options\n",
    "\n",
    "| Library         | Quality | Internet Required | Installation | Output Format |\n",
    "|----------------|---------|-------------------|-------------|--------------|\n",
    "| gTTS           | Good    | Yes               | Simple      | MP3          |\n",
    "| Google Cloud TTS| Excellent | Yes            | Complex     | MP3/WAV/OGG  |\n",
    "| Edge TTS       | Very Good | Yes (first use) | Simple      | MP3          |\n",
    "| pyttsx3        | Basic   | No                | Simple      | WAV          |\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "1. **For quick implementation**: Use gTTS - good quality, easy to use\n",
    "2. **For production quality**: Use Google Cloud TTS - excellent quality, many voices\n",
    "3. **For offline use**: Use Edge TTS - good quality with cached voices\n",
    "\n",
    "All these options are more reliable than pyttsx3 and provide better quality speech output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fed618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to: tts_output/sample_speech.mp3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage - Uncomment the one you want to try\n",
    "\n",
    "text = \"Hello, this is a test of the text-to-speech system. This should sound much better than pyttsx3.\"\n",
    "output_file = \"./tts_output/sample_speech.mp3\"\n",
    "\n",
    "# Try gTTS (Google Text-to-Speech)\n",
    "# tts_gtts(text, output_file)\n",
    "\n",
    "# Try Edge TTS (Microsoft Edge TTS) - Jupyter compatible way with await\n",
    "# Method 1: Using await directly (requires that the run_edge_tts function is defined)\n",
    "await run_edge_tts(text, output_file)\n",
    "\n",
    "# Method 2: Or use the synchronous wrapper\n",
    "# tts_edge(text, output_file)\n",
    "\n",
    "# Try Google Cloud TTS (requires API credentials)\n",
    "# tts_google_cloud(text, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1001609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback option: Using gtts if edge-tts doesn't work\n",
    "try:\n",
    "    from gtts import gTTS\n",
    "    tts = gTTS(text=\"This is a fallback test using gTTS, which has no asyncio issues.\")\n",
    "    output_path = \"./tts_output/fallback_speech.mp3\"\n",
    "    from pathlib import Path\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    tts.save(output_path)\n",
    "    print(f\"Fallback audio saved to: {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with fallback TTS: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c28b3",
   "metadata": {},
   "source": [
    "## Batch Text-to-Speech Conversion for Commands\n",
    "\n",
    "This section converts a set of predefined commands to speech files that can be used in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc266dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define texts and output paths for batch conversion\n",
    "command_texts = [\n",
    "    \"Hello, what can you do?\",\n",
    "    \"Find me vegeterian soup recipes and tag the recipes. 5 recipes\",\n",
    "    \"I like to know about third recipe in the list but not review\",\n",
    "    \"Show the recipe reviews\",\n",
    "    \"Get nutriotion information for this recipe\",\n",
    "    \"Run the nutrition analysis for the recipe we just discussed.\",\n",
    "    \"make this recipe more healthy for low fat diet\",\n",
    "    \"What's a good substitute for egg yolks\"\n",
    "]\n",
    "\n",
    "# Define output paths and labels\n",
    "command_labels = [\n",
    "    \"1.Intro\",\n",
    "    \"2.Recipe Search\",\n",
    "    \"3.Get Recipe Info\",\n",
    "    \"4.Check the Reviews\", \n",
    "    \"5.Get Nutrition Info\",\n",
    "    \"6.Nutrition Analysis\",\n",
    "    \"7.Recipe Customization\", \n",
    "    \"8.Search on Internet\"\n",
    "]\n",
    "\n",
    "# Create output folder\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_folder = Path(\"./command_voices\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Function to generate file name from label\n",
    "def get_filename(label, speaker=\"Nariman\", ext=\"ogg\"):\n",
    "    sanitized_label = label.replace(\" \", \"_\").replace(\".\", \"\")\n",
    "    return f\"{label.split('.')[0]}.{speaker}_{sanitized_label}.{ext}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a897fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch conversion function using Edge TTS\n",
    "async def batch_convert_edge_tts(texts, labels, output_folder, voice=\"en-US-AriaNeural\", file_ext=\"ogg\"):\n",
    "    \"\"\"Convert multiple texts to speech using Edge TTS\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of texts to convert\n",
    "        labels (list): List of corresponding labels\n",
    "        output_folder (Path): Folder to save output files\n",
    "        voice (str): Voice to use for TTS\n",
    "        file_ext (str): File extension (ogg or mp3)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of generated file paths\n",
    "    \"\"\"\n",
    "    import edge_tts\n",
    "    from pathlib import Path\n",
    "    \n",
    "    output_files = []\n",
    "    \n",
    "    for i, (text, label) in enumerate(zip(texts, labels)):\n",
    "        # Generate filename from label\n",
    "        filename = get_filename(label, \"Nariman\", file_ext)\n",
    "        output_path = output_folder / filename\n",
    "        \n",
    "        # Set up TTS communication\n",
    "        communicate = edge_tts.Communicate(text, voice)\n",
    "        \n",
    "        # Save audio to file\n",
    "        await communicate.save(str(output_path))\n",
    "        \n",
    "        print(f\"[{i+1}/{len(texts)}] Saved: {output_path}\")\n",
    "        output_files.append(str(output_path))\n",
    "    \n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ecae655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch conversion function using gTTS (as fallback)\n",
    "def batch_convert_gtts(texts, labels, output_folder, lang='en', slow=False, file_ext=\"mp3\"):\n",
    "    \"\"\"Convert multiple texts to speech using gTTS\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of texts to convert\n",
    "        labels (list): List of corresponding labels\n",
    "        output_folder (Path): Folder to save output files\n",
    "        lang (str): Language code\n",
    "        slow (bool): Whether to speak slowly\n",
    "        file_ext (str): File extension (usually mp3 for gTTS)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of generated file paths\n",
    "    \"\"\"\n",
    "    from gtts import gTTS\n",
    "    from pathlib import Path\n",
    "    \n",
    "    output_files = []\n",
    "    \n",
    "    for i, (text, label) in enumerate(zip(texts, labels)):\n",
    "        # Generate filename from label\n",
    "        filename = get_filename(label, \"Nariman\", file_ext)\n",
    "        output_path = output_folder / filename\n",
    "        \n",
    "        # Create gTTS object and save\n",
    "        tts = gTTS(text=text, lang=lang, slow=slow)\n",
    "        tts.save(str(output_path))\n",
    "        \n",
    "        print(f\"[{i+1}/{len(texts)}] Saved: {output_path}\")\n",
    "        output_files.append(str(output_path))\n",
    "    \n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec9ee545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/8] Saved: command_voices/1.Nariman_1Intro.ogg\n",
      "[2/8] Saved: command_voices/2.Nariman_2Recipe_Search.ogg\n",
      "[3/8] Saved: command_voices/3.Nariman_3Get_Recipe_Info.ogg\n",
      "[4/8] Saved: command_voices/4.Nariman_4Check_the_Reviews.ogg\n",
      "[5/8] Saved: command_voices/5.Nariman_5Get_Nutrition_Info.ogg\n",
      "[6/8] Saved: command_voices/6.Nariman_6Nutrition_Analysis.ogg\n",
      "[7/8] Saved: command_voices/7.Nariman_7Recipe_Customization.ogg\n",
      "[8/8] Saved: command_voices/8.Nariman_8Search_on_Internet.ogg\n",
      "Successfully generated 8 audio files.\n"
     ]
    }
   ],
   "source": [
    "# Convert commands using Edge TTS (better quality)\n",
    "# Choose a good voice - examples:\n",
    "# - en-US-AriaNeural (female)\n",
    "# - en-US-GuyNeural (male)\n",
    "# - en-GB-SoniaNeural (British female)\n",
    "\n",
    "voice = \"en-US-AriaNeural\"  # Change as needed\n",
    "file_ext = \"ogg\"  # ogg files are typically smaller with good quality\n",
    "\n",
    "try:\n",
    "    # Run the batch conversion\n",
    "    generated_files = await batch_convert_edge_tts(\n",
    "        command_texts, \n",
    "        command_labels, \n",
    "        output_folder, \n",
    "        voice=voice,\n",
    "        file_ext=file_ext\n",
    "    )\n",
    "    print(f\"Successfully generated {len(generated_files)} audio files.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with Edge TTS: {str(e)}\")\n",
    "    print(\"Falling back to gTTS...\")\n",
    "    # Fallback to gTTS\n",
    "    generated_files = batch_convert_gtts(\n",
    "        command_texts, \n",
    "        command_labels, \n",
    "        output_folder,\n",
    "        file_ext=\"mp3\"\n",
    "    )\n",
    "    print(f\"Successfully generated {len(generated_files)} audio files using fallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d885a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice_options = [\n",
      "    (\"Select Voice...\", \"\"),\n",
      "    (\"7.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/7.Nariman_7Recipe_Customization.ogg\"),\n",
      "    (\"5.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/5.Nariman_5Get_Nutrition_Info.ogg\"),\n",
      "    (\"6.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/6.Nariman_6Nutrition_Analysis.ogg\"),\n",
      "    (\"1.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/1.Nariman_1Intro.ogg\"),\n",
      "    (\"4.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/4.Nariman_4Check_the_Reviews.ogg\"),\n",
      "    (\"8.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/8.Nariman_8Search_on_Internet.ogg\"),\n",
      "    (\"3.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/3.Nariman_3Get_Recipe_Info.ogg\"),\n",
      "    (\"2.Nariman\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/2.Nariman_2Recipe_Search.ogg\"),\n",
      "    (\"Nariman 1\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/Nariman_1.ogg\"),\n",
      "    (\"Neda 1\", \"/kaggle/input/voices-of-commands-genai-capstone-2025/Neda_1.ogg\"),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Generate voice options list for application\n",
    "def generate_voice_options_list(output_folder, base_path=\"/kaggle/input/voices-of-commands-genai-capstone-2025\"):\n",
    "    \"\"\"Generate a list of voice options for the application\"\"\"\n",
    "    # List all files in the output folder\n",
    "    files = list(output_folder.glob(\"*.ogg\")) + list(output_folder.glob(\"*.mp3\"))\n",
    "    \n",
    "    # Create voice options list\n",
    "    voice_options = [(\"Select Voice...\", None)]\n",
    "    \n",
    "    for file in files:\n",
    "        # Get the base name without extension\n",
    "        name = file.stem\n",
    "        # Generate label from filename\n",
    "        if \"_\" in name:\n",
    "            label_parts = name.split(\"_\", 1)\n",
    "            if \".\" in label_parts[0]:\n",
    "                label = label_parts[0]  # Use numbered label if it exists\n",
    "            else:\n",
    "                label = name.replace(\"_\", \" \")\n",
    "        else:\n",
    "            label = name\n",
    "            \n",
    "        # Create the voice option tuple with the kaggle path\n",
    "        kaggle_path = f\"{base_path}/{file.name}\"\n",
    "        voice_options.append((label, kaggle_path))\n",
    "    \n",
    "    # Add additional default voice options\n",
    "    voice_options.append((\"Nariman 1\", f\"{base_path}/Nariman_1.ogg\"))\n",
    "    voice_options.append((\"Neda 1\", f\"{base_path}/Neda_1.ogg\"))\n",
    "    \n",
    "    return voice_options\n",
    "\n",
    "# Generate the voice options list\n",
    "voice_options = generate_voice_options_list(output_folder)\n",
    "\n",
    "# Print the voice options in the format we need\n",
    "print(\"voice_options = [\")\n",
    "for label, path in voice_options:\n",
    "    print(f\"    (\\\"{label}\\\", \\\"{path if path else ''}\\\"),\")\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05a205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated audio files:\n",
      "1. 1.Nariman_1Intro.ogg (14.2 KB)\n",
      "2. 2.Nariman_2Recipe_Search.ogg (38.7 KB)\n",
      "3. 3.Nariman_3Get_Recipe_Info.ogg (23.9 KB)\n",
      "4. 4.Nariman_4Check_the_Reviews.ogg (15.0 KB)\n",
      "5. 5.Nariman_5Get_Nutrition_Info.ogg (21.0 KB)\n",
      "6. 6.Nariman_6Nutrition_Analysis.ogg (25.2 KB)\n",
      "7. 7.Nariman_7Recipe_Customization.ogg (22.5 KB)\n",
      "8. 8.Nariman_8Search_on_Internet.ogg (19.1 KB)\n"
     ]
    }
   ],
   "source": [
    "# Check what files were created\n",
    "import os\n",
    "\n",
    "print(\"Generated audio files:\")\n",
    "for i, file in enumerate(sorted(os.listdir(output_folder))):\n",
    "    file_path = os.path.join(output_folder, file)\n",
    "    file_size = os.path.getsize(file_path) / 1024  # Size in KB\n",
    "    print(f\"{i+1}. {file} ({file_size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70181cd2",
   "metadata": {},
   "source": [
    "## Voice Dataset for Kaggle\n",
    "\n",
    "### Dataset: Voices of Commands - GenAI Capstone 2025\n",
    "\n",
    "#### Description\n",
    "This dataset contains high-quality voice recordings for the ChefBelle AI Kitchen Assistant project, developed as part of the Google GenAI Intensive Course Capstone 2025Q1. The voice recordings represent various user commands and queries related to recipe search, nutrition information, recipe customization, and more.\n",
    "\n",
    "#### Purpose\n",
    "The voice files are designed to demonstrate and test speech interaction capabilities of the ChefBelle AI Kitchen Assistant. These files showcase typical user interactions with the AI system, allowing for realistic testing and demonstration of the application's voice response features.\n",
    "\n",
    "#### File Information\n",
    "The dataset includes the following voice command recordings:\n",
    "\n",
    "1. **1.Nariman_intro.ogg** - Basic greeting and capability query (\"Hello, what can you do?\")\n",
    "2. **2.Nariman_search.ogg** - Recipe search query (\"Find me vegeterian soup recipes and tag the recipes. 5 recipes\")\n",
    "3. **3.Nariman_get_info.ogg** - Specific recipe information request (\"I like to know about third recipe in the list but not review\")\n",
    "4. **4.Nariman_review.ogg** - Request for recipe reviews (\"Show the recipe reviews\")\n",
    "5. **5.Nariman_nutrition.ogg** - Nutrition information query (\"Get nutriotion information for this recipe\")\n",
    "6. **6.Nariman_nutrition_analysis.ogg** - Detailed nutrition analysis request (\"Run the nutrition analysis for the recipe we just discussed.\")\n",
    "7. **7.Nariman_customization.ogg** - Recipe modification query (\"make this recipe more healthy for low fat diet\")\n",
    "8. **8.Nariman_grounding.ogg** - General cooking knowledge query (\"What's a good substitute for egg yolks\")\n",
    "9. **Nariman_1.ogg** - Additional voice sample\n",
    "10. **Neda_1.ogg** - Alternative voice sample\n",
    "\n",
    "#### Technical Specifications\n",
    "- **Audio Format**: OGG Vorbis (.ogg) - Selected for its excellent compression while maintaining good audio quality\n",
    "- **Voice Type**: Generated using Microsoft Edge TTS (Neural voices)\n",
    "- **Primary Voice**: en-US-AriaNeural (female voice)\n",
    "- **Language**: English (US)\n",
    "- **Quality**: High-quality synthesized speech with natural intonation and rhythm\n",
    "\n",
    "#### Usage in ChefBelle Project\n",
    "These voice recordings are used in the user interface of the ChefBelle AI Kitchen Assistant to demonstrate command examples and provide audio feedback. The application loads these files as part of its interactive demo capabilities, showing users the types of questions they can ask the AI assistant.\n",
    "\n",
    "#### Citation and Credits\n",
    "This voice dataset was created specifically for the Google GenAI Intensive Course Capstone 2025Q1 project. The synthesized voices are generated using Microsoft's Edge TTS technology and are used for educational and demonstration purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c58aa-5dbd-4d0b-b244-d70fd58d3554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
